{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 69-PyTorch-Kaggle-porto-driver\n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">\n",
    "\n",
    "\n",
    "### Data\n",
    "- Download from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.3.0\n",
      "__Python VERSION: 3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)]\n",
      "__pyTorch VERSION: 0.2.1+a4fc05a\n",
      "__CUDA VERSION\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "OS:  win32\n",
      "Python:  3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)]\n",
      "PyTorch:  0.2.1+a4fc05a\n",
      "Numpy:  1.13.3\n",
      "3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)]\n",
      "33.3\n",
      "svmem(total=68627443712, available=55941156864, percent=18.5, used=12686286848, free=55941156864)\n",
      "memory GB: 0.18726348876953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:USE CUDA=True\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import logging\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# print('__CUDNN VERSION:', torch.backends.cudnn.lib.cudnnGetErrorString())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "\n",
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install psutil\n",
    "import psutil\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def memReport():\n",
    "    for obj in gc.get_objects():\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    \n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "\n",
    "cpuStats()\n",
    "# memReport()\n",
    "\n",
    "# %%timeit\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "\n",
    "# use_cuda=False\n",
    "lgr.info(\"USE CUDA=\" + str (use_cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix seed\n",
    "seed=17*19\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)    \n",
    "# ! dir    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  View the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "c:\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (595212, 59)\n",
      "Test shape: (892816, 58)\n",
      "Columns: Index(['id', 'target', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03',\n",
      "       'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin',\n",
      "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
      "       'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15',\n",
      "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01',\n",
      "       'ps_reg_02', 'ps_reg_03', 'ps_car_01_cat', 'ps_car_02_cat',\n",
      "       'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat',\n",
      "       'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat',\n",
      "       'ps_car_11_cat', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14',\n",
      "       'ps_car_15', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04',\n",
      "       'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09',\n",
      "       'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
      "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
      "       'ps_calc_19_bin', 'ps_calc_20_bin'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc; gc.enable()\n",
    "# !pip install xgboost\n",
    "import xgboost as xgb\n",
    "# http://www.lfd.uci.edu/~gohlke/pythonlibs/#xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import sklearn\n",
    "\n",
    "# Data params\n",
    "TARGET_VAR= 'target'\n",
    "BASE_FOLDER = 'd:/db/data/porto/'\n",
    "\n",
    "# Read in our input data\n",
    "df_train = pd.read_csv(BASE_FOLDER + '/train.csv')\n",
    "df_test = pd.read_csv(BASE_FOLDER + '/test.csv')\n",
    "# This prints out (rows, columns) in each dataframe\n",
    "print('Train shape:', df_train.shape)\n",
    "print('Test shape:', df_test.shape)\n",
    "\n",
    "print('Columns:', df_train.columns)\n",
    "\n",
    "# y_train = df_train['target'].values\n",
    "# id_train = df_train['id'].values\n",
    "# id_test = df_test['id'].values\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595200, 130) (892816, 131)\n"
     ]
    }
   ],
   "source": [
    "# from rgf.sklearn import RGFClassifier     # https://github.com/fukatani/rgf_python\n",
    "\n",
    "train = df_train\n",
    "test = df_test\n",
    "\n",
    "# Preprocessing (Forza Baseline)\n",
    "id_test = test['id'].values\n",
    "\n",
    "col = [c for c in train.columns if c not in ['id','target']]\n",
    "col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "\n",
    "train = train.replace(-1, np.NaN)\n",
    "d_median = train.median(axis=0)\n",
    "d_mean = train.mean(axis=0)\n",
    "train = train.fillna(-1)\n",
    "one_hot = {c: list(train[c].unique()) for c in train.columns if c not in ['id','target']}\n",
    "\n",
    "\n",
    "def transform(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c:\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "\n",
    "    for c in one_hot:\n",
    "        if len(one_hot[c])>2 and len(one_hot[c]) < 7:\n",
    "            for val in one_hot[c]:\n",
    "                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n",
    "    return df\n",
    "\n",
    "\n",
    "train = transform(train)\n",
    "test = transform(test)\n",
    "\n",
    "col = [c for c in train.columns if c not in ['id','target']]\n",
    "col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "\n",
    "col_test = [c for c in test.columns if c not in ['target']]\n",
    "col_test = [c for c in col_test if not c.startswith('ps_calc_')]\n",
    "\n",
    "\n",
    "dups = train[train.duplicated(subset=col, keep=False)]\n",
    "\n",
    "train = train[~(train['id'].isin(dups['id'].values))]\n",
    "\n",
    "y_train = train['target'].values\n",
    "id_train = train['id'].values\n",
    "id_test = test['id'].values\n",
    "\n",
    "target_train = train['target']\n",
    "train = train[col]\n",
    "test = test[col_test]\n",
    "print(train.values.shape, test.values.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 476160 Validation samples: 119040\n"
     ]
    }
   ],
   "source": [
    "x_train = train\n",
    "x_test = test\n",
    "\n",
    "# Take a random 20% of the dataset as validation data\n",
    "trainX, valX, trainY, valY = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)\n",
    "print('Train samples: {} Validation samples: {}'.format(len(trainX), len(valX)))\n",
    "\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# n_components = 35\n",
    "# pca = PCA(n_components=n_components, svd_solver='randomized',whiten=True).fit(trainX)\n",
    "# trainX = pca.transform(trainX)\n",
    "\n",
    "\n",
    "N_FEATURES=trainX.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  From Numpy to PyTorch GPU tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "\n",
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def XnumpyToTensor(x_data_np):\n",
    "    x_data_np = np.array(x_data_np, dtype=np.float32)        \n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")    \n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")\n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "    \n",
    "    print(type(X_tensor.data)) # should be 'torch.cuda.FloatTensor'            \n",
    "    print((X_tensor.data.shape)) # torch.Size([108405, 29])\n",
    "    return X_tensor\n",
    "\n",
    "\n",
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def YnumpyToTensor(y_data_np):    \n",
    "    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")            \n",
    "    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")        \n",
    "    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n",
    "\n",
    "    print(type(Y_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))    \n",
    "    return Y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dropout (p = 0.30000000000000004)\n",
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (130 -> 65)\n",
      "  (1): LeakyReLU (0.01)\n",
      "  (2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (3): Dropout (p = 0.30000000000000004)\n",
      "  (4): Linear (65 -> 130)\n",
      "  (5): LeakyReLU (0.01)\n",
      "  (6): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (7): Dropout (p = 0.30000000000000004)\n",
      "  (8): Linear (130 -> 130)\n",
      "  (9): LeakyReLU (0.01)\n",
      "  (10): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (11): Dropout (p = 0.30000000000000004)\n",
      "  (12): Linear (130 -> 1)\n",
      "  (13): Sigmoid ()\n",
      ")\n",
      "INFO:__main__:Using the GPU\n",
      "INFO:__main__:<torch.optim.adam.Adam object at 0x000001C212DA22B0>\n",
      "INFO:__main__:BCELoss (\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# p is the probability of being dropped in PyTorch\n",
    "\n",
    "# NN params\n",
    "DROPOUT_PROB = 0.50\n",
    "\n",
    "LR = 0.005\n",
    "MOMENTUM= 0.85\n",
    "dropout = torch.nn.Dropout(p=1 - (DROPOUT_PROB))\n",
    "\n",
    "lgr.info(dropout)\n",
    "\n",
    "hiddenLayer1Size=int(N_FEATURES/2)\n",
    "hiddenLayer2Size=int(N_FEATURES)\n",
    "\n",
    "linear1=torch.nn.Linear(N_FEATURES, hiddenLayer1Size, bias=True) \n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "\n",
    "linear2=torch.nn.Linear(hiddenLayer1Size, N_FEATURES)\n",
    "torch.nn.init.xavier_uniform(linear2.weight)\n",
    "\n",
    "linear3=torch.nn.Linear(N_FEATURES, hiddenLayer2Size)\n",
    "torch.nn.init.xavier_uniform(linear3.weight)\n",
    "\n",
    "linear4=torch.nn.Linear(hiddenLayer2Size, hiddenLayer2Size)\n",
    "torch.nn.init.xavier_uniform(linear4.weight)\n",
    "\n",
    "linear5=torch.nn.Linear(hiddenLayer2Size, N_FEATURES)\n",
    "torch.nn.init.xavier_uniform(linear5.weight)\n",
    "\n",
    "linear6=torch.nn.Linear(N_FEATURES, 1)\n",
    "torch.nn.init.xavier_uniform(linear6.weight)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "tanh=torch.nn.Tanh()\n",
    "relu=torch.nn.LeakyReLU()\n",
    "\n",
    "\n",
    "net = torch.nn.Sequential(linear1,relu,nn.BatchNorm1d(hiddenLayer1Size),dropout,\n",
    "                          linear2,relu,nn.BatchNorm1d(N_FEATURES),dropout,                                                    \n",
    "                          linear5,relu,nn.BatchNorm1d(N_FEATURES),dropout,\n",
    "                          linear6,sigmoid\n",
    "                          )\n",
    "\n",
    "\n",
    "lgr.info(net)  # net architecture\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-4) #  L2 regularization\n",
    "loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    net.cuda()\n",
    "    loss_func.cuda()\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "lgr.info (optimizer)\n",
    "lgr.info (loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (0): Linear (130 -> 65)\n",
      "  (1): LeakyReLU (0.01)\n",
      "  (2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (3): Dropout (p = 0.30000000000000004)\n",
      "  (4): Linear (65 -> 130)\n",
      "  (5): LeakyReLU (0.01)\n",
      "  (6): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (7): Dropout (p = 0.30000000000000004)\n",
      "  (8): Linear (130 -> 130)\n",
      "  (9): LeakyReLU (0.01)\n",
      "  (10): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (11): Dropout (p = 0.30000000000000004)\n",
      "  (12): Linear (130 -> 1)\n",
      "  (13): Sigmoid ()\n",
      ")\n",
      "(476160, 130)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n",
      "torch.Size([476160, 130])\n",
      "(476160, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n",
      "(476160, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "0 [ 0.82115686]\n",
      "LOG_LOSS=0.7837673639417777, ROC_AUC=0.499392986544378, GINI=-0.0012140269112439483\n",
      "100 [ 0.15410288]\n",
      "LOG_LOSS=0.15437879800644633, ROC_AUC=0.6096208744338931, GINI=0.21924174886778625\n",
      "200 [ 0.15251628]\n",
      "LOG_LOSS=0.15261603467507534, ROC_AUC=0.6273776244324689, GINI=0.25475524886493783\n",
      "300 [ 0.15208118]\n",
      "LOG_LOSS=0.15199711166282892, ROC_AUC=0.6352118016648356, GINI=0.2704236033296712\n",
      "400 [ 0.15167485]\n",
      "LOG_LOSS=0.15193596223815325, ROC_AUC=0.6357078977024768, GINI=0.27141579540495364\n",
      "500 [ 0.15162459]\n",
      "LOG_LOSS=0.15157853020142195, ROC_AUC=0.6406540224321026, GINI=0.28130804486420513\n",
      "600 [ 0.15129671]\n",
      "LOG_LOSS=0.15139065388516754, ROC_AUC=0.642832748512521, GINI=0.28566549702504207\n",
      "700 [ 0.15142028]\n",
      "LOG_LOSS=0.15141486377851923, ROC_AUC=0.6428322205005257, GINI=0.2856644410010514\n",
      "800 [ 0.15147412]\n",
      "LOG_LOSS=0.15133828547306155, ROC_AUC=0.6442128576762499, GINI=0.28842571535249983\n",
      "900 [ 0.15100862]\n",
      "LOG_LOSS=0.1511792255504305, ROC_AUC=0.6460147434757758, GINI=0.2920294869515516\n",
      "1000 [ 0.15117593]\n",
      "LOG_LOSS=0.15110380493344255, ROC_AUC=0.6465954473833626, GINI=0.2931908947667252\n",
      "1100 [ 0.15127045]\n",
      "LOG_LOSS=0.1511137564633044, ROC_AUC=0.6463481722667023, GINI=0.29269634453340454\n",
      "1200 [ 0.15126848]\n",
      "LOG_LOSS=0.1511765662533159, ROC_AUC=0.6459466208735158, GINI=0.2918932417470317\n",
      "1300 [ 0.15116611]\n",
      "LOG_LOSS=0.15118184631874268, ROC_AUC=0.6460845545594097, GINI=0.29216910911881944\n",
      "1400 [ 0.1511143]\n",
      "LOG_LOSS=0.1509997995659402, ROC_AUC=0.6478681541785972, GINI=0.29573630835719444\n",
      "1500 [ 0.150985]\n",
      "LOG_LOSS=0.15134285261816632, ROC_AUC=0.6440341801022569, GINI=0.28806836020451376\n",
      "1600 [ 0.15100172]\n",
      "LOG_LOSS=0.151108624895262, ROC_AUC=0.6452175277370418, GINI=0.29043505547408355\n",
      "1700 [ 0.15104742]\n",
      "LOG_LOSS=0.1509934314277699, ROC_AUC=0.6484953024539107, GINI=0.2969906049078215\n",
      "1800 [ 0.15103364]\n",
      "LOG_LOSS=0.150919155217732, ROC_AUC=0.6477854297840946, GINI=0.2955708595681892\n",
      "1900 [ 0.15090422]\n",
      "LOG_LOSS=0.15119463174400682, ROC_AUC=0.6446289363476604, GINI=0.2892578726953208\n",
      "2000 [ 0.15111621]\n",
      "LOG_LOSS=0.1512159382302563, ROC_AUC=0.645222746862397, GINI=0.290445493724794\n",
      "2100 [ 0.15097491]\n",
      "LOG_LOSS=0.15101920403837105, ROC_AUC=0.6463129968709519, GINI=0.2926259937419038\n",
      "2200 [ 0.15111481]\n",
      "LOG_LOSS=0.1510468362325458, ROC_AUC=0.6479106012622311, GINI=0.2958212025244622\n",
      "2300 [ 0.15117587]\n",
      "LOG_LOSS=0.1510234056759996, ROC_AUC=0.647541841193485, GINI=0.29508368238697\n",
      "2400 [ 0.15093638]\n",
      "LOG_LOSS=0.15085295131181678, ROC_AUC=0.6493818351599245, GINI=0.2987636703198491\n",
      "2500 [ 0.15104485]\n",
      "LOG_LOSS=0.15093504734297694, ROC_AUC=0.6488212448811227, GINI=0.2976424897622454\n",
      "2600 [ 0.1511085]\n",
      "LOG_LOSS=0.15120516069191772, ROC_AUC=0.6464233041543144, GINI=0.29284660830862874\n",
      "2700 [ 0.15106605]\n",
      "LOG_LOSS=0.15089669915853385, ROC_AUC=0.6491826465490471, GINI=0.29836529309809423\n",
      "2800 [ 0.15087378]\n",
      "LOG_LOSS=0.15101131342115343, ROC_AUC=0.647474467504273, GINI=0.2949489350085459\n",
      "2900 [ 0.15100931]\n",
      "LOG_LOSS=0.15093373641688848, ROC_AUC=0.6486400704901358, GINI=0.29728014098027167\n",
      "GPU: 8133.396 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyHCXpBYy3CWphf4/5L6Dv3pCDv8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c212d9ef28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c22ea83048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import time\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "\n",
    "# for windows\n",
    "torch.backends.cudnn.enabled=False\n",
    "\n",
    "start_time = time.time()    \n",
    "epochs=2000 # change to 2000 for better results\n",
    "div_factor=100\n",
    "all_losses = []\n",
    "loss_arr =[]\n",
    "DEBUG_ON=False\n",
    "\n",
    "print (net)\n",
    "\n",
    "\n",
    "\n",
    "X_tensor_train= XnumpyToTensor(trainX)\n",
    "Y_tensor_train= YnumpyToTensor(trainY)\n",
    "print(type(X_tensor_train.data), type(Y_tensor_train.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "# CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.\n",
    "# X_tensor_train=X_tensor_train.contiguous()\n",
    "# Y_tensor_train=Y_tensor_train.contiguous()\n",
    "                \n",
    "# From here onwards, we must only use PyTorch Tensors\n",
    "for step in range(epochs):    \n",
    "    out = net(X_tensor_train)                 # input x and predict based on x\n",
    "    cost = loss_func(out, Y_tensor_train)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    cost.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "                   \n",
    "        \n",
    "    if step % div_factor == 0:        \n",
    "        loss = cost.data[0]\n",
    "        all_losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "        # Use .cpu() to move the tensor to host memory first.        \n",
    "        prediction = (net(X_tensor_train).data).float() # probabilities         \n",
    "#         prediction = (net(X_tensor).data > 0.5).float() # zero or one\n",
    "#         print (\"Pred:\" + str (prediction)) # Pred:Variable containing: 0 or 1\n",
    "#         pred_y = prediction.data.numpy().squeeze()            \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = Y_tensor_train.cpu().data.numpy()\n",
    "                        \n",
    "        tu = (log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ), 2*roc_auc_score(target_y,pred_y ) - 1)\n",
    "        print ('LOG_LOSS={}, ROC_AUC={}, GINI={}'.format(*tu))  \n",
    "        \n",
    "        loss_arr.append(cost.cpu().data.numpy()[0])\n",
    "                \n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('GINI:' + str(2*roc_auc_score(target_y,pred_y ) - 1))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119040, 130)\n",
      "(119040,)\n",
      "(119040, 130)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n",
      "torch.Size([119040, 130])\n",
      "(119040, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n",
      "(119040, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "LOG_LOSS=0.15364122035462377, ROC_AUC=0.6310116813939206, GINI=0.2620233627878412\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF5YnCuecc2F5onDOOReWJwrnnHNh/X8yie0BNcxEAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c212dc8e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.eval()\n",
    "# Validation data\n",
    "\n",
    "# trainX, valX, trainY, valY = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)\n",
    "\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "\n",
    "# trainX, valX, trainY, valY = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)\n",
    "# pca = PCA(n_components=n_components, svd_solver='randomized',whiten=True).fit(valX)\n",
    "# valX = pca.transform(valX)\n",
    "\n",
    "X_tensor_val= XnumpyToTensor(valX)\n",
    "Y_tensor_val= YnumpyToTensor(valY)\n",
    "\n",
    "\n",
    "print(type(X_tensor_val.data), type(Y_tensor_val.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "predicted_val = (net(X_tensor_val).data).float() # probabilities \n",
    "# predicted_val = (net(X_tensor_val).data > 0.5).float() # zero or one\n",
    "pred_y = predicted_val.cpu().numpy()\n",
    "target_y = Y_tensor_val.cpu().data.numpy()                \n",
    "\n",
    "print (type(pred_y))\n",
    "print (type(target_y))\n",
    "\n",
    "\n",
    "print ('\\n')\n",
    "tu = (log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ), 2*roc_auc_score(target_y,pred_y ) - 1)\n",
    "print ('LOG_LOSS={}, ROC_AUC={}, GINI={}'.format(*tu))  \n",
    "        \n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('GINI=' + str(2*roc_auc_score(target_y,pred_y ) - 1))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# print (pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (892816, 131)\n",
      "Columns: Index(['id', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
      "       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
      "       'ps_ind_09_bin',\n",
      "       ...\n",
      "       'ps_car_09_cat_oh_-1.0', 'ps_car_09_cat_oh_4.0', 'ps_car_10_cat_oh_1',\n",
      "       'ps_car_10_cat_oh_0', 'ps_car_10_cat_oh_2', 'ps_car_11_oh_2.0',\n",
      "       'ps_car_11_oh_3.0', 'ps_car_11_oh_1.0', 'ps_car_11_oh_0.0',\n",
      "       'ps_car_11_oh_-1.0'],\n",
      "      dtype='object', length=131)\n",
      "(892816, 131)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-74e0fd484777>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mp_test\u001b[0m \u001b[1;33m=\u001b[0m   \u001b[0mpredicted_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# otherwise we get an array, we need a single float\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mdf_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'target'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mp_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#     df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity)\u001b[0m\n\u001b[0;32m   4545\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4546\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[1;32m-> 4547\u001b[1;33m                       verify_integrity=verify_integrity)\n\u001b[0m\u001b[0;32m   4548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4549\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    205\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                        copy=copy)\n\u001b[1;32m--> 207\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m    406\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m                 copy=self.copy)\n\u001b[0m\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4830\u001b[0m     blocks = [make_block(\n\u001b[0;32m   4831\u001b[0m         \u001b[0mconcatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4832\u001b[1;33m         placement=placement) for placement, join_units in concat_plan]\n\u001b[0m\u001b[0;32m   4833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4834\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4830\u001b[0m     blocks = [make_block(\n\u001b[0;32m   4831\u001b[0m         \u001b[0mconcatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4832\u001b[1;33m         placement=placement) for placement, join_units in concat_plan]\n\u001b[0m\u001b[0;32m   4833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4834\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4945\u001b[0m             \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4946\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4947\u001b[1;33m         \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concat_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4949\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py\u001b[0m in \u001b[0;36m_concat_compat\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "X_df_test = x_test\n",
    "print('Test shape:', X_df_test.shape)\n",
    "print('Columns:', X_df_test.columns)\n",
    "id_test = X_df_test['id'].values\n",
    "X_df_test=X_df_test.apply(lambda x: pandas.to_numeric(x, errors='ignore'))\n",
    "\n",
    "print (X_df_test.shape)\n",
    "columns = ['id', 'target']\n",
    "df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n",
    "\n",
    "\n",
    "for index, row in X_df_test.iterrows():\n",
    "    rwo_no_id=row.drop('id')    \n",
    "#     print (rwo_no_id.values)    \n",
    "    x_data_np = np.array(rwo_no_id.values, dtype=np.float32)        \n",
    "    if use_cuda:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "                    \n",
    "    X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n",
    "    predicted_val = (net(X_tensor_test).data).float() # probabilities     \n",
    "    p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n",
    "    \n",
    "    df_pred = df_pred.append({'id':row['id'], 'target':p_test},ignore_index=True)\n",
    "#     df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n",
    "\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pred.id=df_pred.id.astype(int)\n",
    "\n",
    "def savePred(df_pred, loss):\n",
    "#     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n",
    "    csv_path = 'pred/pred_{}_{}.csv'.format(loss, (str(time.time())))\n",
    "    df_pred.to_csv(csv_path, columns=('id', 'target'), index=None)\n",
    "    print (csv_path)\n",
    "    \n",
    "savePred (df_pred, str(2*roc_auc_score(target_y,pred_y ) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476169, 57)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'>\n",
      "torch.Size([476169, 57])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:CNNNumerAI (\n",
      "  (features): Sequential (\n",
      "    (0): Conv1d(57, 342, kernel_size=(5,), stride=(1,), padding=(3,))\n",
      "    (1): LeakyReLU (0.01)\n",
      "    (2): MaxPool1d (size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential (\n",
      "    (0): Linear (342 -> 1)\n",
      "    (1): Dropout (p = 0.25)\n",
      "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (sig): Sigmoid ()\n",
      ")\n",
      "INFO:__main__:<torch.optim.adam.Adam object at 0x0000016ACFA7D908>\n",
      "INFO:__main__:BCELoss (\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after view, (size():torch.Size([476169, 57, 1])\n",
      "after CNN, (size():torch.Size([476169, 342, 1])\n",
      "after 2nd view, (size():torch.Size([476169, 342])\n",
      "after self.out, (size():torch.Size([476169, 1])\n",
      "(b.size():torch.Size([476169, 1])\n"
     ]
    }
   ],
   "source": [
    "use_cuda=False\n",
    "N_FEATURES=trainX.shape[1]\n",
    "LR=0.005\n",
    "X_tensor_train= XnumpyToTensor(trainX) # default order is NBC for a 3d tensor, but we have a 2d tensor\n",
    "X_shape=X_tensor_train.data.size()\n",
    "\n",
    "# 21      6            3         108405       21*32=672    torch.Size([108405, 672, 2] n_max_pool1d=1\n",
    "\n",
    "n_mult_factor=6\n",
    "n_input= trainX.shape[1]\n",
    "n_hidden= n_input * n_mult_factor\n",
    "n_output=1\n",
    "n_input_rows=trainX.shape[0]\n",
    "n_cnn_kernel=5\n",
    "n_padding=3\n",
    "\n",
    "n_max_pool1d=2\n",
    "\n",
    "DEBUG_ON=True\n",
    "def debug(msg, x):\n",
    "    if DEBUG_ON:\n",
    "        print (msg + ', (size():' + str (x.size()))\n",
    "    \n",
    "class CNNNumerAI(nn.Module):    \n",
    "    def __init__(self, n_input, n_hidden, n_output,n_cnn_kernel, n_mult_factor, n_padding,n_max_pool1d):\n",
    "        super(CNNNumerAI, self).__init__()    \n",
    "        self.n_input=n_input\n",
    "        self.n_hidden=n_hidden\n",
    "        self.n_output= n_output \n",
    "        self.n_cnn_kernel=n_cnn_kernel\n",
    "        self.n_mult_factor=n_mult_factor\n",
    "        self.n_padding=n_padding\n",
    "        self.n_max_pool1d=n_max_pool1d\n",
    "        self.n_l1=int((n_mult_factor * self.n_input) * (n_padding + 1) / n_max_pool1d)\n",
    "                    \n",
    "        self.features = nn.Sequential( # Mimicking AlexNet \n",
    "            torch.nn.Conv1d(self.n_input, self.n_hidden,kernel_size=(self.n_cnn_kernel,), stride=(1,), padding=(self.n_padding,)),                                             \n",
    "            torch.nn.LeakyReLU(),            \n",
    "            torch.nn.MaxPool1d(kernel_size=self.n_max_pool1d),\n",
    "            \n",
    "#             torch.nn.Conv1d(self.n_hidden,self.n_hidden*2,kernel_size=(self.n_cnn_kernel,), stride=(1,), padding=(self.n_padding,)),                                             \n",
    "#             torch.nn.LeakyReLU(),            \n",
    "#             torch.nn.MaxPool1d(kernel_size=self.n_max_pool1d),\n",
    "            \n",
    "#             torch.nn.Conv1d(self.n_hidden*2,self.n_hidden*2,kernel_size=(self.n_cnn_kernel,), stride=(1,), padding=(self.n_padding,)),                                             \n",
    "#             torch.nn.LeakyReLU(),            \n",
    "#             torch.nn.MaxPool1d(kernel_size=self.n_max_pool1d),                                                \n",
    "        )   \n",
    "                        \n",
    "        hiddenLayer2Size=int(self.n_hidden)      \n",
    "        \n",
    "        linear1=torch.nn.Linear(hiddenLayer2Size, 1)\n",
    "        torch.nn.init.xavier_uniform(linear1.weight)\n",
    "\n",
    "        dropout = torch.nn.Dropout(p=1 - (0.75))\n",
    "        relu=torch.nn.LeakyReLU()\n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "                                  linear1,dropout,nn.BatchNorm1d(self.n_output)\n",
    "#                                   linear2,dropout,relu,\n",
    "#                                   linear3,dropout,relu,\n",
    "#                                   linear4,dropout,\n",
    "#                                     linear1\n",
    "                                  )                                 \n",
    "        self.sig=nn.Sigmoid()\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "#         debug('raw',x)   \n",
    "        varSize=x.data.shape[0] # must be calculated here in forward() since its is a dynamic size                          \n",
    "        # for CNN  \n",
    "        x=x.contiguous() \n",
    "        x = x.view(varSize,self.n_input,1)\n",
    "        debug('after view',x)   \n",
    "        x=self.features(x)\n",
    "        debug('after CNN',x)   \n",
    "        # for Linear layer\n",
    "#         x = x.view(varSize,self.n_l1) \n",
    "        x = x.view(varSize,int(self.n_hidden)) \n",
    "        debug('after 2nd view',x)                  \n",
    "        x=self.classifier(x)   \n",
    "        debug('after self.out',x)   \n",
    "        x=self.sig(x)\n",
    "        return x\n",
    "\n",
    "net = CNNNumerAI(n_input, n_hidden, n_output,n_cnn_kernel, n_mult_factor, n_padding, n_max_pool1d)    \n",
    "lgr.info(net)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-2) #  L2 regularization\n",
    "loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    net.cuda()\n",
    "    loss_func.cuda()\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "lgr.info (optimizer)\n",
    "lgr.info (loss_func)\n",
    "\n",
    "b = net(X_tensor_train)\n",
    "print ('(b.size():' + str (b.size()))\n",
    "\n",
    "\n",
    "\n",
    "# Only on windows\n",
    "torch.backends.cudnn.enabled=False\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
