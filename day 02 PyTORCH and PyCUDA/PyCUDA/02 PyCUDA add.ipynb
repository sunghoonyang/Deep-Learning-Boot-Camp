{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## Using CUDA, Jupyter, PyCUDA and PyTorch\n",
    "\n",
    "### 02 PyCUDA add\n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"images/gtx.png\" width=\"35%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Ignore numpy warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Some defaults:\n",
    "plt.rcParams['figure.figsize'] = (12, 6)  # Default plot size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyCUDA Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pycuda\n",
    "from pycuda import compiler\n",
    "import pycuda.driver as drv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Make sure we have CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 device(s) found.\n",
      "Device #0: GeForce GTX 1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'pycuda.driver' from '/usr/local/lib/python2.7/dist-packages/pycuda/driver.pyc'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drv.init()\n",
    "print(\"%d device(s) found.\" % drv.Device.count())           \n",
    "for ordinal in range(drv.Device.count()):\n",
    "    dev = drv.Device(ordinal)\n",
    "    print \"Device #%d: %s\" % (ordinal, dev.name())    \n",
    "\n",
    "drv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple addition on the GPU: CUDA Kernel definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pycuda.compiler.SourceModule object at 0x7ffafa85f850>\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import numpy\n",
    "\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "srcGPU = \"\"\"\n",
    "    #include <stdio.h>\n",
    "   __global__ void addGPU(float *dest, float *a, float *b)\n",
    "{\n",
    "  const int i = threadIdx.x;  \n",
    "  dest[i] = a[i] + b[i];\n",
    "  //dest[i] = threadIdx.x + threadIdx.y + blockDim.x;\n",
    "  //dest[i] = blockDim.x;\n",
    "  //printf(\"I am %d.%d\\\\n\", threadIdx.x, threadIdx.y);\n",
    "  \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "srcGPUModule = SourceModule(srcGPU)\n",
    "\n",
    "print srcGPUModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Host memory allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.]\n",
      "[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "ARR_SIZE=16\n",
    "\n",
    "a = numpy.random.randn(ARR_SIZE).astype(numpy.float32)\n",
    "a=numpy.ones_like(a)*3\n",
    "print a\n",
    "b = numpy.random.randn(ARR_SIZE).astype(numpy.float32)\n",
    "b=numpy.ones_like(b)*2\n",
    "print b\n",
    "\n",
    "dest = numpy.zeros_like(a)\n",
    "\n",
    "# print dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Execution on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pycuda._driver.Function object at 0x7ffafa89ddd0>\n",
      "[ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]\n"
     ]
    }
   ],
   "source": [
    "addGPUFunc = srcGPUModule.get_function(\"addGPU\")\n",
    "\n",
    "print addGPUFunc\n",
    "\n",
    "addGPUFunc(drv.Out(dest), drv.In(a), drv.In(b),\n",
    "                                          block=(ARR_SIZE,32,1))\n",
    "print dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Timing Numpy vs. PyCUDA ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pycuda 0.00541090965271\n",
      "npy 1.00135803223e-05\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "rounds =3\n",
    "print 'pycuda', timeit.timeit(lambda: \n",
    "                              addGPUFunc(drv.Out(dest), drv.In(a), drv.In(b),\n",
    "                                          grid=(ARR_SIZE,1,1), \n",
    "                                          block=(1,1,1)), \n",
    "                              number=rounds)\n",
    "# print dest\n",
    "\n",
    "# print 'pycuda', timeit.timeit(lambda: \n",
    "#                               multGPUFunc(drv.Out(dest), drv.In(a), drv.In(b),                                          \n",
    "#                                           block=(ARR_SIZE,1,1)), \n",
    "#                               number=rounds)\n",
    "\n",
    "# print dest\n",
    "\n",
    "\n",
    "print 'npy', timeit.timeit(lambda:a*b , \n",
    "                              number=rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
