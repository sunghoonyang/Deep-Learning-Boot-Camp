{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 09 PyTorch Kaggle Image Data-set loading with CNN\n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">\n",
    "\n",
    "#### References:\n",
    "\n",
    "- http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "- https://www.bountysource.com/issues/44576966-a-tutorial-on-writing-custom-datasets-samplers-and-using-transforms\n",
    "\n",
    "- https://medium.com/towards-data-science/my-first-kaggle-competition-9d56d4773607\n",
    "\n",
    "- https://github.com/sohyongsheng/kaggle-planet-forest\n",
    "\n",
    "- https://github.com/rwightman/pytorch-planet-amazon/blob/master/dataset.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.6 (default, Oct 26 2016, 20:30:19) \n",
      "[GCC 4.8.4]\n",
      "__pyTorch VERSION: 0.2.0_1\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 0\n",
      "__Devices\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "import logging\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# No GPU ... ? \n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "OSError                                   Traceback (most recent call last)\n",
    "<ipython-input-3-64c0769366fe> in <module>()\n",
    "     36 print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "     37 print('__Devices')\n",
    "---> 38 call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "     39 print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "     40 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Torch CPU\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CUDA Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Setting up global variables\n",
    "\n",
    "- Root folder\n",
    "- Image folder\n",
    "- Image Label folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT ='/root/data/amz/'\n",
    "IMG_PATH = DATA_ROOT + '/train-jpg/'\n",
    "IMG_EXT = '.jpg'\n",
    "IMG_DATA_LABELS = DATA_ROOT + '/train_v2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Torch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "    \n",
    "class GenericImageDataset(Dataset):    \n",
    "\n",
    "    def __init__(self, csv_path, img_path, img_ext, transform=None):\n",
    "        \n",
    "        t = time.time()        \n",
    "        lgr.info('CSV path {}'.format(csv_path))\n",
    "        lgr.info('IMG path {}'.format(img_path))        \n",
    "        \n",
    "        assert img_ext in ['.jpg']\n",
    "        \n",
    "        tmp_df = pd.read_csv(csv_path, header=None)\n",
    "                        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.img_path = img_path\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "\n",
    "        self.X_train = tmp_df[0]        \n",
    "#         self.X_train = self.X_train.ix[1:]\n",
    "        \n",
    "        self.y_train = self.mlb.fit_transform(tmp_df[1].str.split()).astype(np.float32)         \n",
    "                \n",
    "#         lgr.info(\"DF:\\n\" + str (self.X_train))\n",
    "#         lgr.info (\"self.y_train:\\n\" + str(self.y_train))\n",
    "\n",
    "        lgr.info('[*]Dataset loading time {}'.format(time.time() - t))\n",
    "        lgr.info('[*] Data size is {}'.format(len(self)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         lgr.info (\"__getitem__:\" + str(index))\n",
    "        path=self.img_path + self.X_train[index] + self.img_ext\n",
    "#         lgr.info (\" --- get item path:\" + path)\n",
    "        img = Image.open(path)\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None: # TypeError: batch must contain tensors, numbers, or lists; \n",
    "                                     #found <class 'PIL.Image.Image'>\n",
    "            img = self.transform(img)\n",
    "#             print (str (type(img))) # <class 'torch.FloatTensor'>                \n",
    "        label = torch.from_numpy(self.y_train[index])\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        l=len(self.X_train.index)\n",
    "#         lgr.info (\"Lenght:\" +str(l))\n",
    "        return (l)       \n",
    "\n",
    "    @staticmethod        \n",
    "    def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "    @staticmethod    \n",
    "    def flaotTensorToImage(img, mean=0, std=1):\n",
    "        \"\"\"convert a tensor to an image\"\"\"\n",
    "        img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "        img = (img*std+ mean)*255\n",
    "        img = img.astype(np.uint8)    \n",
    "        return img    \n",
    "    \n",
    "    @staticmethod\n",
    "    def toTensor(img):\n",
    "        \"\"\"convert a numpy array of shape HWC to CHW tensor\"\"\"\n",
    "        img = img.transpose((2, 0, 1)).astype(np.float32)\n",
    "        tensor = torch.from_numpy(img).float()\n",
    "        return tensor/255.0\n",
    "\n",
    "    @staticmethod\n",
    "    def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Torch transforms.ToTensor() methood\n",
    "\n",
    "- Converts: a PIL.Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformations = transforms.Compose([transforms.ToTensor()])\n",
    "transformations = transforms.Compose([transforms.Scale(32),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Torch DataLoader Class\n",
    "\n",
    "- Will load our GenericImageDataset\n",
    "- Can be regarded as a list (or iterator, technically). \n",
    "- Each time it is invoked will provide a minibatch of (img, label) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:CSV path /root/data/amz//train_v2.csv\n",
      "INFO:__main__:IMG path /root/data/amz//train-jpg/\n",
      "INFO:__main__:[*]Dataset loading time 0.198098897934\n",
      "INFO:__main__:[*] Data size is 40479\n"
     ]
    }
   ],
   "source": [
    "dset_train = GenericImageDataset(IMG_DATA_LABELS,\n",
    "                                 IMG_PATH,\n",
    "                                 IMG_EXT,transformations)\n",
    "\n",
    "# train_loader = DataLoader(dset_train,\n",
    "#                           batch_size=64,\n",
    "#                           shuffle=False,\n",
    "#                           num_workers=1 # 1 for CUDA\n",
    "#                          # pin_memory=True # CUDA only\n",
    "#                          )\n",
    "# import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train Validation Split\n",
    "\n",
    "- Since there is no train_test_split method in PyTorcj, we have to split a TRAINNING dataset into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FullTrainningDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, full_ds, offset, length):\n",
    "        self.full_ds = full_ds\n",
    "        self.offset = offset\n",
    "        self.length = length\n",
    "        assert len(full_ds)>=offset+length, Exception(\"Parent Dataset not long enough\")\n",
    "        super(FullTrainningDataset, self).__init__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.full_ds[i+self.offset]\n",
    "    \n",
    "validationRatio=0.22    \n",
    "\n",
    "def trainTestSplit(dataset, val_share=validationRatio):\n",
    "    val_offset = int(len(dataset)*(1-val_share))\n",
    "    return FullTrainningDataset(dataset, 0, val_offset), FullTrainningDataset(dataset, val_offset, len(dataset)-val_offset)\n",
    "\n",
    " \n",
    "train_ds, val_ds = trainTestSplit(dset_train)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=False, num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Test the DataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:i=0: \n",
      "INFO:__main__:i=1: \n",
      "INFO:__main__:i=2: \n",
      "INFO:__main__:i=3: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAABzCAYAAADXAHYWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f141450c290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagesToShow=4\n",
    "\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    lgr.info('i=%d: '%(i))            \n",
    "    images, labels = data            \n",
    "    num = len(images)\n",
    "    \n",
    "    ax = plt.subplot(1, imagesToShow, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    for n in range(num):\n",
    "        image=images[n]\n",
    "        label=labels[n]\n",
    "        plt.imshow (GenericImageDataset.flaotTensorToImage(image))\n",
    "        \n",
    "    if i==imagesToShow-1:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:i=0: \n",
      "INFO:__main__:i=1: \n",
      "INFO:__main__:i=2: \n",
      "INFO:__main__:i=3: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAABzCAYAAADXAHYWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztfWmMbdl11rfuuVNVvX5TT2632253Y6cRseLgMAgcESKi\nKEgGpAgJMAgiMcgoSJGSCIQS4SALEMoPSwgsJIyM0sgQiRCZICAKIQkBwmQSK46J4ygOnbbd3ek3\n1qu6w7ln82Ovb+3h3td55e7ct1/X+qTSqXuGffbZ+wxr+NZaEkKAw+FwOBz3G6P73QGHw+FwOAD/\nIDkcDoejEfgHyeFwOBxNwD9IDofD4WgC/kFyOBwORxPwD5LD4XA4msC5/SCJyIdF5Pn73Q/H3eFz\n1D58jtrHgzRHe/8gicj7ReS/ishNEbkmIv9FRH7PvvvxRkFE/oeIvFtEnhGRT1fbrorIvxaROyLy\n6yLyZ+5XP8+CczZH3yki/0tEliLyifvUxTPjvMyRiMxE5OP6/NwWkZ8XkW+7n329V5yXOdJtz4vI\nl0Xkloh8XkT+4ldzjr1+kETkIoAfA/APAFwF8CSAHwCw3Gc/3iiIyATAOwD8CoD3Afh0tcs/BLAC\n8DiADwL4mIj8rr128ow4h3P0JQAfAfBP99y1rxrnbI7GAF4A8IcAXALwfQB+WESe3m8vz4ZzNkcA\n8HcBPB1CuAjgjwH4iIi876zn2beG9G4ACCF8MoSwCSGchhB+PITwGQAQkWdF5CdF5FUR+U0R+eci\ncpkHi8gXReR7ReQzqnV8XEQeF5F/p9LTT4jIFd33aREJIvKXReRL+vX+nrt1TER+v0ozN0TkF0Tk\nm+7her4WwC+FmO7iG5BNkogcAfh2AN8fQjgOIfwsgE8B+HNnHrX94tzMkV7nj4QQfhTAq2cdqPuI\nczNHIYQ7IYQPhxC+GEIYQgg/BuDXEF+KLePczJFe52dDCPzYBv179t6HKzW0tz8AFxEf/H8G4NsA\nXKm2/w4A3wJgBuBRAD8D4KPZ9i8C+DlEjeNJAC/rwHw9gDmAnwTwt3Tfp3VQPgngCMB7ALwC4I/o\n9g8DeF7/f1L79UcRP9Lfor8fvct1fAeAGwBOACz0/x7Abf3/ndqnk+q47wHwb/Y55j5Hd5+jav+P\nAPjE/R5/n6O7z5Ee87ju+9z9ngefo3KOAPwj3S9oXy+cedzuw0T9TgCfAPAbemGfAvD4Xfb9EwD+\nTzVJH8x+/ysAH8t+/zUAP1pN0nPZ9r8P4OM7JumvA/ih6tz/AcCf/y2u5T8DeC+AtwP4eQCSbftG\nAF+p9v9LAH7qfj8sPkc793tgPkjneI4mAH4CwD++3+Pvc3TXOeoAvB/RtDo565jtndQQQvhcCOEv\nhBDehqgGvhXARwFAVdJ/ISIvisgtAM8DeKRq4qXs/9Mdvy9U+7+Q/f/rer4a7wDwJ1WFvSEiNxAH\n9Yl6R4lEhRsichPAHwDwUwB+GcDXALguIt+lux4jSkk5LiJKFk3jHM3RA4vzNkciMgLwQ4g+2e/c\nce7mcN7mSK95E6J74m0APrTj/K+J+0r7DiH8X0QJ4mt11d9B/NK/J0Tn2J8FIK/zNE9l/78d0Yld\n4wVEqeFy9ncUQvh7O/p8LYRwGcBfAfBP9P9/D+ADetxHddfPAxiLyLuyw78OwGdf5/XsFW/yOXpT\n4M0+RyIiAD6OaL769hDC+nVey97xZp+jHRjjq/Ah7Ztl95yIfLeIvE1/PwXgTyPaSgHgIUTN4qaI\nPAnge9+A036/iBxKZLd9B4B/uWOf5wF8QES+VUQ6EZmLyDexn3dBzjT5egD/O98YQrgD4EcA/G0R\nORKRPwjgjyNKec3iPM0RAIjIWETmiKYGtjt+fZfz24vzNkcAPoZo/vpACOH0dVzD3nCe5khEHhOR\nPyUiF7TNb0W81v941gvYt4Z0G8DvA/DfReQO4uT8IoDv1u0/AOB3A7gJ4N8ivtBfL34awBcQB+cH\nQwg/Xu8QQngB8WPxNxGdgS8g3iCvNT7vA/BpEXkYwCaEcH3HPn8VwAGiQ/KTAD4UQmhdQzpvc/R9\niOaPv4EopZ7qupZxbuZIRN6BKKG/F8BXRORY/z74BlzTbyfOzRwhanofQvSVXQfwgwC+K4TwqbNe\ngKgj6k0HiXEKv4boWOvvb28cu+Bz1D58jtrHm2mOzm3qIIfD4XC0Bf8gORwOh6MJvGlNdg6Hw+F4\nsOAaksPhcDiagH+QHA6Hw9EE9hpv8c6ve1cAIkcQ2T+i4WCSfR43Ia7cbOJOs2nc2K8HPSZuH491\nv6FqFIBonNkwxHXdiPvG3zRX2vl1GYJstREkFM2PuLOumMzjUK6XkeQyGXXWxriL+x6frGJ/dP0L\nv/iF1xsI94bj937zNwYAGOlYLdYxBnGk1z/KJulktYn/cB5tPjlncUxWfbxijv/JMsU1jrvY3rrX\nceziuG2G2Pagc3SobSGUcwgAmxD3nYzjsUu9Rzjucz22D7per+FkubE2gm6bz2IbvMpP//R/a26O\n3vvN749zZPdrHAuO1Wqdxibog9GN4xUFHbfxNF4nnx/u1+tcjUZpnsc6rotFnLfxJG4THUdB+Wxs\ntK2rlw+sjScuxqQCnR7D5/uVG8cAgOuni7ijPjZDXz6bANB1nLfYj0HfDZ/72Z9rbo6+4Q/HORr0\nYefzRAzZ/cux5rX2el1i2/We5/uqem8CSGOvJ+SzsO7jPc53Wr8pn8W8XxOdV95P7OGF+Szuq21c\nPznV82sbWUfstuEqvf7/+Z9+5p7myDUkh8PhcDSBvWpIXUdJK2oKk0n83ak2MRTajUpyo1J9oYQ3\nVQmPYqKoZNBlX2sKIROVDvtNJdFXWs6wQ/Lg15/SGaVQO5Lqjkp0lIh604MA0e/+paM5AODG7XaD\nzXuVqDqVsEwj0us+XaUwB2qP1HKIEUoNdKrzTOl72GRzhHLcZFxqs6r8mLa1VglP0vBirUnvl6qx\nCY/V05yq1sp5nc5ifydJicUmxHUrbaPrmhO6DbwOWg8Gmgf0ug9maT56HWteDbULXt+I2o9qVZSw\nuyyLjRonMFXtcaP3Oq0GYaBGGnekxD9kc1RnxRnpBM70/Js1NTPtr76ZZEjH8XqDLhueInsv1NrP\nZjNs7ct3ygiVxsF3z4jjzPWlNSFu1LZ0Hvmc6FCBj6hUliSOKQB01Ja5j57/1slSr0X347uQlqb8\nva078RpGZ1R5XENyOBwORxPYq4a07un/KW3Q/MKOsy9+30epdqi+/ObTIV1dd6BUPGQ0dkpw9GGY\n7ZUStLZFrYrHbrI2RiPaslUbEGpKKhVO4hBSstwlCW16iktxMZ22myrN7NS8Hh3fhUqwuX9tpirG\nqKO/r5SUB5T+vdrvBySJaK5i+GqtGpj2YzanH0p9SrSvZ6JUqHwYc+3XajXkqzOU8w4kH9miL++n\nFmEaCLVF7Ssl3PU6086pcVByVWsEL900U/utkm0mfJvW0uuy8qcSK9VEqV0P2TNgzys1Bp2Dw/kU\nADDVZ/9U53885jsi909QM9C+hnbniFfe2bhyrnQedhxD39yaPkBzIumc8JmYTgAAT15NxQReunYH\nALBQC4YNtzYiobQ8sD+5r9Bee9WwSvWb+9W+97gxLsySJGfTeVxDcjgcDkcT2K+ozq/0hD6jiF1f\nRX65yX7ih3aE0j5NCYr75f6MFaV6suzMkErbbKVVGVvs7kw9u5RK8qD2R9upjDM7PqV7bcL8Xw1i\nqRLqsIl9JOtss4jXt8psztRelmv1u3BDR0ZX/Ckj2qvjiumkUG8ApPGj5Ea/02Qcz7FYqe8jlMcB\nSfrmvmQpnSzitcz0GqiBr9WX2GcSPO8B3iPScMA4NQ+TunX9hIzFVaaZ0M+krEVqp2YlCLu1nfx+\n5/9mQdDfc/VVbcwnSIbkUCyB0j+cg+PNe+L4hM9RRd1E8jlPVas6UdZqk5CSJczrpFZO9hsABL4z\nKvdSV63n62umVpkrR4e278vXol+afiW2PxrTN6rsX9VeOf85Q87ef3qe2l9uu9Hnxddptm2w61VW\n31Bd1G8B15AcDofD0QT2qiFRYiJzrrZjDxkzjRISiSWMkxBK37RV1n6LTBAbMaZlo1K/aUraZigZ\nSMmEmn2nS5KZ2YSpdZn2xUZqgysyLY4xS5PJ1j6t4HAW+7ZUf8B6EwdgPtdBW6YBHqeLBpDYV2T4\nJM2zlMZzoYlSPdl8U5X+TMJSbUaUBTeZxPWrdZIwOfe9agHUrudzXarP7lQ1ps3A9bmmNhTXMNox\nj62Amib9bRyrtWoq3ST1nVpqMJOCtjGUUu5U5zcoYzEXe5M/tNRyeh0r+oxERfkuxN+zjMY4Fj50\nbL9UdbnZnkVzOW3Pw0bviXAXrasFWIwjLSnmcNFFfl36fFC74NiEmplYMdheuXnHti3WKz2m1GZH\nld+cVgF2Z5RRFaV6L0ulIVVuwOTPz+bBrnvgtrPBNSSHw+FwNAH/IDkcDoejCezVZEe1NVEfaZYr\nAykBoE8HxW1GDad5oiIRVKYIIKn7IwuULGmxpK/SWUqdNFdBh56pOOJQ0ew3Hld07xEduQxyS0jk\nCTbarqnB0icZZbs0iXZd6jtNYJ3RvnX8LH0I5zX+HOu855yG5apMbWOqvlqJNkZPVVOdWuqGzJzR\n0YYQyn1psj3RlDc0xU6Ndp61YayZ3eaSlnD1YgywXi7iYJAqzR5PMyrvBgx9KOnsNDWbCVx/HyoB\npMtCMKacGxJ89NljkLSlJ9Kb5+Agmn0fvpCc7gxOT8GUKPpcp0EajUriUzyPkip6PoPtkoNGFh5S\nm4B3Pfu85vK+FCNAxFG4oKbni0cxlc/1mynAnsQihm3QHXGgJnBaSE/UFM/3qEx23Odmmiv1FUsR\nNRS7lWbVKrjWTXYOh8PheCCxXw3JAhirIDGjNWaBsUP8ko9UgqNf1YJrdT9qMwzKm0wTYWBTSW6r\nKrHg2KivpaMvl5wteFe7viG9nGk+mPjQqK/lteUHM0Ho0aTdwNjFkul34m9KaUz7g0yLpZRF53Zy\n2MYlKfqU2ricSJpn5VCAFIW1JdWMjVGyNho2NeaMDhxqeTuUc9N1pP9D29RURnkaFwZdKtHhdHk2\nuuo+8dZLMVHp5oKSSKoULnlA6s07MWnpRok0DJ6ls5uaELVcUoqn2T3K50Uq+k9vCVn1ntH5PtBw\ngKP5PGsjLo81bZgRirTJMQN2dX9aL3L6ud2Duhg3HD5hGl91G9GKkCcpplpg5C6+a3pNbKyNkQB0\n5TBqnos7KY3XUufrRJMhM82TpXeSkqBAMkMeeEzrTopYKfWbwYgw5XNWxMXyFV8lrr5XuIbkcDgc\njiawV1GdX36eVKT8Z5zbMweVYq2UQJmOxCR3ajdV+pq4UpeUlAPTp8TVKbhVd6dknzdRpVM3jciC\nEis/FbWCTLKjhLnclGUSmoSO60ylTybjrBNnAkl7GU/itZ6qdkV7OWmsE5XKLfFskZpJ7eR6LMdq\nyvQzVSp8Cmc5pZhBgANT7ZtEr/3Te4f3CunheYqobmC6o1pKbA+8HiYoHZtcqdeXPQOT7iguLRVP\nXJ8ou+CKYn0u2pq0G8oHZTbhUv0U4DnUarFOErwpr1V+Gu5Laj6DqOnrmk22J2LNBL/DGcXvPWJU\nsdz5OrDxzgOvSfu2WJa4oAVizBRdOu6Hqu0++8Qj1sSrt08AAJ//8isA8rCJ0pkj1Xss99vTghWq\nlEy2zxYdnXO1Heie/Epn8yI1/Ng5HA6H4zxhvz4kpmWhtE3JVf1FTIIKbKc2J0PLpCL6gQLZOxos\nmKXkoJRdp7owNl2VAJCJCEOWw8MC2ygNsAn2j+w+lm2gsTyTMlIapHjMMivh0BqobdC/NjUprWRa\nASktiCSKVPGbBb3IiJxWxfcAWJSySWyVq4rjyTHjPXLxMPkKF2T3VemkrNgfmIpffS7Gskzd4D5W\nWLHO49IQhsqfZj5Z3T7u0mM9tsjIYlHXT0vS8c7A7uo3eNqyH9SgBh27HpvsmFFxrCVoZaLbEVPr\nVCaJ7DliwtV+LfWm5lAXL+T7gZacXAuxEjf021b+ncNZnM93veVhAMDlo1j4MA8wv72Kvrl+Xd7j\nlgSgshbRhzRkqcASWa7WlPSYYmtm6cmUoHWVzmq0i8X3GnANyeFwOBxNYK8a0qiWFiylDHR90hws\nTQYlCpbQNl8NUTKAcv8M2T9k6nWjWj7Uc/EQk/Qy5oml+C9LZVgajVI5SOURMrGyr0pTNJy30+zE\nlHRow6c0nCfJtAJxFTOO2qyo72i5Us1wTR9TfsKSCamuHNOqLioNb9LF5UIDkRhPASTm5YRF5yqp\nkMlGu/LEKf4MSSOvE+G2iDpGqrbWFxpNpUVx74H3evLOxd+0Hkj+hPEZZFv1mSOGUSlZF93gc4Ny\nG5ukZtqRgbnjfhtJ+YwPZ0zcuU/Ys6Bxe4Pl26nHcHtV0phoHYjX+cqt6Ce6o/f+q7dT6qDbp8ui\nDbPs0J9ax0NV1oSiH5XPyCxIlar85JVY/uI0exZfvn2s59fTbM72ILmG5HA4HI4msFcNKZDlpp9P\nFuEbWcG+9AU2abYS8FJCVn551cdkCTaT1MSYC2OxlPkljUFHS7fZwLPgAfYppdKn5CbFwdyvtsnn\nK9n31dCuD4lpFlgkbD5hLNFma1ey51gZnhrTTLNYsFaEEvXMPzWfpduumkYbe84Rs0GwZMdStaF1\nllx1qnN/Qf1KPA+XnBvLI1kVKQNg5aFZuoIlK1pEYKxbKJ8RY4vuOsbKtJT72F1aTUTeRtK8SmZW\n7coiLDFyIRxva01529TEL2hpieuLGD81zt9QpZJ35hiXfUKqe43via2SN8j9etSq9BBLVhwPfvH6\nraKN5Sp7JmuzS60Y17vVzwS259MYgoyd0uf9ictRM7pyITI4D6bpfXZN2X4DmOj4bM+Ra0gOh8Ph\naAL7TRlAzajixo+UMJXHuCRJuZLsrNw4c9mVzL0hY9mNqvK51HIY8Uzz5mBlMaipZceZJEENSPvF\nXGssKcE4KR6Wl1KnVmXBCO06KCZk01Uai0lJ2RyZRFf7Dmh71t9W0qHbtkWzuTsLFhBTnxW1SZUO\nNyuyLXW8D9Kty/apPfXGutN9J2XRsmFd7gcAVy7MdF38PW+4zDwzYCR1o1R7hloszjfW8TBbOdZq\nH+3WpoyxV93HQ6265M9ADWpi6vdTqf+RS5FBdmcZWWPM3AFkvo2uaKJJrJbMqxh/d1a3ZlsDlcov\nzvvSiuzVZeeNNZz5qatnbDBrD48h607K/uSGj6rUDsz3Xb6DmceT+Sf7LKuJud/r2Kp7hGtIDofD\n4WgC+2XZkUHVk/WkX1hm7s6+j52x2iJq31FXZdNlnMom05BEJWPLJI0yLqkn+6oq+pdL8JYPT9vo\nGDehI8fTrUyaQdG/uK5k8Pd9uz4kjncqtazaBjMtSxpfBuIzJmg2jcecqtNoyRLyuj8FukUWwT+z\ncvbavsW2aD+6cuyseGKm3VDaq0tsWw5BZerdWJdS6ywrd2/xZHrotVsLtI6auRZ2SN+1jlIrO7UE\nm1hZ+VpqwOX5Uj+k2k/XF2rAdt/qqwGAmWqmj12O/okvXbud9a06YkfxvlZA3+fMsqeX77OiuOBd\nlQhmR1FLhFovmNOvmDsqzfRXU5thBpuh9NPXMWT5MWaFsoJ95fz+xqs3AABLzZuXF8tM2Rt47N2u\nbTdcQ3I4HA5HE/APksPhcDiawF5Ndp0FTMbTMvmiUbYzc9t4VhaWoknFllWhr82aTvGMZiilw5Rm\nAZrhzOk9rU0+dw+4o9OwZ0GsTbkvzY65Fs4CZpYUs+Hkqgxepm1lrn1d01KWmcpYIM2o8bppyfRD\nOs8LNacOA8sUJD2epg2aSY+0dMGpUlqnaqawYoA0iebZTys6MrdwnG+frvT8arIjcSKbOm7jfM6m\n7cpqyXRWPQMDk8emCyMpJKA0mbGMyqgiFdDUnAcRT6w0ROWYt+KZ0N/s4LadRu7i3DZTvC75/FzR\n9Dgh446T6HBT5zO0O0VGyTYCAoO29YKnWdJYSwyg88YIi7rAKDNuHc2VBTZN57vFe7zKompmTiYP\nDtULdYfpcGIFLPUYfbC7CYljsZ8vXb+tp8pISkzAOjipweFwOBwPMPasIelXm+WMl0pvBCXqpDlY\nKXBKYdRqrHZESRvlsZOs9DJLo5tUbxRIpRDTSUhty0pgZ/Rz3cbEnGJJVUuJR6pA3lwysHIMQ6mZ\ntQhK3yQzUNiezzSNSVZUmtrEZqNajGpCI3NoxjaYoHUDJlfdvn4SE0jRPiFJxYrqUXJXyn6Rwije\nP0y8ytlLTNuSAruLNcw+UdqThjN33lrGNDGjSmslmWSxSaQRXgbTKnVVEDrH9cIkitskjZxosk4A\nOBliu1YaRNM4MVmujZQJ1rUUvivVV4TdClLeMyy58LCSGwDgUh8L/k1uxJQ5NzRdTosI9qwrOWhd\nlYHI+QhMj2YB9Ew0i+IYPlcHU85VSjB864TF/OJvajWpqJ6ut3Rtej/kKokFNJMIUaU8Y6gLwyr0\nsC6Lrq0L9A13Z2zshGtIDofD4WgCe9WQNqQrGjUwrqcdeyj8E3GZFI2Srmjp6i0NjG4vOK+qPenP\niaafOV2RNhnXU2rsTZrIbaIl7djKYlS20UkVkNZJLjWolsXrrvmrDcHKGKv0O1efDrWcVRao2Kux\nm9rMpPLNrHScWTYA5uPIfIVMoqvjdec0Snocs5W2zRT8x6fqS8qkMvp7GE5gKYzUxs4+M9h1sWYK\no6RNc85JYQ1yNslun/iy2u7NJ8mxoISblXHhSIeBZT54j5elQ1hCvA4mB4DTNVMwxWNOR0ppHkcJ\nnQXjxkzCuau0tS5rqjrRa7lu+ocuHc2KcwCA6IP82JWHAACXLxxs9bUVpERj+n6yd1/EySLdXwxG\n5/NjeVi5g/6zUr/Uy6sT3S9/T8X/LSi8CmGxkjBb77HU50TXLzVc7sLni0mSmbIrf1aYXsisFK9B\n9N+Fdt+MDofD4ThX2K+GVGkg9EGM1F48zQMVuW9XfWHrwnhh+0tft2Els839VLLpzG9g9Z1z7ab0\n+1j2ktpnVNlKcw2Kfhj2dVpfU0NgoCrZhGRAWvHE7DKPNOB0VUl/Kw38tfIiVaDqkPuQVEnhcLKt\nmrnFchOcsy5L2kj/4XSiiVdtzqDn01NNeRKdy0wjr2+fPKV+a1irpLySMh2MBVDmjoGKkWcLHZSF\nMtdeVP/T1Py4WcAkz1Pd80tNErxWBuRDs6jVzDVqvNaCstNvb9ENx6ohLUNsk8lWAeBINTFK+9Te\nW4SlGmMyYJTsuqIUCt8t9CGxAoeVRKFvu3w/FUX+OPeqpY7Zlq5fV+naqLnkHOGg+nTfl08D0w5R\n+2KiY95nhU/ctKySeXuvcA3J4XA4HE1gvyw7sq2qRJ20W4+67e+jVDbQ9XpdHNtVhfzysKD1ppRy\n6R+wmAvGRVFzokSdSQhk7fWUJSh9V+k0eE2JPZRLDbTTb5fIaA5SztHJOkqsLFAohWwb/z88qON9\n6Icq/WrUkGeTdNsxJiilDopjQ+1rQc1Ih5P+qDyB6LpKUUT2JJNT9n2pmR1Y4tSQtRH3PVC/0rBp\nV1abaB953eYPsEyaaV+zBrCIoY7fwaRM2LnWYxkzloPS/Egl45ElFtZ/dPuMPhA9riixUCXoNH8F\n/SV6f/EZoS8xtzws1M9k8TJnLG2wV5DFSIsDGYrULjImL7XXrtI4qBml0KGS2Zv7+w7UYXo4j1rq\ncsnipHzX0a8XlzduxUJ668yfy2Cw9HrS53hU+h+pRFv8aJGgin5yrnCWncPhcDgeQOy3QF/FkGNW\nBUoPfWaL5NfXiuhZaXCVIvTDzmhtSt95jAs/zjyPceMHnoMsErKTNB4qk+At/gilTbQzFgtjayjN\nkMufrlvAbVLs0yLqch8U5CiVMfIfAEYqUW00ZEXDVTBVSXnNwap8dJMsywKZh6EUtpN0bbZxaL+q\njiHzN9Ylta2MdPxNDfkhLV2xXKd5IBNvNFYtat6u9M1yG6agsHyBDuImk3rFKFt8xuI+JxoDmBIP\n1+zV7HzGmqSFIW6cVb5fshjpO1xnbL8towAj+lFK5ZxDagcnGl8DACtqaFbiu11Lw5EmHK7Lftvz\ntaOGOTVdW9qtTo1I99d5nkwSA/E9X/MMAODSQxcAAF9+6VUAwNNPPQEgYzFqAb3P/PKvxjay7Dj0\nJ47UZ7ip3lPj6lr43OWrjTFtfT+bzuMaksPhcDiawJ4L9Em+wESDjagF5SWlVytl/agUwNxbY5WS\nmLuOUi81qtw2S0mCcS/MrcasD3Y62mStDMU2+8rii1SipG/JmGRWWqK0++bXy1V5/EBr2FRj02tX\nx6M4hnlp7+TfIcsrjs10Qo1UY3r0wllaYJn5KWg3Z1YN7rtQaZxMqkH7tayyMcTzl9oxNTCWF2HJ\ndJY5oeReSHZqH6ft/ahhBhfvJIv/MP/A9v27xbLjM6gqZ6B1wooW6nNWjE0ZJ8OS2itt62HNO3fx\nMC6X+mxuMh/ugC0VqbiWsWXq0Jk9rXYDsGbRO7IKG9ZiDw/ie2uoaGYilbYDJKauaUhDsSG9L8lu\ni8snHn3YmnjmHU8BAJ5717MAgFdeeQUAcPXKZQDA9Zs3AQAvfuVlAMBLr0YN6nSRsl0c34klV45P\n4+B3ltqm9NGSC8B3nWRTW4exeS47h8PhcDyQ2KsYSLsiJVqychiLIkOSeMiQYn4uSk6WsZlF2Yxe\nX9rIgZyVgmI5mZGxR0dUye/P/VBMjWdajh7Sh20pO/YjYpyJQBbvxMzKDWdqSAw5tdPTAbOj+Bsv\n0aRq5gZkfBmlb5USWZgvl5oGlbbnU849M7+rpmbaDDMP98W54nnI1CvjoRKzq7wmnj3PLk97+IWD\nWdHXlpGITKV2mWvgzPM3ttQnKPflrc8x1Lla5U5QnU+uo090rXFIbHs+jVoBn8HCElCxUNODo3Ni\neQ/VT4TqoUXG3tO2qNU1iSoHIy+HcV5XD1OWieuLqJncOo7aCn12ljtQrUTvfHv0Bz3z1FsBAO9+\n5p3WxqOLz8lJAAAOJklEQVSPPQIAuHzxEgDg8UcfK7oz0xgxZj557JGr8Zy3j9M+ms9wlJLWAQCO\nldnMee0tJlF9tJk6bUxlez+ezRrU7pvR4XA4HOcK/kFyOBwORxPYs+e2pFDTdKNZQgrz19Qc4Axu\npBmAjmutVV9mMymKdm3WNO+RQs7AM6U19gxI0/1ZiCrjvHZK615tWEgORd+ptlZxshbwma3KTHft\nygEMPOUYUOWmCr5YZrTvjsF+ZdCdpRvSueN1W6LHLBkjVXyed5NssADS/Af1nD5Ek9oq0YFTuYWS\nDpyCaPUcLL2ge+dB1LyfJpqodZFRwluDFalMjBsA6Xry5yilcFFaO2/bdUkx5nxbUHFG7zfHPJ9X\n0ux18o7NMR6qxfYYBjNblxfBa6G51wKhMyNxHXRZF8dsCuy2lcuJi6X2+ZoSCIBE4GGCaJK9+Bxd\neigmk33u2acBAE88/igA4CAz+x3MY2kOM09r6ArdA1evRBPd7eNoopvuKBJ6oM/WaBPPd+uGBs+u\nl8U1WejNDmtccneUVPZ7RbtvRofD4XCcK+yX1MDEmF1ZcgCWFiiTvnXbbFIGtaYgQG3TSjGXaYgA\noBtVwXcqdllS11GlDdATmX356cgj7bgzZ7rUuwLIiwymLVbGuFajWgTLPqh2uZUINi9XrEPBfbtu\n91zJhpqR0sIz7fF0Eed83ZeSFSV7EhGGSoIOecaTyoE6NnosKfplmvyUaijNA7XnOycxOHDTtyt9\n01rABJ4WoFgRfAAkSnhFLeaxfZXMdlRpxkAKmq1BRZcB7SeLOHa9hQ5sxz7wmKR5l0HNpDRPjLSU\n5qFT5/lMNYiWNaT0TtHrtgD/uDzONPxkWSjfbRwztvWr/+9FAMBvXr8OAHjyLW+xNo6OjvTYeMxc\nCTt8B/ZK0jm+w9IVfPclTem2brupJIubqhkJLUZUas3SE1EmYy0137MGuLiG5HA4HI4msFcNKVF3\nmX8nLigFrbKAyYmmsKdUZHZLFYpo405xsCpp5eV09Xubgj3LwEhLT6SHzGal32oXrJRBlVLHJECm\nqVkl6Y3SNssyt5xctU4aayln+u00IcoGtQJt1DhCRfXk+FduAwDAdEp/U1lKgQX5mH6IQbgrakiZ\nVMYgVibitDT+ZDoz8LoKO+jy9EOhvN5pw0GX1CYsnZbFNey4r/RWZuBxKhlAdUrHrNJqCsq2+Y5K\nqjbPRssGk+turHx26o8lSb6LZYEaxEOHkXrcddGPkRdznJrGq5r49tU2A6msMlY8kb/zBLjC+1Et\nRUM5Fzdv39Hfcf2t4xi4Ohql1EF9/1kAwGOPRvr3pYsXizZv3YpFHT/3KzFl0EuvRi0rD4z9yivX\n4vlVu6LloatSr6WwiVK7BrIwAku15j4kh8PhcDyA2KuGRMlOxqZeAACWCwa/5t0p08GkgM0ywWKK\nr9uWvCzYb80vPlOyczvPpL4Fs0mnrzrPM9f07tTiqOUw3pD9Mslo2Gajsa2Wk6ua1Es/mymAeg2Z\n5EybN1Pz3D6N0laokmtSc+lsvBOojbItprq34EqWJtH9GSCdp82nlsXSyqdaMG6sWraVptdr4Dmp\nhQFZSRRq7e1OESYzvd4F/QTUmPTey7THrvZLKMRufmVCcr7HvI+30w/x3qCfiedlOQ8yJDneeRV4\nU+JMWy19DMYO03fDQzLV/XZofXUurgaRGGh8f8VffMWss5RCvH+F7wlV6e0dY/RJZYDqc/YLv/QF\na4PP4HQamXK8nw+0HAXfR1yyLMaNmykwdrVaaY/re6Z8B9dVTrrcIlKzns9oDHINyeFwOBxNYL8F\n+izVfcTa2FmU1pLUYH6HmglXumwSk6uKl0F2pjrWoqs0lU0lQeewHrGoX1dK/+YPGsh4qg9Mmpil\nuGlZ/K400bkmU11ZrETIdlWbtvkKynlkOQRqjSxOdmeRJd3UQw8Px/mhWFlaH/ZHNSgy6TLthilk\nlnY/6VxYmYLS58Lfh7Nkg7+jPiorRXJW0W6PsNitqqAbtbs+Y6vSj8pnL6UM4j+6nima9DjJNGGO\nSVXJwhiwB5oyyHxapUCv7XJO2I+K0Ro4R2ViUeyQvlMSUjQL9rrTMVqv6L8uC+fF/0vmbqqtExf0\nQVOb4TsvT8HF8uMnWkJipdqzxW5xuvkcTfhcr1IboXyX1hnOLH6QFIAdVqlKmTOf+r3CNSSHw+Fw\nNIE9F+hTKcxKmZcFv3K1QozdpbZts1OXbK/E2Ye2mbdR7tslCgiAxHixJkalRA0kDWjTa6YG7Sql\nfSu6Z0kFt9lolA77TSUVNojpmDERWhqEG3ZkWbDYkcq/tGapENMImSg1HtdlAzDWRLd9NTRH8+hD\nWCiVL1CS1+2rLLHmbEo/U6kJW9E3xh9Zto94llUWx8LS3Qc6r/2uMPRGwHvOtHX1CzAWj5kzAICK\nprHoyPbS+9jKtZhWyXNk59Nl8uPGpZXoCNX2ymoRO1daJSzRic14re6U/goglS1hZohl324CXLHY\nSmUQq9Y6ku13DKq4PbOkUJuy95W+i3ROcz/faWV1sfejDuupxj1ZmZ5NyaSL7ZX/mCXJXphlo/Tv\n5lYTS0yxFXt5b3ANyeFwOBxNYL+ZGnRJmzeX/AD3O6LjLaifmse2MhX30y//JtsQqkhulnYekRFX\nl+Rl5HlRHqGUXihx1kXfQuWHymNx7DJVstiVR6oZ6HXePolS6AXGhejlFGUJeF0s9qarU4hLXF+n\n4B9n9nPGKbDMyKUjsoJKSdpyZJm/JGuD/7D9SVmo7mTBEgxaclv7w9im/OB0T7TroEh+nnJ9rrsS\nrHLN+5MMwwkLXZpPSdusLBNAun8pMc/1+TkYx8bJyBynevdVTzONqC4YeBe2Hc9OnwgAXNf4myWZ\nYmcsj71PGNN0TRajao8TMhSzvgc7SBdDccygc5i0HuboTE0kn3vp1zHrEN+P9POplptnJOHcT6sy\nLSnurHwmrehinr2lylPaeQlzh8PhcDyI2HOmhrhMQfElm6PLcpxtjBnXFcfSH8F4FUoEobJfA5kf\nwHxJDEDS83WlDdTig4ZtWbMuApfio0o2oOW8y3PAmd+LEiSaBe3TlHDIDppr5oJc6aQfhzEVFw9K\nthW1xwlZQZSkx9tj0+uknGi0P5lHzBBh/olJGXMEAPNRWSCO9nra6ZnBm+e/c8rS66kbzBDA82yq\n0tNNgeXeKyUuJKeZrbNVpgHy2FIK5pzwOcpLb/MZI+Pyimqx1JiM+Ug/X6UNAUm63s6Lx35ovyxW\nLGrMJ8uU841Wiiua2brlQpfUPFLezLier7g8iwXv9WBzFNdz3HlPWugYLUp5Pke+L6vceZWLPWmm\nfMft8JXafcXU8FWVhnF3FzMVtjM1nBXtzqjD4XA4zhX8g+RwOByOJrBfkx3NBwxUNGd/qbYDSV2t\nC7aJNhLUlFcHmWbZ1FONLCn3pSknmQpJQ4+/15ttR59UJgcL+jQVlWa5yjyHRGIwynrDqYPW6vSe\nTcrktomgkFTxzGoGAFhoinsjIugYrZdxeTRnIGpOeVUzgN6Jkga0aMtSFpHynI0vy0vYvWImjjIQ\neqG8cwuQ3mFWoAWDQZ8twogzVg0yLnj5kpnychM2kIoU2v1bERCCUXrTMRyLq0fRVHY4neoRpJ+X\nJpxdt/f2PV+GXNCcOphTXM89Ta+oyRD7seyjGe9mVuSuNbCcCqeC5syOrobXeAWYNc2o8XxvlNvz\nuVWrddIwko0urmdIi+7BEIhdrGxLMmDvay7LMI7O2sz6ode3Ql+0da9wDcnhcDgcTWC/gbFVyQY6\nznelKO+oEVnalzInRa0ZmUCQrZeKgh1UXjFqqYlncWGltjPJw6QF0ja7UnIeUPeDzuFsHylFnvqY\nlsBEjxzvxSr29XBGLSRzVFPKmpRzYlqiXmcqyKfU4yyolUNNCi+lsJUF7nHclUarntxdTlPO/eUL\nUZJfav+WmzKAsk5XlJ9nudzWEFpDXRp8nDjbAJK2oSt1E8e3JPDYM1LR7A8yzeTKhUhiOBgzWLqk\nLifyQqnWhtxhrv/yvrpxErUbzjNDA06X8fdy3RfbgYyK3vDcEBZ0X2XVMitJt+MdQ0JNX4aasI2g\nr57RlhqUBaSS1k0tykIg9D2q40uyUB6CkRIW8N5AcX7TiPg8m7UivROHKl3YWeEaksPhcDiawF41\nJH55w4iBXUyYWtMJS00HqGjUSFLgqKZSZ1KZFZBi6nXdNB2VSV43ID25pF8CyV6airyVdO/OSmyT\ntlomgQWApaa/YWExNB3QF5eU5EgHllqrBDAyDqtKVGUmGZOcWeCLU5UHXVo5Ef1Nmu9Ej5lU2hWl\n8lUeuKn/TtXXQfr3ZohtrXTi62KKfSZ904+ZAgrbFcNZnoCqvfkc6NPJad+UckHKPROycr1K5bo/\nE85eOZxZG0daesXuX0tOrDukqNaizVyCZ4jATdWMrh3HctnUgDh3TOE02tK+toM/Wwb7yrmwxLQ6\nhHnJBt7JmyoxgKXfGe/2gYdiX22PmhgD+nV935dlRux9VfhztY9VKjALGaiKK/KZyS1KffXePmuZ\n+XbfjA6Hw+E4V5CWi8U5HA6H4/zANSSHw+FwNAH/IDkcDoejCfgHyeFwOBxNwD9IDofD4WgC/kFy\nOBwORxPwD5LD4XA4moB/kBwOh8PRBPyD5HA4HI4m4B8kh8PhcDQB/yA5HA6Hown4B8nhcDgcTcA/\nSA6Hw+FoAv5BcjgcDkcT8A+Sw+FwOJqAf5AcDofD0QT8g+RwOByOJuAfJIfD4XA0Af8gORwOh6MJ\n+AfJ4XA4HE3AP0gOh8PhaAL+QXI4HA5HE/APksPhcDiagH+QHA6Hw9EE/j+zVTNMEhXCtgAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13667abb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, data in enumerate(val_loader, 0):\n",
    "    lgr.info('i=%d: '%(i))            \n",
    "    images, labels = data            \n",
    "    num = len(images)\n",
    "    \n",
    "    ax = plt.subplot(1, imagesToShow, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    for n in range(num):\n",
    "        image=images[n]\n",
    "        label=labels[n]\n",
    "        plt.imshow (GenericImageDataset.flaotTensorToImage(image))\n",
    "        \n",
    "    if i==imagesToShow-1:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The NN model\n",
    "\n",
    "- We will use a simple CNN with conv(3x3) -> bn -> relu -> pool(4x4) -> fc.\n",
    "\n",
    "- In PyTorch, a model is defined by a subclass of nn.Module. It has two methods:\n",
    "\n",
    "- `__init__: constructor. Create layers here. Note that we don't define the connections between layers in this function.`\n",
    "\n",
    "\n",
    "- `forward(x): forward function. Receives an input variable x. Returns a output variable. Note that we actually connect the layers here dynamically.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n",
      "INFO:__main__:Model Net (\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d (p=0.5)\n",
      "  (fc1): Linear (2304 -> 256)\n",
      "  (fc2): Linear (256 -> 17)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning/code/notebook\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, initKernel='uniform'):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(2304, 256)\n",
    "        self.fc2 = nn.Linear(256, 17)\n",
    "        \n",
    "        # xavier initializer\n",
    "        if initKernel == 'uniform':\n",
    "            nn.init.xavier_uniform(self.conv1.weight, gain=np.sqrt(2.0))\n",
    "        else:\n",
    "            nn.init.kaiming_normal(self.conv1.weight)                    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "#         return F.sigmoid(x)\n",
    "#         return F.log_softmax(x)\n",
    "    \n",
    "    \n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")\n",
    "    model = Net().cuda() # On GPU\n",
    "else:\n",
    "    lgr.info (\"Using the CPU\")\n",
    "    model = Net() # On CPU\n",
    "\n",
    "lgr.info('Model {}'.format(model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Loss and Optimizer\n",
    "\n",
    "- Select a loss function and the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Optimizer <torch.optim.sgd.SGD object at 0x7f1365c8b410>\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=1e-1,momentum=0.9, weight_decay=1e-4)\n",
    "lgr.info('Optimizer {}'.format(optimizer))\n",
    "\n",
    "# criterion = nn.ClassNLLCriterion() -- a negative log-likelihood criterion for multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Start training in Batches\n",
    "\n",
    "See example here:\n",
    "http://codegists.com/snippet/python/pytorch_mnistpy_kernelmode_python\n",
    "\n",
    "https://github.com/pytorch/examples/blob/53f25e0d0e2710878449900e1e61d31d34b63a9d/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-a763c6f3462c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'{} {:6.3f} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-a763c6f3462c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#             loss = F.nll_loss(preds, target.long()) # RuntimeError: multi-target not supported at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:22\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mgrad_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mgrad_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_variables\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, user_create_graph)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 new_grads.append(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    " \n",
    "\n",
    "    \n",
    "clf=model \n",
    "opt= optimizer\n",
    "loss_history = []\n",
    "acc_history = []\n",
    " \n",
    "def train(epoch):\n",
    "    clf.train() # set model in training mode (need this because of dropout)\n",
    "     \n",
    "    # dataset API gives us pythonic batching \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        if use_cuda:\n",
    "            data, target = Variable(data.cuda(async=True)), Variable(target.cuda(async=True)) # On GPU                \n",
    "        else:            \n",
    "            data, target = Variable(data), Variable(target) # RuntimeError: expected CPU tensor (got CUDA tensor)                           \n",
    "                 \n",
    "        # forward pass, calculate loss and backprop!\n",
    "        opt.zero_grad()\n",
    "        preds = clf(data)\n",
    "        if use_cuda:\n",
    "#             loss = F.binary_cross_entropy(preds, target).cuda()\n",
    "            loss = F.log_softmax(preds).cuda() # TypeError: log_softmax() takes exactly 1 argument (2 given)\n",
    "#             loss = F.nll_loss(preds, target).cuda() # https://github.com/torch/cutorch/issues/227\n",
    "            \n",
    "        else:\n",
    "#             loss = F.binary_cross_entropy(preds, target)\n",
    "            loss = F.log_softmax(preds)\n",
    "#             loss = F.nll_loss(preds, target.long()) # RuntimeError: multi-target not supported at /pytorch/torch/lib/THNN/generic/ClassNLLCriterion.c:22\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            loss_history.append(loss.data[0])\n",
    "            lgr.info('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.data[0]))              \n",
    "\n",
    "            \n",
    "start_time = time.time()    \n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "    train(epoch)    \n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Shape:torch.Size([64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected r_ [64], ta [64] and tb [64 x 17] to have the same number of elements, but got 64, 64 and 1088 elements respectively at /pytorch/torch/lib/TH/generic/THTensorMath.c:2829",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-1debb1689722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-157-1debb1689722>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#         correct += pred.eq(target.data.long()).cpu().sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected r_ [64], ta [64] and tb [64 x 17] to have the same number of elements, but got 64, 64 and 1088 elements respectively at /pytorch/torch/lib/TH/generic/THTensorMath.c:2829"
     ]
    }
   ],
   "source": [
    "def test(epoch):\n",
    "    clf.eval() # set model in inference mode (need this because of dropout)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "     \n",
    "    for data, target in val_loader:\n",
    "        \n",
    "        if use_cuda:\n",
    "            data, target = Variable(data.cuda(async=True)), Variable(target.cuda(async=True)) # On GPU                \n",
    "        else:            \n",
    "            data, target = Variable(data), Variable(target) # RuntimeError: expected CPU tensor (got CUDA tensor)               \n",
    "         \n",
    "        output = clf(data)\n",
    "        test_loss += F.binary_cross_entropy(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        print (\"Shape of pred:\" + str(pred.shape))\n",
    "        target_data_long=target.data.long()\n",
    "        print (\"Shape of target_data_long:\" + str(target_data_long.shape))\n",
    "        correct += pred.eq(target_data_long).cpu().sum()\n",
    " \n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    acc_history.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "\n",
    "    \n",
    "for epoch in range(1, 3):\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "    test(epoch)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "[NbConvertApp] Converting notebook ./09 PyTorch Kaggle Image Data-set loading with CNN.ipynb to slides\n",
      "[NbConvertApp] Writing 397955 bytes to ./py09.html.slides.html\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "jupyter nbconvert \\\n",
    "    --to=slides \\\n",
    "    --reveal-prefix=https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.2.0/ \\\n",
    "    --output=py09.html \\\n",
    "    './09 PyTorch Kaggle Image Data-set loading with CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
