{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 18  PyTorch NUMER.AI  Binary Classification using BCELoss \n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">\n",
    "\n",
    "\n",
    "### Data\n",
    "- Download from https://numer.ai/leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "__pyTorch VERSION: 0.1.12+4eb448a\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "OS:  linux2\n",
      "Python:  2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "PyTorch:  0.1.12+4eb448a\n",
      "Numpy:  1.13.1\n",
      "2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "0.0\n",
      "svmem(total=67469099008, available=60899651584, percent=9.7, used=5941116928, free=51718328320, active=10733961216, inactive=3935977472, buffers=877129728, cached=8932524032, shared=80064512)\n",
      "memory GB: 0.214756011963\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "# %%timeit\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import logging\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "\n",
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install psutil\n",
    "import psutil\n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "\n",
    "cpuStats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:USE CUDA=True\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "lgr.info(\"USE CUDA=\" + str (use_cuda))\n",
    "\n",
    "# ! watch -n 0.1 'ps f -o user,pgrp,pid,pcpu,pmem,start,time,command -p `lsof -n -w -t /dev/nvidia*`'\n",
    "# sudo apt-get install dstat #install dstat\n",
    "# sudo pip install nvidia-ml-py #install Python NVIDIA Management Library\n",
    "# wget https://raw.githubusercontent.com/datumbox/dstat/master/plugins/dstat_nvidia_gpu.py\n",
    "# sudo mv dstat_nvidia_gpu.py /usr/share/dstat/ #move file to the plugins directory of dstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN params\n",
    "DROPOUT_PROB = 0.75\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.005\n",
    "TEST_RATIO = .11\n",
    "MOMENTUM= 0.9\n",
    "PIN_MEMORY=use_cuda # True IF CUDA\n",
    "\n",
    "# Data params\n",
    "TARGET_VAR= 'target'\n",
    "TOURNAMENT_DATA_CSV = 'numerai_tournament_data.csv'\n",
    "TRAINING_DATA_CSV = 'numerai_training_data.csv'\n",
    "BASE_FOLDER = 'numerai/'\n",
    "\n",
    "\n",
    "# fix seed\n",
    "seed=17*19\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Load a CSV file for Binary classification (numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135682</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.53352</td>\n",
       "      <td>0.64336</td>\n",
       "      <td>0.46577</td>\n",
       "      <td>0.53001</td>\n",
       "      <td>0.55734</td>\n",
       "      <td>0.45773</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51224</td>\n",
       "      <td>0.50484</td>\n",
       "      <td>0.41929</td>\n",
       "      <td>0.50954</td>\n",
       "      <td>0.47383</td>\n",
       "      <td>0.48797</td>\n",
       "      <td>0.38373</td>\n",
       "      <td>0.46233</td>\n",
       "      <td>0.33341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110546</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.54196</td>\n",
       "      <td>0.81576</td>\n",
       "      <td>0.46632</td>\n",
       "      <td>0.62320</td>\n",
       "      <td>0.52427</td>\n",
       "      <td>0.64378</td>\n",
       "      <td>0.55662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52643</td>\n",
       "      <td>0.63809</td>\n",
       "      <td>0.67121</td>\n",
       "      <td>0.49421</td>\n",
       "      <td>0.45291</td>\n",
       "      <td>0.46932</td>\n",
       "      <td>0.54445</td>\n",
       "      <td>0.30997</td>\n",
       "      <td>0.19023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76047</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.49158</td>\n",
       "      <td>0.69131</td>\n",
       "      <td>0.57816</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.43064</td>\n",
       "      <td>0.49986</td>\n",
       "      <td>0.61902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43310</td>\n",
       "      <td>0.72286</td>\n",
       "      <td>0.76257</td>\n",
       "      <td>0.36600</td>\n",
       "      <td>0.55330</td>\n",
       "      <td>0.56566</td>\n",
       "      <td>0.67528</td>\n",
       "      <td>0.34960</td>\n",
       "      <td>0.25721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66098</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.54519</td>\n",
       "      <td>0.42473</td>\n",
       "      <td>0.63472</td>\n",
       "      <td>0.39003</td>\n",
       "      <td>0.37485</td>\n",
       "      <td>0.43810</td>\n",
       "      <td>0.59557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41658</td>\n",
       "      <td>0.63417</td>\n",
       "      <td>0.50189</td>\n",
       "      <td>0.40883</td>\n",
       "      <td>0.58705</td>\n",
       "      <td>0.63785</td>\n",
       "      <td>0.56225</td>\n",
       "      <td>0.55989</td>\n",
       "      <td>0.58642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88227</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.44307</td>\n",
       "      <td>0.74076</td>\n",
       "      <td>0.52210</td>\n",
       "      <td>0.56543</td>\n",
       "      <td>0.51125</td>\n",
       "      <td>0.66457</td>\n",
       "      <td>0.42263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45851</td>\n",
       "      <td>0.58805</td>\n",
       "      <td>0.49860</td>\n",
       "      <td>0.48023</td>\n",
       "      <td>0.52606</td>\n",
       "      <td>0.53253</td>\n",
       "      <td>0.38361</td>\n",
       "      <td>0.43829</td>\n",
       "      <td>0.25014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   era data_type  feature1  feature2  feature3  feature4  feature5  \\\n",
       "0  135682  era1     train   0.53352   0.64336   0.46577   0.53001   0.55734   \n",
       "1  110546  era1     train   0.54196   0.81576   0.46632   0.62320   0.52427   \n",
       "2   76047  era1     train   0.49158   0.69131   0.57816   0.54010   0.43064   \n",
       "3   66098  era1     train   0.54519   0.42473   0.63472   0.39003   0.37485   \n",
       "4   88227  era1     train   0.44307   0.74076   0.52210   0.56543   0.51125   \n",
       "\n",
       "   feature6  feature7   ...    feature13  feature14  feature15  feature16  \\\n",
       "0   0.45773   0.41169   ...      0.51224    0.50484    0.41929    0.50954   \n",
       "1   0.64378   0.55662   ...      0.52643    0.63809    0.67121    0.49421   \n",
       "2   0.49986   0.61902   ...      0.43310    0.72286    0.76257    0.36600   \n",
       "3   0.43810   0.59557   ...      0.41658    0.63417    0.50189    0.40883   \n",
       "4   0.66457   0.42263   ...      0.45851    0.58805    0.49860    0.48023   \n",
       "\n",
       "   feature17  feature18  feature19  feature20  feature21  target  \n",
       "0    0.47383    0.48797    0.38373    0.46233    0.33341       0  \n",
       "1    0.45291    0.46932    0.54445    0.30997    0.19023       0  \n",
       "2    0.55330    0.56566    0.67528    0.34960    0.25721       1  \n",
       "3    0.58705    0.63785    0.56225    0.55989    0.58642       0  \n",
       "4    0.52606    0.53253    0.38361    0.43829    0.25014       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Feature enrichement\n",
    "- This would be usually not required when using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genBasicFeatures(inDF):\n",
    "    print('Generating basic features ...')\n",
    "    df_copy=inDF.copy(deep=True)\n",
    "    magicNumber=21\n",
    "    feature_cols = list(inDF.columns)\n",
    "#     feature_cols = list(inDF.columns[:-1])\n",
    "    # feature_cols=xgb_cols\n",
    "#     target_col = inDF.columns[-1]\n",
    "\n",
    "    inDF['x_mean'] = np.mean(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_median'] = np.median(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_std'] = np.std(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_skew'] = scipy.stats.skew(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_kurt'] = scipy.stats.kurtosis(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_var'] = np.var(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_max'] = np.max(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_min'] = np.min(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    # http://stackoverflow.com/questions/16236684/apply-pandas-function-to-column-to-create-multiple-new-columns\n",
    "#     inDF=inDF.merge(df_copy.ix[:, 0:magicNumber].apply(lambda row: NumerCommonML.enrichFeatures(row), axis=1),\n",
    "#                     left_index=True, right_index=True)\n",
    "\n",
    "    print (inDF.head(1))\n",
    "    return inDF\n",
    "\n",
    "def addPolyFeatures(inDF, deg=2):\n",
    "    print('Generating poly features ...')\n",
    "    df_copy=inDF.copy(deep=True)\n",
    "    poly=PolynomialFeatures(degree=deg)\n",
    "    p_testX = poly.fit(df_copy)\n",
    "    # AttributeError: 'PolynomialFeatures' object has no attribute 'get_feature_names'\n",
    "    target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(df_copy.columns,p) for p in poly.powers_]]\n",
    "    df_copy = pd.DataFrame(p_testX.transform(df_copy),columns=target_feature_names)\n",
    "        \n",
    "    return df_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Train / Validation / Test Split\n",
    "- Numerai provides a data set that is allready split into train, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train, Validation, Test Split\n",
    "def loadDataSplit():\n",
    "    df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    df_test_valid = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "\n",
    "    answers_1_SINGLE = df_train[TARGET_VAR]\n",
    "    df_train.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    df_train.drop('id', axis=1,inplace=True)\n",
    "    df_train.drop('era', axis=1,inplace=True)\n",
    "    df_train.drop('data_type', axis=1,inplace=True)    \n",
    "    \n",
    "    # Add polynomial features    \n",
    "    df_train=genBasicFeatures(df_train)\n",
    "    df_train = addPolyFeatures(df_train)\n",
    "\n",
    "    df_train.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=False,  index = False)    \n",
    "    df_train= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=None, dtype=np.float32)    \n",
    "    df_train = pd.concat([df_train, answers_1_SINGLE], axis=1)\n",
    "    feature_cols = list(df_train.columns[:-1])\n",
    "#     print (feature_cols)\n",
    "    target_col = df_train.columns[-1]\n",
    "    trainX, trainY = df_train[feature_cols], df_train[target_col]\n",
    "    \n",
    "    \n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    # Validation set\n",
    "    df_validation_set=df_test_valid.loc[df_test_valid['data_type'] == 'validation'] \n",
    "    df_validation_set=df_validation_set.copy(deep=True)\n",
    "    answers_1_SINGLE_validation = df_validation_set[TARGET_VAR]\n",
    "    df_validation_set.drop(TARGET_VAR, axis=1,inplace=True)    \n",
    "    df_validation_set.drop('id', axis=1,inplace=True)\n",
    "    df_validation_set.drop('era', axis=1,inplace=True)\n",
    "    df_validation_set.drop('data_type', axis=1,inplace=True)\n",
    "    \n",
    "   # Add polynomial features    \n",
    "    df_validation_set=genBasicFeatures(df_validation_set)\n",
    "    df_validation_set = addPolyFeatures(df_validation_set)\n",
    "    \n",
    "    df_validation_set.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=False,  index = False)    \n",
    "    df_validation_set= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=None, dtype=np.float32)    \n",
    "    df_validation_set = pd.concat([df_validation_set, answers_1_SINGLE_validation], axis=1)\n",
    "    feature_cols = list(df_validation_set.columns[:-1])\n",
    "\n",
    "    target_col = df_validation_set.columns[-1]\n",
    "    valX, valY = df_validation_set[feature_cols], df_validation_set[target_col]\n",
    "                            \n",
    "    # Test set for submission (not labeled)    \n",
    "    df_test_set = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "#     df_test_set=df_test_set.loc[df_test_valid['data_type'] == 'live'] \n",
    "    df_test_set=df_test_set.copy(deep=True)\n",
    "    df_test_set.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    tid_1_SINGLE = df_test_set['id']\n",
    "    df_test_set.drop('id', axis=1,inplace=True)\n",
    "    df_test_set.drop('era', axis=1,inplace=True)\n",
    "    df_test_set.drop('data_type', axis=1,inplace=True)   \n",
    "    \n",
    "    # Add polynomial features    \n",
    "    df_test_set=genBasicFeatures(df_test_set)\n",
    "    df_test_set = addPolyFeatures(df_test_set)\n",
    "   \n",
    "    \n",
    "    feature_cols = list(df_test_set.columns) # must be run here, we dont want the ID    \n",
    "#     print (feature_cols)\n",
    "    df_test_set = pd.concat([tid_1_SINGLE, df_test_set], axis=1)            \n",
    "    testX = df_test_set[feature_cols].values\n",
    "        \n",
    "    return trainX, trainY, valX, valY, testX, df_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating basic features ...\n",
      "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0   0.53352   0.64336   0.46577   0.53001   0.55734   0.45773   0.41169   \n",
      "\n",
      "   feature8  feature9  feature10   ...     feature20  feature21    x_mean  \\\n",
      "0    0.5207   0.36351    0.72262   ...       0.46233    0.33341  0.495936   \n",
      "\n",
      "   x_median     x_std   x_skew    x_kurt    x_var    x_max    x_min  \n",
      "0   0.50484  0.088713  0.48164  0.453078  0.00787  0.72262  0.33341  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "Generating poly features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating basic features ...\n",
      "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0   0.33463    0.5162   0.73225    0.3637   0.35314   0.63717   0.51138   \n",
      "\n",
      "   feature8  feature9  feature10   ...     feature20  feature21    x_mean  \\\n",
      "0   0.62956   0.18643    0.60806   ...       0.59448    0.46003  0.492229   \n",
      "\n",
      "   x_median     x_std    x_skew    x_kurt    x_var    x_max    x_min  \n",
      "0   0.51138  0.166973 -0.148699 -1.259785  0.02788  0.73225  0.18643  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "Generating poly features ...\n",
      "Generating basic features ...\n",
      "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0   0.33463    0.5162   0.73225    0.3637   0.35314   0.63717   0.51138   \n",
      "\n",
      "   feature8  feature9  feature10   ...     feature20  feature21    x_mean  \\\n",
      "0   0.62956   0.18643    0.60806   ...       0.59448    0.46003  0.492229   \n",
      "\n",
      "   x_median     x_std    x_skew    x_kurt    x_var    x_max    x_min  \n",
      "0   0.51138  0.166973 -0.148699 -1.259785  0.02788  0.73225  0.18643  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "Generating poly features ...\n",
      "(108405, 465)\n",
      "(108405,)\n",
      "(16686, 465)\n",
      "(16686,)\n",
      "(45647, 465)\n",
      "(45647, 466)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "# X, y = loadDataSplit(999)\n",
    "\n",
    "\n",
    "# # Number of features for the input layer\n",
    "N_FEATURES=trainX.shape[1]\n",
    "# print (trainX.head(3))\n",
    "# print (df_test_set.head(3))\n",
    "print (trainX.shape)\n",
    "print (trainY.shape)\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "print (testX.shape)\n",
    "print (df_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create PyTorch GPU tensors from numpy arrays\n",
    "\n",
    "- Note how we transfrom the np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def XnumpyToTensor(x_data_np):\n",
    "    x_data_np = np.array(x_data_np.values, dtype=np.float32)        \n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")    \n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")\n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "    \n",
    "    print(type(X_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))    \n",
    "    return X_tensor\n",
    "\n",
    "\n",
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def YnumpyToTensor(y_data_np):    \n",
    "    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")            \n",
    "    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")        \n",
    "    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n",
    "\n",
    "    print(type(Y_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))    \n",
    "    return Y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The NN model\n",
    "\n",
    "### MLP model\n",
    "- A multilayer perceptron is a logistic regressor where instead of feeding the input to the logistic regression you insert a intermediate layer, called the hidden layer, that has a nonlinear activation function (usually tanh or sigmoid) . One can use many such hidden layers making the architecture deep.\n",
    "\n",
    "- Here we define a simple MLP structure. We map the input feature vector to a higher space (256), then later gradually decrease the dimension, and in the end into a 16-dimension space. Because we are calculating the probability of each genre independently, after the final affine layer we need to implement a sigmoid layer. \n",
    "\n",
    "###  Initial weights selection\n",
    "\n",
    "- There are many ways to select the initial weights to a neural network architecture. A common initialization scheme is random initialization, which sets the biases and weights of all the nodes in each hidden layer randomly.\n",
    "\n",
    "- Before starting the training process, an initial value is assigned to each variable. This is done by pure randomness, using for example a uniform or Gaussian distribution. But if we start with weights that are too small, the signal could decrease so much that it is too small to be useful. On the other side, when the parameters are initialized with high values, the signal can end up to explode while propagating through the network.\n",
    "\n",
    "- In consequence, a good initialization can have a radical effect on how fast the network will learn useful patterns.For this purpose, some best practices have been developed. One famous example used is **Xavier initialization**. Its formulation is based on the number of input and output neurons and uses sampling from a uniform distribution with zero mean and all biases set to zero.\n",
    "\n",
    "- In effect (according to theory) initializing the weights of the network to values that would be closer to the optimal, and therefore require less epochs to train.\n",
    "\n",
    "### References: \n",
    "* **`nninit.xavier_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a uniform distribution.\n",
    "* **`nninit.xavier_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a normal distribution.\n",
    "* **`nninit.kaiming_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.](https://arxiv.org/abs/1502.01852) using a uniform distribution.\n",
    "* **`nninit.kaiming_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Net2 (\n",
      "  (dis): Sequential (\n",
      "    (0): Linear (465 -> 2048)\n",
      "    (1): Dropout (p = 0.45)\n",
      "    (2): LeakyReLU (0.1)\n",
      "    (3): Linear (2048 -> 2048)\n",
      "    (4): Dropout (p = 0.45)\n",
      "    (5): LeakyReLU (0.1)\n",
      "    (6): Linear (2048 -> 1)\n",
      "    (7): Dropout (p = 0.45)\n",
      "    (8): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# p is the probability of being dropped in PyTorch\n",
    "# At each layer, DECREASE dropout\n",
    "dropout = torch.nn.Dropout(p=1 - DROPOUT_PROB +0.20)\n",
    "\n",
    "dropout1 = torch.nn.Dropout(p=1 - DROPOUT_PROB +0.20)\n",
    "dropout2 = torch.nn.Dropout(p=1 - DROPOUT_PROB +0.10)\n",
    "dropout3 = torch.nn.Dropout(p=1 - DROPOUT_PROB )\n",
    "dropout4 = torch.nn.Dropout(p=1 - DROPOUT_PROB -0.10)\n",
    "dropout5 = torch.nn.Dropout(p=1 - DROPOUT_PROB -0.20)\n",
    "\n",
    "\n",
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, n_feature, n_hidden, n_output,initKernel='uniform'):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "#         self.out = torch.nn.Linear(n_hidden, n_output)   # output layer        \n",
    "        \n",
    "#         # xavier initializer\n",
    "#         if initKernel == 'uniform':\n",
    "#             nn.init.xavier_uniform(self.hidden.weight, gain=np.sqrt(2.0))\n",
    "#         else:\n",
    "#             nn.init.kaiming_normal(self.hidden.weight)           \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "#         x = self.out(x)\n",
    "#         return F.sigmoid(x)\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output,initKernel='uniform'):\n",
    "        super(Net2, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(n_feature, n_hidden),\n",
    "            dropout,\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            dropout,\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "            dropout,\n",
    "            nn.Sigmoid()\n",
    "        )        \n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "hiddenLayer1Size=1024\n",
    "hiddenLayer2Size=int(hiddenLayer1Size/8)\n",
    "hiddenLayer3Size=int(hiddenLayer2Size/4)\n",
    "hiddenLayer4Size=int(hiddenLayer3Size/4)\n",
    "\n",
    "# # Hypothesis using sigmoid\n",
    "linear1=torch.nn.Linear(N_FEATURES, hiddenLayer1Size, bias=True) \n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "\n",
    "linear2=torch.nn.Linear(hiddenLayer1Size, hiddenLayer2Size)\n",
    "torch.nn.init.xavier_uniform(linear2.weight)\n",
    "\n",
    "linear3=torch.nn.Linear(hiddenLayer2Size, hiddenLayer3Size)\n",
    "torch.nn.init.xavier_uniform(linear3.weight)\n",
    "\n",
    "linear4=torch.nn.Linear(hiddenLayer3Size, hiddenLayer4Size)\n",
    "torch.nn.init.xavier_uniform(linear4.weight)\n",
    "\n",
    "linear5=torch.nn.Linear(hiddenLayer4Size, 1)\n",
    "torch.nn.init.xavier_uniform(linear5.weight)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "tanh=torch.nn.Tanh()\n",
    "\n",
    "net = torch.nn.Sequential(linear1,dropout5,tanh,\n",
    "                          linear2,tanh,\n",
    "                          linear3,tanh,\n",
    "                          linear4,tanh,\n",
    "                          linear5,sigmoid\n",
    "                          )\n",
    "\n",
    "# net = Net(n_feature=N_FEATURES, n_hidden=1024, n_output=1)   # define the network\n",
    "net = Net2(n_feature=N_FEATURES, n_hidden=2048, n_output=1)   # define the network\n",
    "\n",
    "lgr.info(net)  # net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Print the full net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (465 -> 1024), weights=((1024L, 465L), (1024L,)), parameters=477184\n",
      "  (1): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (2): Tanh (), weights=(), parameters=0\n",
      "  (3): Linear (1024 -> 128), weights=((128L, 1024L), (128L,)), parameters=131200\n",
      "  (4): Tanh (), weights=(), parameters=0\n",
      "  (5): Linear (128 -> 32), weights=((32L, 128L), (32L,)), parameters=4128\n",
      "  (6): Tanh (), weights=(), parameters=0\n",
      "  (7): Linear (32 -> 8), weights=((8L, 32L), (8L,)), parameters=264\n",
      "  (8): Tanh (), weights=(), parameters=0\n",
      "  (9): Linear (8 -> 1), weights=((1L, 8L), (1L,)), parameters=9\n",
      "  (10): Sigmoid (), weights=(), parameters=0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# See https://stackoverflow.com/questions/42480111/model-summary-in-pytorch/42616812\n",
    "from torch.nn.modules.module import _addindent\n",
    "import torch\n",
    "import numpy as np\n",
    "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
    "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
    "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
    "    for key, module in model._modules.items():\n",
    "        # if it contains layers let call it recursively to get params and weights\n",
    "        if type(module) in [\n",
    "            torch.nn.modules.container.Container,\n",
    "            torch.nn.modules.container.Sequential\n",
    "        ]:\n",
    "            modstr = torch_summarize(module)\n",
    "        else:\n",
    "            modstr = module.__repr__()\n",
    "        modstr = _addindent(modstr, 2)\n",
    "\n",
    "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
    "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
    "\n",
    "        tmpstr += '  (' + key + '): ' + modstr \n",
    "        if show_weights:\n",
    "            tmpstr += ', weights={}'.format(weights)\n",
    "        if show_parameters:\n",
    "            tmpstr +=  ', parameters={}'.format(params)\n",
    "        tmpstr += '\\n'   \n",
    "\n",
    "    tmpstr = tmpstr + ')'\n",
    "    return tmpstr\n",
    "\n",
    "lgr.info(torch_summarize(net))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Loss and Optimizer\n",
    "\n",
    "###  BCELoss\n",
    "- In addition, we will calculate the binary cross entropy loss (BCELoss). Luckily we have one loss function already present. For details please checkout http://pytorch.org/docs/master/nn.html. \n",
    "\n",
    "- ** NOTE this BCELoss may not be numerical stable, although it's fine during my training process.**\n",
    "\n",
    "### Optimization\n",
    "\n",
    "- if return F.log_softmax(x) then loss = F.nll_loss(output, target) (MNIST)\n",
    "- print(nn.BCEWithLogitsLoss()(o, t)) is equivalent to print(nn.BCELoss()(sigmoid(o), t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "INFO:__main__:<torch.optim.adam.Adam object at 0x7faec66c7450>\n",
      "INFO:__main__:BCELoss (\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.02)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=5e-4)\n",
    "\n",
    "#L2 regularization can easily be added to the entire model via the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-4) #  L2 regularization\n",
    "# optimizer = torch.optim.Adagrad(net.parameters(), lr=1e-6, weight_decay=5e-4)\n",
    "# loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted\n",
    "# loss_func = torch.nn.NLLLoss()\n",
    "loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "# http://andersonjo.github.io/artificial-intelligence/2017/01/07/Cost-Functions/\n",
    "# use_cuda=True\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    net.cuda()\n",
    "    loss_func.cuda()\n",
    "#     cudnn.benchmark = True\n",
    "    #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "lgr.info (optimizer)\n",
    "lgr.info (loss_func)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Training in batches  + Measuring the performance of the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108405, 465)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(108405, 465)\n",
      "<type 'numpy.ndarray'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "0 [ 0.70895278]\n",
      "ACC=0.0, LOG_LOSS=1.51792936589, ROC_AUC=0.49201588272 \n",
      "150 [ 0.69286054]\n",
      "ACC=0.0, LOG_LOSS=0.692856128575, ROC_AUC=0.513143765789 \n",
      "300 [ 0.69310606]\n",
      "ACC=0.0, LOG_LOSS=0.693077024467, ROC_AUC=0.509649438654 \n",
      "450 [ 0.69318068]\n",
      "ACC=0.0, LOG_LOSS=0.693097775948, ROC_AUC=0.50934355059 \n",
      "600 [ 0.69314444]\n",
      "ACC=0.0, LOG_LOSS=0.693059971458, ROC_AUC=0.510434836006 \n",
      "750 [ 0.69285852]\n",
      "ACC=0.0, LOG_LOSS=0.692855893647, ROC_AUC=0.513267388126 \n",
      "900 [ 0.69277549]\n",
      "ACC=0.0, LOG_LOSS=0.692769362688, ROC_AUC=0.515268980121 \n",
      "1050 [ 0.69294876]\n",
      "ACC=0.0, LOG_LOSS=0.692947408066, ROC_AUC=0.511591539148 \n",
      "1200 [ 0.69283974]\n",
      "ACC=0.0, LOG_LOSS=0.692846889282, ROC_AUC=0.513461320782 \n",
      "1350 [ 0.69314319]\n",
      "ACC=0.0, LOG_LOSS=0.693329298472, ROC_AUC=0.517107061844 \n",
      "GPU: 309.040 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X1wXNd93vHvgwUWIIDlO7iQSUmkLC4U2lYol5ETu03l\npqLpuo066dSmJk6VZGx10sqJ5cap3HQkl4qn9jSN8zKsM2rCzLSxxSaK7LAJZUkTJSPHll1CjiyL\nlPliSopIiST4JryQeFnsr3/cC3AJAsQSXHAB7POZ2cHec89dnbtD3WfPveeeq4jAzMysodYNMDOz\nucGBYGZmgAPBzMxSDgQzMwMcCGZmlnIgmJkZ4EAwM7OUA8HMzAAHgpmZpRpr3YArsXLlyli7dm2t\nm2FmNq88//zzJyOiY7p68yoQ1q5dS3d3d62bYWY2r0h6rZJ6PmVkZmaAA8HMzFIOBDMzAxwIZmaW\nciCYmRngQDAzs5QDwczMgDoJhD9/4Sh//O2KhuGamdWtugiEJ75/jB1/+0qtm2FmNqfVRSAUOnO8\nemqAwZHRWjfFzGzOqotA6MrnKAUcOtFf66aYmc1Z9REIne0AHDjeV+OWmJnNXXURCDeuaCObaWC/\nA8HMbEp1EQhNmQZu6mjjwDEHgpnZVOoiEAC6OnMcOO5rCGZmU6mbQCjkcxw9e56+wZFaN8XMbE6q\nKBAkbZG0X9IhSQ9Msv6Lkl5IXwcknS1bd4+kg+nrnrLyuyV9X9KLkr4uaWV1dmlyXfkcgHsJZmZT\nmDYQJGWA7cAHgQ3A3ZI2lNeJiPsjYmNEbAR+D3g83XY58BDwHuB24CFJyyQ1Ar8DvD8ibgVeBO6r\n3m5dqqtzLBB8HcHMbDKV9BBuBw5FxOGIGAZ2Anddpv7dwKPp+w8AT0fE6Yg4AzwNbAGUvtokCVgM\nvDHDfajI6qWLaM1m2O8Ly2Zmk6okEFYDr5ctH0nLLiHpRmAd8Mzlto2IEeCXgO+TBMEG4A+vqOVX\nqKFBrM/n3EMwM5tCtS8qbwUei4jLzhEhqYkkEG4D3kZyyugzU9S9V1K3pO6enp6ralxXvt2BYGY2\nhUoC4ShwfdnymrRsMlu5cLrocttuBIiIH0ZEAH8CvHeyD4yIRyJiU0Rs6ujoqKC5Uyvkc5zsH+Zk\n/9BVfY6Z2UJUSSDsAdZLWicpS3LQ3zWxkqRbgGXAc2XFTwKb0wvJy4DNadlRYIOksSP8ncDLM9+N\nyvjCspnZ1BqnqxARRUn3kRzIM8COiNgraRvQHRFj4bAV2Jn+4h/b9rSkh0lCBWBbRJwGkPRfgGcl\njQCvAT9frZ2ayvjQ02N9vPftszrK1cxs3pk2EAAiYjewe0LZgxOWPzvFtjuAHZOU/z7w+5U2tBo6\ncs0sbW1iv+9FMDO7RN3cqQwgiYJHGpmZTaquAgGS00YHjvVRdmbLzMyow0AodOboGyry5luDtW6K\nmdmcUneBMHZh2c9GMDO7WN0FQiGfPj3NU1iYmV2k7gJhaWuW/OJm9xDMzCaou0CA5I5lT3JnZnax\nugyErnyOgyf6GS15pJGZ2Zi6DIRCZ47hYonXTg3UuilmZnNGXQbChaen+bSRmdmYugyE9elIo/3H\nPIWFmdmYugyE1mwjNyxvdQ/BzKxMXQYCJFNhe+ipmdkF9RsI+RyvnBxgqHjZh7uZmdWNug2EQmeO\n0VJwuMcjjczMoI4DwSONzMwuVlEgSNoiab+kQ5IemGT9FyW9kL4OSDpbtu4eSQfT1z1l5VlJj6T1\nfyDpX1VnlyqzbmUbjQ3yHctmZqlpn5gmKQNsJ3nu8RFgj6RdEbFvrE5E3F9W/xPAben75cBDwCYg\ngOfTbc8Avw6ciIiCpAZgefV2a3rZxgZu6mhzD8HMLFVJD+F24FBEHI6IYWAncNdl6t8NPJq+/wDw\ndEScTkPgaWBLuu4Xgf8KEBGliDg5kx24GoW8RxqZmY2pJBBWA6+XLR9Jyy4h6UZgHfDM5baVtDRd\nfljSdyX9qaT8FJ95r6RuSd09PT0VNLdyXfkcr58+z8BQsaqfa2Y2H1X7ovJW4LGImG4sZyOwBvhW\nRLwbeA74zckqRsQjEbEpIjZ1dHRUtbGFzuTC8sETvmPZzKySQDgKXF+2vCYtm8xWLpwuuty2p4Bz\nwONp+Z8C766gLVU1PtLIF5bNzCoKhD3AeknrJGVJDvq7JlaSdAuwjOTX/pgngc2SlklaBmwGnozk\nCff/F7gjrfdTwD6useuXt9LS1ODrCGZmVDDKKCKKku4jObhngB0RsVfSNqA7IsbCYSuwMz3Yj217\nWtLDJKECsC0iTqfv/yPwvyX9NtAD/EJ1dqlymQaxflXOI43MzKggEAAiYjewe0LZgxOWPzvFtjuA\nHZOUvwb8ZKUNnS2FfI5vHKzuxWozs/mobu9UHtPV2c6JviHODAzXuilmZjVV94FQ8BQWZmaAA4Gu\nTgeCmRk4EOhc3EKupdEjjcys7tV9IEiiK5/jgB+naWZ1ru4DAZI7lvcf76NsxKyZWd1xIJDcsfzW\n+RFO9A3VuilmZjXjQODCSCM/G8HM6pkDASjk2wGPNDKz+uZAAFa0N7Oyvdk9BDOraw6EVFdnu3sI\nZlbXHAipQj7HgeP9lEoeaWRm9cmBkOrK5zg/MsqRM+dr3RQzs5pwIKTGnp7mO5bNrF45EFLrV3mk\nkZnVt4oCQdIWSfslHZL0wCTrvyjphfR1QNLZsnX3SDqYvu6ZZNtdkl66ut24ermWJlYvXeSRRmZW\nt6Z9QI6kDLAduBM4AuyRtCsixh95GRH3l9X/BHBb+n458BCwCQjg+XTbM+n6nwHmzCRCXZ05B4KZ\n1a1Kegi3A4ci4nBEDAM7gbsuU/9u4NH0/QeApyPidBoCTwNbACS1A58CfmOmja+2Qj7HD3v6GS6W\nat0UM7NrrpJAWA28XrZ8JC27hKQbgXXAMxVs+zDw34FzV9DeWdXV2U6xFLx6aqDWTTEzu+aqfVF5\nK/BYRIxerpKkjcDbI+Kr032gpHsldUvq7umZ3Wcfe04jM6tnlQTCUeD6suU1adlktnLhdNHltv0J\nYJOkV4G/BQqS/mayD4yIRyJiU0Rs6ujoqKC5M/f2jnYa5JFGZlafKgmEPcB6SeskZUkO+rsmVpJ0\nC7AMeK6s+Elgs6RlkpYBm4EnI+JLEfG2iFgL/EPgQETccXW7cvVamjKsXdnmHoKZ1aVpRxlFRFHS\nfSQH9wywIyL2StoGdEfEWDhsBXZG2VNmIuK0pIdJQgVgW0Scru4uVNctnTn2vdFb62aYmV1z0wYC\nQETsBnZPKHtwwvJnp9h2B7DjMp/9KvDOStpxLRTyOZ546Rjnh0dZlM3UujlmZteM71SeoCufIwIO\nnZgzt0eYmV0TDoQJPKeRmdUrB8IENy5vJdvY4JFGZlZ3HAgTNGYauLmj3SONzKzuOBAm0dWZcw/B\nzOqOA2EShXyON98a5K3zI7VuipnZNeNAmERXZ/JshIPuJZhZHXEgTGJ8TiMHgpnVEQfCJFYvXURb\nNsMBX1g2szriQJiEJAqdOfcQzKyuOBCm0JVPnp5WNjWTmdmC5kCYQiGf48y5EU72D9e6KWZm14QD\nYQpd6RQWvh/BzOqFA2EKfnqamdUbB8IUVrZnWd6WdQ/BzOqGA2EKkijk2z3SyMzqRkWBIGmLpP2S\nDkl6YJL1X5T0Qvo6IOls2bp7JB1MX/ekZa2S/lLSDyTtlfT56u1S9XTlcxzwSCMzqxPTPjFNUgbY\nDtwJHAH2SNoVEfvG6kTE/WX1PwHclr5fDjwEbAICeF7SLmAI+M2I+Ov0Oc1/JemDEfFE9Xbt6hU6\ncwwMj3L07HnWLGutdXPMzGZVJT2E24FDEXE4IoaBncBdl6l/N/Bo+v4DwNMRcToizgBPA1si4lxE\n/DVA+pnfBdbMdCdmS1feI43MrH5UEgirgdfLlo+kZZeQdCOwDnim0m0lLQX+BfBXU3zmvZK6JXX3\n9PRU0NzqWT8+0siP0zSzha/aF5W3Ao9FxGgllSU1kvQmfjciDk9WJyIeiYhNEbGpo6Ojik2d3pJF\nTVy3pMU9BDOrC5UEwlHg+rLlNWnZZLZy4XRRJds+AhyMiN+uoB01UUinsDAzW+gqCYQ9wHpJ69IL\nwFuBXRMrSboFWAY8V1b8JLBZ0jJJy4DNaRmSfgNYAnzy6nZhdnV15jjU009xtFTrppiZzappAyEi\nisB9JAfyl4E/iYi9krZJ+umyqluBnVE2RjMiTgMPk4TKHmBbRJyWtAb4dWAD8N10uOrHqrZXVVTI\n5xgulnjt9LlaN8XMbFZNO+wUICJ2A7snlD04YfmzU2y7A9gxoewIoCtpaK2MjzQ61sfbO9pr3Boz\ns9njO5WncfOqdiQ/Pc3MFj4HwjQWZTPcuLzVI43MbMFzIFSgkM/xA480MrMFzoFQga7OHK+eHGBw\npKLbK8zM5iUHQgUK+RylgB/2+I5lM1u4HAgV8NPTzKweOBAqsHZFG00ZeU4jM1vQHAgVyDY2cNPK\ndvcQzGxBcyBUqKvTcxqZ2cLmQKhQV2eOo2fP0zc4UuummJnNCgdChQrpFBYHT/g6gpktTA6ECpXP\naWRmthA5ECq0ZtkiFjVlPKeRmS1YDoQKNTSIQt4jjcxs4XIgXIHk6Wm+hmBmC1NFgSBpi6T9kg5J\nemCS9V9MH3LzgqQDks6WrbtH0sH0dU9Z+T+Q9P30M39X0px/PkJXZ46T/UOc6h+qdVPMzKpu2kCQ\nlAG2Ax8kecLZ3ZI2lNeJiPsjYmNEbAR+D3g83XY58BDwHuB24KH0UZoAXwI+DqxPX1uqskezaGyk\n0YHj7iWY2cJTSQ/hduBQRByOiGFgJ3DXZerfDTyavv8A8HREnI6IM8DTwBZJ1wGLI+Lb6SM3/xfw\nL2e8F9eI5zQys4WskkBYDbxetnwkLbuEpBuBdcAz02y7On0/7WfOJatyzSxZ1OSRRma2IFX7ovJW\n4LGIqNqDAyTdK6lbUndPT0+1PnambaErn/O9CGa2IFUSCEeB68uW16Rlk9nKhdNFl9v2aPp+2s+M\niEciYlNEbOro6KigubOr0NnO/uN9JGe6zMwWjkoCYQ+wXtI6SVmSg/6uiZUk3QIsA54rK34S2Cxp\nWXoxeTPwZES8CfRK+vF0dNG/Af78KvflmujK5+gbLHKsd7DWTTEzq6ppAyEiisB9JAf3l4E/iYi9\nkrZJ+umyqluBnVH20zkiTgMPk4TKHmBbWgbw74A/AA4BPwSeqML+zLqxkUae+dTMFprGSipFxG5g\n94SyBycsf3aKbXcAOyYp7wbeWWlD54oLQ0/7uKNrVY1bY2ZWPb5T+Qota8uyKtfsO5bNbMFxIMxA\nV2fO9yKY2YLjQJiBQj7HwRN9jJY80sjMFg4Hwgx05XMMjpR4/fS5WjfFzKxqHAgzUEinsPAdy2a2\nkDgQZmD9qnbAT08zs4XFgTADbc2NXL98kXsIZragOBBmqCvvkUZmtrA4EGaokM9xuGeA4WKp1k0x\nM6sKB8IMdXXmKJaCV04O1LopZmZV4UCYofE5jXzayMwWCAfCDN3U0UamQR5pZGYLhgNhhpobM6xb\n2eYegpktGA6Eq9CVz3kabDNbMBwIV6GQz/H3p89xbrhY66aYmV21igJB0hZJ+yUdkvTAFHU+LGmf\npL2SvlJW/gVJL6Wvj5SV/5Sk70p6QdLfSrr56nfn2urqTO5YPnjcU2Gb2fw3bSBIygDbgQ8CG4C7\nJW2YUGc98BngfRHxDuCTafmHgHcDG4H3AL8qaXG62ZeAn42IjcBXgP9clT26hjzSyMwWkkp6CLcD\nhyLicEQMAzuBuybU+TiwPSLOAETEibR8A/BsRBQjYgB4EdiSrgtgLByWAG/MfDdq48YVbWQbGzzS\nyMwWhEoCYTXwetnykbSsXAEoSPqmpG9LGjvofw/YIqlV0krg/cD16bqPAbslHQF+Dvj8THeiVjIN\nYv2qdvcQzGxBqNZF5UZgPXAHcDfwPyUtjYinSJ7F/C3gUeA5YDTd5n7gn0XEGuCPgN+a7IMl3Sup\nW1J3T09PlZpbPX56mpktFJUEwlEu/KoHWJOWlTsC7IqIkYh4BThAEhBExOciYmNE3AkIOCCpA/jR\niPhOuv3/Ad472X88Ih6JiE0Rsamjo6PiHbtWuvI5jvcOcfbccK2bYmZ2VSoJhD3AeknrJGWBrcCu\nCXW+RtI7ID01VAAOS8pIWpGW3wrcCjwFnAGWSCqk298JvHyV+1ITYw/LOeCRRmY2zzVOVyEiipLu\nA54EMsCOiNgraRvQHRG70nWbJe0jOSX06Yg4JakF+IYkgF7goxFRBJD0ceDPJJVIAuIXZ2H/Zl1X\n2Uij29ctr3FrzMxmbtpAAIiI3STXAsrLHix7H8Cn0ld5nUGSkUaTfeZXga9eYXvnnOuWtJBrbvRI\nIzOb93yn8lWSRKEz55FGZjbvORCqoJA+PS3pKJmZzU8OhCroyrdz9twIPX1DtW6KmdmMORCqYGyk\nkU8bmdl85kCogvGRRr6wbGbzmAOhCla0N7OyPes7ls1sXnMgVEkhn2O/b04zs3nMgVAlhXyOg8f7\nKJU80sjM5icHQpV0deY4NzzK0bPna90UM7MZcSBUScEXls1snnMgVEkhnzxO00NPzWy+ciBUSa6l\nidVLF3mkkZnNWw6EKirk233KyMzmLQdCFRU6cxzuGWBktFTrppiZXTEHQhV15XMMj5Z47dRArZti\nZnbFHAhVdGGkkW9QM7P5p6JAkLRF0n5JhyQ9MEWdD0vaJ2mvpK+UlX9B0kvp6yNl5ZL0OUkHJL0s\n6Zevfndq6+ZV7TTII43MbH6a9olpkjLAdpLnHh8B9kjaFRH7yuqsBz4DvC8izkhalZZ/CHg3sBFo\nBv5G0hMR0Qv8PHA9cEtElMa2mc9amjKsXdHmp6eZ2bxUSQ/hduBQRByOiGFgJ3DXhDofB7ZHxBmA\niDiRlm8Ano2IYkQMAC8CW9J1vwRsi4jShG3mtbGH5ZiZzTeVBMJq4PWy5SNpWbkCUJD0TUnfljR2\n0P8esEVSq6SVwPtJegUAbwc+Iqlb0hNpL2PeK3TmePXUAIMjo7VuipnZFZn2lNEVfM564A5gDfCs\npHdFxFOSfgz4FtADPAeMHSmbgcGI2CTpZ4AdwD+a+MGS7gXuBbjhhhuq1NzZ05XPUQo4dKKfd65e\nUuvmmJlVrJIewlEu/KqH5IB/dEKdI8CuiBiJiFeAAyQBQUR8LiI2RsSdgNJ1Y9s8nr7/KnDrZP/x\niHgkIjZFxKaOjo5K9qmmujqTKSx82sjM5ptKAmEPsF7SOklZYCuwa0Kdr5H0DkhPDRWAw5Iyklak\n5beSHPSfKtvm/en7f8yFoJjXblzRRjbT4JFGZjbvTHvKKCKKku4DngQywI6I2CtpG9AdEbvSdZsl\n7SM5JfTpiDglqQX4hiSAXuCjEVFMP/rzwJcl3Q/0Ax+r9s7VQlOmgZs6PNLIzOafiq4hRMRuYPeE\nsgfL3gfwqfRVXmeQZKTRZJ95FvjQFbZ3XujqzNH96plaN8PM7Ir4TuVZUMjnOHr2PL2DI7VuiplZ\nxRwIs6ArncLioK8jmNk84kCYBV2dntPIzOYfB8IsWL10Ea3ZjIeemtm84kCYBQ0NYn0+54flmNm8\n4kCYJbd4TiMzm2ccCLOk0Jnj1MAwJ/uHat0UM7OKOBBmydhII9+gZmbzhQNhlhTSOY08hYWZzRcO\nhFnS0d7MstYmX0cws3nDgTBLJFHwSCMzm0ccCLOoqzPHgeP9JFM9mZnNbQ6EWVTI5+gfKvLGW4O1\nboqZ2bQcCLNobAoLjzQys/nAgTCLCqvSOY18YdnM5oGKAkHSFkn7JR2S9MAUdT4saZ+kvZK+Ulb+\nBUkvpa+PTLLd70pakLPALWltonNxi3sIZjYvTPuAHEkZYDtwJ8lzkPdI2hUR+8rqrAc+A7wvIs5I\nWpWWfwh4N7ARaAb+RtITEdGbrt8ELKvyPs0phc6cewhmNi9U0kO4HTgUEYcjYhjYCdw1oc7Hge0R\ncQYgIk6k5RuAZyOiGBEDwIvAFhgPmv8G/NrV78bc1ZVv5+CJfkZLHmlkZnNbJYGwGni9bPlIWlau\nABQkfVPStyVtScu/B2yR1CppJfB+4Pp03X3Aroh4c+bNn/sK+RzDxRKvnRqodVPMzC6romcqV/g5\n64E7gDXAs5LeFRFPSfox4FtAD/AcMCrpbcC/TutflqR7gXsBbrjhhio199oZH2l0vI+bOtpr3Boz\ns6lV0kM4yoVf9ZAc8I9OqHOE5Nf+SES8AhwgCQgi4nMRsTEi7gSUrrsNuBk4JOlVoFXSocn+4xHx\nSERsiohNHR0dV7Brc8PNq9qR/PQ0M5v7KgmEPcB6SeskZYGtwK4Jdb5G+ms/PTVUAA5LykhakZbf\nCtwKPBURfxkRnRGxNiLWAuci4uaq7NEc05pt5IblrZ7TyMzmvGlPGUVEUdJ9wJNABtgREXslbQO6\nI2JXum6zpH3AKPDpiDglqQX4hiSAXuCjEVGcrZ2Zqwp5jzQys7mvomsIEbEb2D2h7MGy9wF8Kn2V\n1xkkGWk03ecv6JPrXfkcz/zgBEPFUZobM7VujpnZpHyn8jVQ6MwxWgoO93ikkZnNXQ6Ea2D86Wk+\nbWRmc5gD4RpYt7KNxgb52QhmNqc5EK6BbGMDN3W0uYdgZnNatW5Ms2kU8jm+d+RsrZsxpVIpGB4t\nJa9i2StdHpqwPFwsMTK27pJtRi/afqhYYmQ0GC6OXvwZo0FGkGkQDRKNmeRvpkE0Nlx4P/4qW26Y\nUKcxLctM3CYta5hQZ/x9A7Q0Zli1uJlVuRZWLW72hX+bE4aLJU70DXLsrUHeeGuQO38kz6Ls7P7b\ndCBcI135HH/x4psMDBVpa56drz0i6B0scrJ/iJN9Q5zsH+bUQPK+p3+YU/1DnOwf4tTAMOeHRy86\nuBerONdSpkFkMw1kG9NXpoHmxgaaJpS1NAmA4mgwGsHQSNKOUgSjpbJX2XKpFBfVKaZlF9W5yl1Z\n3pZlVa6ZziUt5HMt5Je0kF/cTOfiFvLpa0VbloYGVeHbsno0ODLK8d5B3nwrOeAnf88nf9Pyk/1D\nlD9s8an7f5JCej1ytjgQrpFCOoXFwRP9bLx+acXbjZaC0wNjB/bh5GDfnxzsx96fSt+f6h9meLR0\nyWc0KDnIrWxvZkV7lh9dtpTWbGb8wDx+kC47eGfLD+BldZobG8hmMhdt05QRzWVlmRofKCMuBEmp\nBMVSafzvxLLRCM4Pj3Kib5DjvYMc7x3iWO8gJ3qT/zH3vtF7yf+YAI0NYlWumVWLL4TFqsUt46HR\nuSRZl2tuJL0Px+rEueHi5Af6seXeQU4PDF+y3eKWRt62dBGdS1p4x9sW07l4EdctaaFzSQvXLWnh\nxhVts952B8I1Mj7S6FgfP3JdjlP9w+MH8p4JB/by96cHhif9xduUESvbm8cP8l2duXQ5O16+Mpe8\nX9aarflB+lpSevrpwj/u6bvZG1g85briaIme/qEkLN4aHO/GH+8d4njvIId7BvjWD0/RN3jpPZet\n2Uzaq2hOgiINjvIex0I9TVUqBX1DRXrPj9A7OELv+WL6d4TewcuX9w2OkGkQi5oytGQzLGpKX9kM\nLU1TLGcbkvpNGVqzjSzKNpStu7DN2Oc1Za78Emrf4EjZgX7sAH/xAf+t8yOXbLe8LUvn4uTAftsN\nS9MD/YUDfufillk7c3AlNJ8eAL9p06bo7u6udTNmZLQUvOOhrzNaCkZGJ//OW7OZ8YP6ivSg3tGe\nZWWumRVt6cE+l5QvbvEvz7nm3HBxPCTGXsfeGuJ43yDH3xpM/vYOMVy8tBe3rLWJZW1ZmhszNDde\n6KU1N2ZobmqgOdOQ/G3MjPfUmhsnLDclvbcL7xtobsqUfdal21/u39DVHNB7B0foHype0rOaKNfc\nyOJFTeRakr+LW5pYvKiRxS1NlNLe2/mRUQZHkr/JcilZTtedHxmd9DudTuMUgVP+tykjTg0Mjx/w\n+4cuDf2V7c0X/ZK/bsnFv+zzi1toaapt4Et6PiI2TVvPgXDtfPk7r3HgWF/6672ZFW3JAb4j/ZXf\nmq39LwSbXRHB2XMjHE97GSfSU1THewc5c254/AL+UNmF/KHiKEMj6QX6kdGkfLQ07cG2EmOnCMsD\nZGS0lPxKv8oDerJ8afmSdLm9pbFqPdfiaInBYonzwxPDIw2UsvcX1ymlf4vp+tJFdYeKo6xou/iA\nP/7LPu3hZRvn/mDNSgPBR6Br6Gffc2Otm2A1JollbVmWtWW5pXPq01TTiUh6mkPpyK1LAqRYSkMk\nCZNL1o2/yrYfSZazmYbkIH4ND+hXqzHTQHumgfY5cNplPvO3ZzYPSSLbqHnx69TmD/9rMjMzwIFg\nZmYpB4KZmQEOBDMzS1UUCJK2SNov6ZCkB6ao82FJ+yTtlfSVsvIvSHopfX2krPzL6We+JGmHpKar\n3x0zM5upaQNBUgbYDnyQ5Olnd0vaMKHOeuAzwPsi4h3AJ9PyDwHvBjYC7wF+VdLYWLsvA7cA7wIW\nAR+rxg6ZmdnMVNJDuB04FBGHI2IY2AncNaHOx4HtEXEGICJOpOUbgGcjohgRA8CLwJa0zu5IAf8P\nWHP1u2NmZjNVSSCsBl4vWz6SlpUrAAVJ35T0bUlb0vLvAVsktUpaCbwfuL58w/RU0c8BX5/sPy7p\nXkndkrp7enoqaK6Zmc1EtW5MawTWA3eQ/NJ/VtK7IuIpST8GfAvoAZ4DRids+z9IehHfmOyDI+IR\n4BEAST2SXpthG1cCJ2e47ULk7+MCfxcX8/dxsYXwfVQ0TUIlgXCUi3/Vr0nLyh0BvhMRI8Arkg6Q\nBMSeiPgc8DmA9GLzgbGNJD0EdAD/tpLGRkRHJfUmI6m7krk86oW/jwv8XVzM38fF6un7qOSU0R5g\nvaR1krLAVmDXhDpfI+kdkJ4aKgCHJWUkrUjLbwVuBZ5Klz8GfAC4OyKufKpCMzOrqml7CBFRlHQf\n8CTJxPI7ImKvpG1Ad0TsStdtlrSP5JTQpyPilKQW4BvpFLu9wEcjYmz+2N8HXgOeS9c/HhHbqrx/\nZmZWoXnYnSzxAAACY0lEQVQ1/fXVkHRvej3C8PdRzt/Fxfx9XKyevo+6CQQzM7s8T11hZmZAnQRC\nJVNv1ANJ10v667IpRn6l1m2aC9LBD38n6S9q3ZZak7RU0mOSfiDpZUk/Ues21Yqk+9P/T16S9Gh6\nTXRBW/CBUMnUG3WkCPyHiNgA/Djw7+v4uyj3K8DLtW7EHPE7wNcj4hbgR6nT70XSauCXgU0R8U6S\nATVba9uq2bfgA4HKpt6oCxHxZkR8N33fR/I/+8S7zuuKpDXAh4A/qHVbak3SEuAngT8EiIjhiDhb\n21bVVCOwSFIj0Aq8UeP2zLp6CIRKpt6oO5LWArcB36ltS2rut4FfA3wvDKwjmVHgj9JTaH8gqa3W\njaqFiDgK/Cbw98CbwFsR8VRtWzX76iEQbAJJ7cCfAZ+MiN5at6dWJP1z4EREPF/rtswRjSSzE38p\nIm4DBoC6vOYmaRnJmYR1wNuANkkfrW2rZl89BEIlU2/UjXQywT8DvhwRj9e6PTX2PuCnJb1Kcirx\nn0j649o2qaaOAEciYqzX+BhJQNSjfwq8EhE96ZQ8jwPvrXGbZl09BEIlU2/UBSW3hP8h8HJE/Fat\n21NrEfGZiFgTEWtJ/l08ExEL/lfgVCLiGPC6pK606KeAfTVsUi39PfDj6UzNIvkuFvwF9mrNdjpn\nTTX1Ro2bVSvvI5lq/PuSXkjL/lNE7K5hm2xu+QTw5fTH02HgF2rcnpqIiO9Iegz4LsnovL8jnXV5\nIfOdymZmBtTHKSMzM6uAA8HMzAAHgpmZpRwIZmYGOBDMzCzlQDAzM8CBYGZmKQeCmZkB8P8BP+Zs\njkxASDoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faea027fc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faea020a3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()    \n",
    "epochs=1500\n",
    "all_losses = []\n",
    "\n",
    "X_tensor_train= XnumpyToTensor(trainX)\n",
    "Y_tensor_train= YnumpyToTensor(trainY)\n",
    "\n",
    "print(type(X_tensor_train.data), type(Y_tensor_train.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "# From here onwards, we must only use PyTorch Tensors\n",
    "for step in range(epochs):\n",
    "#     net.train()\n",
    "    \n",
    "#     output = F.sigmoid(net(input))\n",
    "#     loss = crit(output, target)\n",
    "    out = net(X_tensor_train)                 # input x and predict based on x\n",
    "    cost = loss_func(out, Y_tensor_train)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    cost.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "                   \n",
    "        \n",
    "    if step % 150 == 0:        \n",
    "        loss = cost.data[0]\n",
    "        all_losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "        # Use .cpu() to move the tensor to host memory first.        \n",
    "#         prediction = torch.max(F.softmax(out), 1)[1]\n",
    "#         _, prediction = torch.max(out, 1)    \n",
    "        prediction = (net(X_tensor_train).data).float() # probabilities \n",
    "        \n",
    "#         prediction = (net(X_tensor).data > 0.5).float() # zero or one\n",
    "#         print (\"Pred:\" + str (prediction)) # Pred:Variable containing: 0 or 1\n",
    "#         pred_y = prediction.data.numpy().squeeze()\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "    \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = Y_tensor_train.cpu().data.numpy()\n",
    "                        \n",
    "        tu = ((pred_y == target_y).mean(),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "        print ('ACC={}, LOG_LOSS={}, ROC_AUC={} '.format(*tu))        \n",
    "                \n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Performance of the deep learning model on the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16686, 465)\n",
      "(16686,)\n",
      "(16686, 465)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(16686, 465)\n",
      "<type 'numpy.ndarray'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "acc=0.0 log_loss=0.693027365405 roc_auc=0.511354965162 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faea0294bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.eval()\n",
    "# Validation data\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "\n",
    "X_tensor_val= XnumpyToTensor(valX)\n",
    "Y_tensor_val= YnumpyToTensor(valY)\n",
    "\n",
    "\n",
    "print(type(X_tensor_val.data), type(Y_tensor_val.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "predicted_val = (net(X_tensor_val).data).float() # probabilities \n",
    "# predicted_val = (net(X_tensor_val).data > 0.5).float() # zero or one\n",
    "pred_y = predicted_val.cpu().numpy()\n",
    "target_y = Y_tensor_val.cpu().data.numpy()                \n",
    "\n",
    "print (type(pred_y))\n",
    "print (type(target_y))\n",
    "\n",
    "tu = (str ((pred_y == target_y).mean()),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "print ('\\n')\n",
    "print ('acc={} log_loss={} roc_auc={} '.format(*tu))\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# print (pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Submission on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45647, 466)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97040.0</td>\n",
       "      <td>0.506129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65399.0</td>\n",
       "      <td>0.495034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147258.0</td>\n",
       "      <td>0.495502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129573.0</td>\n",
       "      <td>0.511481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134978.0</td>\n",
       "      <td>0.502847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  probability\n",
       "0   97040.0     0.506129\n",
       "1   65399.0     0.495034\n",
       "2  147258.0     0.495502\n",
       "3  129573.0     0.511481\n",
       "4  134978.0     0.502847"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testX, df_test_set\n",
    "# df[df.columns.difference(['b'])]\n",
    "# trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "\n",
    "print (df_test_set.shape)\n",
    "columns = ['id', 'probability']\n",
    "df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n",
    "df_pred.id.astype(int)\n",
    "\n",
    "for index, row in df_test_set.iterrows():\n",
    "    rwo_no_id=row.drop('id')    \n",
    "#     print (rwo_no_id.values)    \n",
    "    x_data_np = np.array(rwo_no_id.values, dtype=np.float32)        \n",
    "    if use_cuda:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "                    \n",
    "    X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n",
    "    predicted_val = (net(X_tensor_test).data).float() # probabilities     \n",
    "    p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n",
    "    \n",
    "    df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n",
    "    \n",
    "# p_test =   pd.DataFrame (p_test, columns=['probability'])\n",
    "\n",
    "# # df_pred = df_test_set.append(p_test, ignore_index=True)\n",
    "# df_pred = pd.concat([p_test, df_test_set], axis=0, ignore_index=True)\n",
    "\n",
    "# # # df_pred = pd.DataFrame({\n",
    "# # #     'id': df_test_set['id'],\n",
    "# # #     'probability': p_test[:,1]\n",
    "# # # })\n",
    "\n",
    "df_pred.head(5)\n",
    "\n",
    "# df_test_set = pd.concat([tid_1_SINGLE, df_test_set], axis=1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/pred_0.693027365405_1504471688.79.csv\n"
     ]
    }
   ],
   "source": [
    "df_pred.id=df_pred.id.astype(int)\n",
    "\n",
    "def savePred(df_pred, loss):\n",
    "#     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n",
    "    csv_path = 'pred/pred_{}_{}.csv'.format(loss, (str(time.time())))\n",
    "    df_pred.to_csv(csv_path, columns=('id', 'probability'), index=None)\n",
    "    print (csv_path)\n",
    "    \n",
    "savePred (df_pred, log_loss(target_y, pred_y))    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
