{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 18  PyTorch NUMER.AI  Deep Learning Binary Classification using BCELoss \n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "- This tutorial was written in order to demonstrate a **fully working** example of a PyTorch NN on a real world use case, namely a Binary Classification problem. If you are interested in the sk-learn version of this problem please refer to: https://github.com/QuantScientist/deep-ml-meetups/tree/master/hacking-kaggle/python/numer-ai \n",
    "\n",
    "- For the scientific foundation behind Binary Classification and Logistic Regression, refer to: https://github.com/QuantScientist/deep-ml-meetups/blob/master/data-science-interviews/imp-ans.pdf\n",
    "\n",
    "- Every step, from reading the CSV into numpy arrays, converting to GPU based tensors, training and validation, are meant to aid newcomers in their first steps in PyTorch. \n",
    "\n",
    "- Additionally, commonly used Kaggle metrics such as ROC_AUC and LOG_LOSS are logged and plotted both for the training set as well as for the validation set. \n",
    "\n",
    "- Thus, the NN architecture is naive and by any means **unoptimized**. Hopefully, I will improve it over time and I am working on a second CNN based version of the same problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Data\n",
    "- Download from https://numer.ai/leaderboard\n",
    "\n",
    "<img src=\"../images/Numerai.png\" width=\"35%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "__pyTorch VERSION: 0.2.0+42448cf\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "OS:  linux2\n",
      "Python:  2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "PyTorch:  0.2.0+42448cf\n",
      "Numpy:  1.13.1\n",
      "2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "0.0\n",
      "svmem(total=67469099008, available=63134949376, percent=6.4, used=3730501632, free=61150445568, active=4437622784, inactive=1223413760, buffers=284803072, cached=2303348736, shared=55218176)\n",
      "memory GB: 0.221778869629\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "# %%timeit\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import logging\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "\n",
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install psutil\n",
    "import psutil\n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "\n",
    "cpuStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:USE CUDA=True\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "lgr.info(\"USE CUDA=\" + str (use_cuda))\n",
    "\n",
    "# ! watch -n 0.1 'ps f -o user,pgrp,pid,pcpu,pmem,start,time,command -p `lsof -n -w -t /dev/nvidia*`'\n",
    "# sudo apt-get install dstat #install dstat\n",
    "# sudo pip install nvidia-ml-py #install Python NVIDIA Management Library\n",
    "# wget https://raw.githubusercontent.com/datumbox/dstat/master/plugins/dstat_nvidia_gpu.py\n",
    "# sudo mv dstat_nvidia_gpu.py /usr/share/dstat/ #move file to the plugins directory of dstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN params\n",
    "DROPOUT_PROB = 0.75\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.005\n",
    "MOMENTUM= 0.9\n",
    "PIN_MEMORY=use_cuda # True IF CUDA\n",
    "\n",
    "# Data params\n",
    "TARGET_VAR= 'target'\n",
    "TOURNAMENT_DATA_CSV = 'numerai_tournament_data.csv'\n",
    "TRAINING_DATA_CSV = 'numerai_training_data.csv'\n",
    "BASE_FOLDER = 'numerai/'\n",
    "\n",
    "# fix seed\n",
    "seed=17*19\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Load a CSV file for Binary classification (numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135682</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.53352</td>\n",
       "      <td>0.64336</td>\n",
       "      <td>0.46577</td>\n",
       "      <td>0.53001</td>\n",
       "      <td>0.55734</td>\n",
       "      <td>0.45773</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51224</td>\n",
       "      <td>0.50484</td>\n",
       "      <td>0.41929</td>\n",
       "      <td>0.50954</td>\n",
       "      <td>0.47383</td>\n",
       "      <td>0.48797</td>\n",
       "      <td>0.38373</td>\n",
       "      <td>0.46233</td>\n",
       "      <td>0.33341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110546</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.54196</td>\n",
       "      <td>0.81576</td>\n",
       "      <td>0.46632</td>\n",
       "      <td>0.62320</td>\n",
       "      <td>0.52427</td>\n",
       "      <td>0.64378</td>\n",
       "      <td>0.55662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52643</td>\n",
       "      <td>0.63809</td>\n",
       "      <td>0.67121</td>\n",
       "      <td>0.49421</td>\n",
       "      <td>0.45291</td>\n",
       "      <td>0.46932</td>\n",
       "      <td>0.54445</td>\n",
       "      <td>0.30997</td>\n",
       "      <td>0.19023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76047</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.49158</td>\n",
       "      <td>0.69131</td>\n",
       "      <td>0.57816</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.43064</td>\n",
       "      <td>0.49986</td>\n",
       "      <td>0.61902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43310</td>\n",
       "      <td>0.72286</td>\n",
       "      <td>0.76257</td>\n",
       "      <td>0.36600</td>\n",
       "      <td>0.55330</td>\n",
       "      <td>0.56566</td>\n",
       "      <td>0.67528</td>\n",
       "      <td>0.34960</td>\n",
       "      <td>0.25721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66098</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.54519</td>\n",
       "      <td>0.42473</td>\n",
       "      <td>0.63472</td>\n",
       "      <td>0.39003</td>\n",
       "      <td>0.37485</td>\n",
       "      <td>0.43810</td>\n",
       "      <td>0.59557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41658</td>\n",
       "      <td>0.63417</td>\n",
       "      <td>0.50189</td>\n",
       "      <td>0.40883</td>\n",
       "      <td>0.58705</td>\n",
       "      <td>0.63785</td>\n",
       "      <td>0.56225</td>\n",
       "      <td>0.55989</td>\n",
       "      <td>0.58642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88227</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.44307</td>\n",
       "      <td>0.74076</td>\n",
       "      <td>0.52210</td>\n",
       "      <td>0.56543</td>\n",
       "      <td>0.51125</td>\n",
       "      <td>0.66457</td>\n",
       "      <td>0.42263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45851</td>\n",
       "      <td>0.58805</td>\n",
       "      <td>0.49860</td>\n",
       "      <td>0.48023</td>\n",
       "      <td>0.52606</td>\n",
       "      <td>0.53253</td>\n",
       "      <td>0.38361</td>\n",
       "      <td>0.43829</td>\n",
       "      <td>0.25014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   era data_type  feature1  feature2  feature3  feature4  feature5  \\\n",
       "0  135682  era1     train   0.53352   0.64336   0.46577   0.53001   0.55734   \n",
       "1  110546  era1     train   0.54196   0.81576   0.46632   0.62320   0.52427   \n",
       "2   76047  era1     train   0.49158   0.69131   0.57816   0.54010   0.43064   \n",
       "3   66098  era1     train   0.54519   0.42473   0.63472   0.39003   0.37485   \n",
       "4   88227  era1     train   0.44307   0.74076   0.52210   0.56543   0.51125   \n",
       "\n",
       "   feature6  feature7   ...    feature13  feature14  feature15  feature16  \\\n",
       "0   0.45773   0.41169   ...      0.51224    0.50484    0.41929    0.50954   \n",
       "1   0.64378   0.55662   ...      0.52643    0.63809    0.67121    0.49421   \n",
       "2   0.49986   0.61902   ...      0.43310    0.72286    0.76257    0.36600   \n",
       "3   0.43810   0.59557   ...      0.41658    0.63417    0.50189    0.40883   \n",
       "4   0.66457   0.42263   ...      0.45851    0.58805    0.49860    0.48023   \n",
       "\n",
       "   feature17  feature18  feature19  feature20  feature21  target  \n",
       "0    0.47383    0.48797    0.38373    0.46233    0.33341       0  \n",
       "1    0.45291    0.46932    0.54445    0.30997    0.19023       0  \n",
       "2    0.55330    0.56566    0.67528    0.34960    0.25721       1  \n",
       "3    0.58705    0.63785    0.56225    0.55989    0.58642       0  \n",
       "4    0.52606    0.53253    0.38361    0.43829    0.25014       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Feature enrichement\n",
    "- This would be usually not required when using NN's; it is here for demonstration purposes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genBasicFeatures(inDF):\n",
    "    print('Generating basic features ...')\n",
    "    df_copy=inDF.copy(deep=True)\n",
    "    magicNumber=21\n",
    "    feature_cols = list(inDF.columns)\n",
    "\n",
    "    inDF['x_mean'] = np.mean(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_median'] = np.median(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_std'] = np.std(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_skew'] = scipy.stats.skew(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_kurt'] = scipy.stats.kurtosis(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_var'] = np.var(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_max'] = np.max(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_min'] = np.min(df_copy.ix[:, 0:magicNumber], axis=1)    \n",
    "\n",
    "    return inDF\n",
    "\n",
    "def addPolyFeatures(inDF, deg=2):\n",
    "    print('Generating poly features ...')\n",
    "    df_copy=inDF.copy(deep=True)\n",
    "    poly=PolynomialFeatures(degree=deg)\n",
    "    p_testX = poly.fit(df_copy)\n",
    "    # AttributeError: 'PolynomialFeatures' object has no attribute 'get_feature_names'\n",
    "    target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(df_copy.columns,p) for p in poly.powers_]]\n",
    "    df_copy = pd.DataFrame(p_testX.transform(df_copy),columns=target_feature_names)\n",
    "        \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Train / Validation / Test Split\n",
    "- Numerai provides a data set that is allready split into train, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train, Validation, Test Split\n",
    "def loadDataSplit():\n",
    "    df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    df_test_valid = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "\n",
    "    answers_1_SINGLE = df_train[TARGET_VAR]\n",
    "    df_train.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    df_train.drop('id', axis=1,inplace=True)\n",
    "    df_train.drop('era', axis=1,inplace=True)\n",
    "    df_train.drop('data_type', axis=1,inplace=True)    \n",
    "    \n",
    "    # Add polynomial features    \n",
    "    df_train=genBasicFeatures(df_train)\n",
    "#     df_train = addPolyFeatures(df_train)\n",
    "\n",
    "    df_train.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=False,  index = False)    \n",
    "    df_train= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=None, dtype=np.float32)    \n",
    "    df_train = pd.concat([df_train, answers_1_SINGLE], axis=1)\n",
    "    feature_cols = list(df_train.columns[:-1])\n",
    "#     print (feature_cols)\n",
    "    target_col = df_train.columns[-1]\n",
    "    trainX, trainY = df_train[feature_cols], df_train[target_col]\n",
    "    \n",
    "    \n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    # Validation set\n",
    "    df_validation_set=df_test_valid.loc[df_test_valid['data_type'] == 'validation'] \n",
    "    df_validation_set=df_validation_set.copy(deep=True)\n",
    "    answers_1_SINGLE_validation = df_validation_set[TARGET_VAR]\n",
    "    df_validation_set.drop(TARGET_VAR, axis=1,inplace=True)    \n",
    "    df_validation_set.drop('id', axis=1,inplace=True)\n",
    "    df_validation_set.drop('era', axis=1,inplace=True)\n",
    "    df_validation_set.drop('data_type', axis=1,inplace=True)\n",
    "    \n",
    "   # Add polynomial features    \n",
    "    df_validation_set=genBasicFeatures(df_validation_set)\n",
    "#     df_validation_set = addPolyFeatures(df_validation_set)\n",
    "    \n",
    "    df_validation_set.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=False,  index = False)    \n",
    "    df_validation_set= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=None, dtype=np.float32)    \n",
    "    df_validation_set = pd.concat([df_validation_set, answers_1_SINGLE_validation], axis=1)\n",
    "    feature_cols = list(df_validation_set.columns[:-1])\n",
    "\n",
    "    target_col = df_validation_set.columns[-1]\n",
    "    valX, valY = df_validation_set[feature_cols], df_validation_set[target_col]\n",
    "                            \n",
    "    # Test set for submission (not labeled)    \n",
    "    df_test_set = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "#     df_test_set=df_test_set.loc[df_test_valid['data_type'] == 'live'] \n",
    "    df_test_set=df_test_set.copy(deep=True)\n",
    "    df_test_set.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    tid_1_SINGLE = df_test_set['id']\n",
    "    df_test_set.drop('id', axis=1,inplace=True)\n",
    "    df_test_set.drop('era', axis=1,inplace=True)\n",
    "    df_test_set.drop('data_type', axis=1,inplace=True)   \n",
    "    \n",
    "    # Add polynomial features    \n",
    "    df_test_set=genBasicFeatures(df_test_set)\n",
    "#     df_test_set = addPolyFeatures(df_test_set)\n",
    "   \n",
    "    \n",
    "    feature_cols = list(df_test_set.columns) # must be run here, we dont want the ID    \n",
    "#     print (feature_cols)\n",
    "    df_test_set = pd.concat([tid_1_SINGLE, df_test_set], axis=1)            \n",
    "    testX = df_test_set[feature_cols].values\n",
    "        \n",
    "    return trainX, trainY, valX, valY, testX, df_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating basic features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating basic features ...\n",
      "Generating basic features ...\n",
      "(108405, 29)\n",
      "(108405,)\n",
      "(16686, 29)\n",
      "(16686,)\n",
      "(45647, 29)\n",
      "(45647, 30)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "# X, y = loadDataSplit(999)\n",
    "\n",
    "\n",
    "# # Number of features for the input layer\n",
    "N_FEATURES=trainX.shape[1]\n",
    "# print (trainX.head(3))\n",
    "# print (df_test_set.head(3))\n",
    "print (trainX.shape)\n",
    "print (trainY.shape)\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "print (testX.shape)\n",
    "print (df_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create PyTorch GPU tensors from numpy arrays\n",
    "\n",
    "- Note how we transfrom the np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def XnumpyToTensor(x_data_np):\n",
    "    x_data_np = np.array(x_data_np.values, dtype=np.float32)        \n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")    \n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")\n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "    \n",
    "    print(type(X_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))    \n",
    "    return X_tensor\n",
    "\n",
    "\n",
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def YnumpyToTensor(y_data_np):    \n",
    "    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")            \n",
    "    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")        \n",
    "    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n",
    "\n",
    "    print(type(Y_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))    \n",
    "    return Y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The NN model\n",
    "\n",
    "### MLP model\n",
    "- A multilayer perceptron is a logistic regressor where instead of feeding the input to the logistic regression you insert a intermediate layer, called the hidden layer, that has a nonlinear activation function (usually tanh or sigmoid) . One can use many such hidden layers making the architecture deep.\n",
    "\n",
    "- Here we define a simple MLP structure. We map the input feature vector to a higher space, then later gradually decrease the dimension, and in the end into a 1-dimension space. Because we are calculating the probability of each genre independently, after the final layer we need to use a sigmoid layer. \n",
    "\n",
    "###  Initial weights selection\n",
    "\n",
    "- There are many ways to select the initial weights to a neural network architecture. A common initialization scheme is random initialization, which sets the biases and weights of all the nodes in each hidden layer randomly.\n",
    "\n",
    "- Before starting the training process, an initial value is assigned to each variable. This is done by pure randomness, using for example a uniform or Gaussian distribution. But if we start with weights that are too small, the signal could decrease so much that it is too small to be useful. On the other side, when the parameters are initialized with high values, the signal can end up to explode while propagating through the network.\n",
    "\n",
    "- In consequence, a good initialization can have a radical effect on how fast the network will learn useful patterns.For this purpose, some best practices have been developed. One famous example used is **Xavier initialization**. Its formulation is based on the number of input and output neurons and uses sampling from a uniform distribution with zero mean and all biases set to zero.\n",
    "\n",
    "- In effect (according to theory) initializing the weights of the network to values that would be closer to the optimal, and therefore require less epochs to train.\n",
    "\n",
    "### References: \n",
    "* **`nninit.xavier_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a uniform distribution.\n",
    "* **`nninit.xavier_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a normal distribution.\n",
    "* **`nninit.kaiming_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.](https://arxiv.org/abs/1502.01852) using a uniform distribution.\n",
    "* **`nninit.kaiming_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (29 -> 1024)\n",
      "  (1): Dropout (p = 0.05)\n",
      "  (2): Tanh ()\n",
      "  (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (4): Linear (1024 -> 128)\n",
      "  (5): Dropout (p = 0.05)\n",
      "  (6): Tanh ()\n",
      "  (7): Linear (128 -> 64)\n",
      "  (8): Dropout (p = 0.05)\n",
      "  (9): LeakyReLU (0.01)\n",
      "  (10): Linear (64 -> 32)\n",
      "  (11): Dropout (p = 0.05)\n",
      "  (12): Tanh ()\n",
      "  (13): Linear (32 -> 16)\n",
      "  (14): Dropout (p = 0.05)\n",
      "  (15): LeakyReLU (0.01)\n",
      "  (16): Linear (16 -> 1)\n",
      "  (17): Sigmoid ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# p is the probability of being dropped in PyTorch\n",
    "# At each layer, DECREASE dropout\n",
    "dropout = torch.nn.Dropout(p=1 - (DROPOUT_PROB +0.20))\n",
    "\n",
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, n_feature, n_hidden, n_output,initKernel='uniform'):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "#         self.out = torch.nn.Linear(n_hidden, n_output)   # output layer        \n",
    "        \n",
    "#         # xavier initializer\n",
    "#         if initKernel == 'uniform':\n",
    "#             nn.init.xavier_uniform(self.hidden.weight, gain=np.sqrt(2.0))\n",
    "#         else:\n",
    "#             nn.init.kaiming_normal(self.hidden.weight)           \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "#         x = self.out(x)\n",
    "#         return F.sigmoid(x)\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output,initKernel='uniform'):\n",
    "        super(Net2, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(n_feature, n_hidden),\n",
    "            dropout,\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            dropout,\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "            dropout,\n",
    "            nn.Sigmoid()\n",
    "        )        \n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "hiddenLayer1Size=1024\n",
    "hiddenLayer2Size=int(hiddenLayer1Size/8)\n",
    "hiddenLayer3Size=int(hiddenLayer1Size/16)\n",
    "hiddenLayer4Size=int(hiddenLayer1Size/32)\n",
    "hiddenLayer5Size=int(hiddenLayer1Size/64)\n",
    "\n",
    "# # Hypothesis using sigmoid\n",
    "linear1=torch.nn.Linear(N_FEATURES, hiddenLayer1Size, bias=True) \n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "\n",
    "linear2=torch.nn.Linear(hiddenLayer1Size, hiddenLayer2Size)\n",
    "torch.nn.init.xavier_uniform(linear2.weight)\n",
    "\n",
    "linear3=torch.nn.Linear(hiddenLayer2Size, hiddenLayer3Size)\n",
    "torch.nn.init.xavier_uniform(linear3.weight)\n",
    "\n",
    "linear4=torch.nn.Linear(hiddenLayer3Size, hiddenLayer4Size)\n",
    "torch.nn.init.xavier_uniform(linear4.weight)\n",
    "\n",
    "linear5=torch.nn.Linear(hiddenLayer4Size, hiddenLayer5Size)\n",
    "torch.nn.init.xavier_uniform(linear5.weight)\n",
    "\n",
    "linear6=torch.nn.Linear(hiddenLayer5Size, 1)\n",
    "torch.nn.init.xavier_uniform(linear6.weight)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "tanh=torch.nn.Tanh()\n",
    "relu=torch.nn.LeakyReLU()\n",
    "\n",
    "net = torch.nn.Sequential(linear1,dropout,tanh,nn.BatchNorm1d(hiddenLayer1Size),\n",
    "                          linear2,dropout,tanh,\n",
    "                          linear3,dropout,relu,\n",
    "                          linear4,dropout,tanh,\n",
    "                          linear5,dropout,relu,\n",
    "                          linear6,sigmoid\n",
    "                          )\n",
    "\n",
    "# net = Net(n_feature=N_FEATURES, n_hidden=1024, n_output=1)   # define the network\n",
    "# net = Net2(n_feature=N_FEATURES, n_hidden=2048, n_output=1)   # define the network\n",
    "\n",
    "lgr.info(net)  # net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Print the full net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (29 -> 1024), weights=((1024L, 29L), (1024L,)), parameters=30720\n",
      "  (1): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (2): Tanh (), weights=(), parameters=0\n",
      "  (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True), weights=((1024L,), (1024L,)), parameters=2048\n",
      "  (4): Linear (1024 -> 128), weights=((128L, 1024L), (128L,)), parameters=131200\n",
      "  (5): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (6): Tanh (), weights=(), parameters=0\n",
      "  (7): Linear (128 -> 64), weights=((64L, 128L), (64L,)), parameters=8256\n",
      "  (8): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (9): LeakyReLU (0.01), weights=(), parameters=0\n",
      "  (10): Linear (64 -> 32), weights=((32L, 64L), (32L,)), parameters=2080\n",
      "  (11): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (12): Tanh (), weights=(), parameters=0\n",
      "  (13): Linear (32 -> 16), weights=((16L, 32L), (16L,)), parameters=528\n",
      "  (14): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (15): LeakyReLU (0.01), weights=(), parameters=0\n",
      "  (16): Linear (16 -> 1), weights=((1L, 16L), (1L,)), parameters=17\n",
      "  (17): Sigmoid (), weights=(), parameters=0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Taken from https://stackoverflow.com/questions/42480111/model-summary-in-pytorch/42616812\n",
    "from torch.nn.modules.module import _addindent\n",
    "import torch\n",
    "import numpy as np\n",
    "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
    "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
    "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
    "    for key, module in model._modules.items():\n",
    "        # if it contains layers let call it recursively to get params and weights\n",
    "        if type(module) in [\n",
    "            torch.nn.modules.container.Container,\n",
    "            torch.nn.modules.container.Sequential\n",
    "        ]:\n",
    "            modstr = torch_summarize(module)\n",
    "        else:\n",
    "            modstr = module.__repr__()\n",
    "        modstr = _addindent(modstr, 2)\n",
    "\n",
    "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
    "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
    "\n",
    "        tmpstr += '  (' + key + '): ' + modstr \n",
    "        if show_weights:\n",
    "            tmpstr += ', weights={}'.format(weights)\n",
    "        if show_parameters:\n",
    "            tmpstr +=  ', parameters={}'.format(params)\n",
    "        tmpstr += '\\n'   \n",
    "\n",
    "    tmpstr = tmpstr + ')'\n",
    "    return tmpstr\n",
    "\n",
    "lgr.info(torch_summarize(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Loss and Optimizer\n",
    "\n",
    "###  BCELoss\n",
    "- In addition, we will calculate the binary cross entropy loss (BCELoss). Luckily we have one loss function already present. For details please checkout http://pytorch.org/docs/master/nn.html. \n",
    "\n",
    "- ** NOTE this BCELoss may not be numerical stable, although it's fine during my training process.**\n",
    "\n",
    "### Optimization\n",
    "\n",
    "- if return F.log_softmax(x) then loss = F.nll_loss(output, target) (MNIST)\n",
    "- print(nn.BCEWithLogitsLoss()(o, t)) is equivalent to print(nn.BCELoss()(sigmoid(o), t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ! pip install sympy\n",
    "import sympy as sp\n",
    "sp.interactive.printing.init_printing(use_latex=True)\n",
    "from IPython.display import display, Math, Latex\n",
    "maths = lambda s: display(Math(s))\n",
    "latex = lambda s: display(Latex(s))\n",
    "\n",
    "#the loss function is as follows:\n",
    "maths(\"\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "INFO:__main__:<torch.optim.adam.Adam object at 0x7ff6645bca50>\n",
      "INFO:__main__:BCELoss (\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.02)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=5e-4)\n",
    "\n",
    "#L2 regularization can easily be added to the entire model via the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-4) #  L2 regularization\n",
    "# optimizer = torch.optim.Adagrad(net.parameters(), lr=1e-6, weight_decay=5e-4)\n",
    "# loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted\n",
    "# loss_func = torch.nn.NLLLoss()\n",
    "loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "# http://andersonjo.github.io/artificial-intelligence/2017/01/07/Cost-Functions/\n",
    "# use_cuda=True\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    net.cuda()\n",
    "    loss_func.cuda()\n",
    "#     cudnn.benchmark = True\n",
    "    #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "lgr.info (optimizer)\n",
    "lgr.info (loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Training in batches  + Measuring the performance of the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108405, 29)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(108405, 29)\n",
      "<type 'numpy.ndarray'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "0 [ 0.70716488]\n",
      "ACC=0.0, LOG_LOSS=0.766747095448, ROC_AUC=0.507757413808 \n",
      "50 [ 0.69321531]\n",
      "ACC=0.0, LOG_LOSS=0.693099017203, ROC_AUC=0.508817884698 \n",
      "100 [ 0.69237965]\n",
      "ACC=0.0, LOG_LOSS=0.692342355838, ROC_AUC=0.522425978029 \n",
      "150 [ 0.69220853]\n",
      "ACC=0.0, LOG_LOSS=0.692171435117, ROC_AUC=0.523551871579 \n",
      "200 [ 0.69217032]\n",
      "ACC=0.0, LOG_LOSS=0.692143617875, ROC_AUC=0.523518494679 \n",
      "250 [ 0.6922496]\n",
      "ACC=0.0, LOG_LOSS=0.692289536093, ROC_AUC=0.522184032219 \n",
      "300 [ 0.69223887]\n",
      "ACC=0.0, LOG_LOSS=0.692351439315, ROC_AUC=0.520347379332 \n",
      "350 [ 0.69229358]\n",
      "ACC=0.0, LOG_LOSS=0.692250174643, ROC_AUC=0.522676407842 \n",
      "400 [ 0.69226164]\n",
      "ACC=0.0, LOG_LOSS=0.692275639234, ROC_AUC=0.520552366024 \n",
      "450 [ 0.69228256]\n",
      "ACC=0.0, LOG_LOSS=0.692273849778, ROC_AUC=0.522025400074 \n",
      "GPU: 354.271 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff68ffa9f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6645743d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()    \n",
    "epochs=250 # change to 1500 for better results\n",
    "all_losses = []\n",
    "\n",
    "X_tensor_train= XnumpyToTensor(trainX)\n",
    "Y_tensor_train= YnumpyToTensor(trainY)\n",
    "\n",
    "print(type(X_tensor_train.data), type(Y_tensor_train.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "# From here onwards, we must only use PyTorch Tensors\n",
    "for step in range(epochs):    \n",
    "    out = net(X_tensor_train)                 # input x and predict based on x\n",
    "    cost = loss_func(out, Y_tensor_train)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    cost.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "                   \n",
    "        \n",
    "    if step % 50 == 0:        \n",
    "        loss = cost.data[0]\n",
    "        all_losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "        # Use .cpu() to move the tensor to host memory first.        \n",
    "        prediction = (net(X_tensor_train).data).float() # probabilities         \n",
    "#         prediction = (net(X_tensor).data > 0.5).float() # zero or one\n",
    "#         print (\"Pred:\" + str (prediction)) # Pred:Variable containing: 0 or 1\n",
    "#         pred_y = prediction.data.numpy().squeeze()            \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = Y_tensor_train.cpu().data.numpy()\n",
    "                        \n",
    "        tu = ((pred_y == target_y).mean(),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "        print ('ACC={}, LOG_LOSS={}, ROC_AUC={} '.format(*tu))        \n",
    "                \n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Performance of the deep learning model on the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16686, 29)\n",
      "(16686,)\n",
      "(16686, 29)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(16686, 29)\n",
      "<type 'numpy.ndarray'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "acc=0.0 log_loss=0.693924313567 roc_auc=0.522455062657 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCmOMMUFZojDGGBPU/wOkpCcqB/R+RgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6643a9650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.eval()\n",
    "# Validation data\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "\n",
    "X_tensor_val= XnumpyToTensor(valX)\n",
    "Y_tensor_val= YnumpyToTensor(valY)\n",
    "\n",
    "\n",
    "print(type(X_tensor_val.data), type(Y_tensor_val.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "predicted_val = (net(X_tensor_val).data).float() # probabilities \n",
    "# predicted_val = (net(X_tensor_val).data > 0.5).float() # zero or one\n",
    "pred_y = predicted_val.cpu().numpy()\n",
    "target_y = Y_tensor_val.cpu().data.numpy()                \n",
    "\n",
    "print (type(pred_y))\n",
    "print (type(target_y))\n",
    "\n",
    "tu = (str ((pred_y == target_y).mean()),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "print ('\\n')\n",
    "print ('acc={} log_loss={} roc_auc={} '.format(*tu))\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# print (pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Submission on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45647, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97040.0</td>\n",
       "      <td>0.519708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65399.0</td>\n",
       "      <td>0.517178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147258.0</td>\n",
       "      <td>0.518780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129573.0</td>\n",
       "      <td>0.519850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134978.0</td>\n",
       "      <td>0.522069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  probability\n",
       "0   97040.0     0.519708\n",
       "1   65399.0     0.517178\n",
       "2  147258.0     0.518780\n",
       "3  129573.0     0.519850\n",
       "4  134978.0     0.522069"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testX, df_test_set\n",
    "# df[df.columns.difference(['b'])]\n",
    "# trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "\n",
    "print (df_test_set.shape)\n",
    "columns = ['id', 'probability']\n",
    "df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n",
    "df_pred.id.astype(int)\n",
    "\n",
    "for index, row in df_test_set.iterrows():\n",
    "    rwo_no_id=row.drop('id')    \n",
    "#     print (rwo_no_id.values)    \n",
    "    x_data_np = np.array(rwo_no_id.values, dtype=np.float32)        \n",
    "    if use_cuda:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "                    \n",
    "    X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n",
    "    predicted_val = (net(X_tensor_test).data).float() # probabilities     \n",
    "    p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n",
    "    \n",
    "    df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n",
    "\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create a CSV with the ID's and the coresponding probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/pred_0.693924313567_1504720448.33.csv\n"
     ]
    }
   ],
   "source": [
    "df_pred.id=df_pred.id.astype(int)\n",
    "\n",
    "def savePred(df_pred, loss):\n",
    "#     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n",
    "    csv_path = 'pred/pred_{}_{}.csv'.format(loss, (str(time.time())))\n",
    "    df_pred.to_csv(csv_path, columns=('id', 'probability'), index=None)\n",
    "    print (csv_path)\n",
    "    \n",
    "savePred (df_pred, log_loss(target_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
