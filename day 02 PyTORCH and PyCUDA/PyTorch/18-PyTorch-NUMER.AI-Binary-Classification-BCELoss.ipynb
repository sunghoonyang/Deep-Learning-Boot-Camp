{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 18  PyTorch NUMER.AI  Deep Learning Binary Classification using BCELoss \n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# What consists a Numerai competition?\n",
    "- Numerai provides payments based on the number of correctly predictted labels (LOGG_LOSS) in a data-set which changes every week.\n",
    "\n",
    "- Two data-sets are provided: numerai_training_data.csv and numerai_tournament_data.csv\n",
    "\n",
    "# Criteria \n",
    "- On top of LOG_LOSS, they also measure:\n",
    "* Consistency\n",
    "* Originality\t\n",
    "* Concordance \n",
    "\n",
    "\n",
    "# PyTorch and Numerai\n",
    "\n",
    "- This tutorial was written in order to demonstrate a **fully working** example of a PyTorch NN on a real world use case, namely a Binary Classification problem on the NumerAI data set. If you are interested in the sk-learn version of this problem please refer to: https://github.com/QuantScientist/deep-ml-meetups/tree/master/hacking-kaggle/python/numer-ai \n",
    "\n",
    "- For the scientific foundation behind Binary Classification and Logistic Regression, refer to: https://github.com/QuantScientist/Deep-Learning-Boot-Camp/tree/master/Data-Science-Interviews-Book\n",
    "\n",
    "- Every step, from reading the CSV into numpy arrays, converting to GPU based tensors, training and validation, are meant to aid newcomers in their first steps in PyTorch. \n",
    "\n",
    "- Additionally, commonly used Kaggle metrics such as ROC_AUC and LOG_LOSS are logged and plotted both for the training set as well as for the validation set. \n",
    "\n",
    "- Thus, the NN architecture is naive and by no means **optimized**. Hopefully, I will improve it over time and I am working on a second CNN based version of the same problem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Data\n",
    "- Download from https://numer.ai/leaderboard\n",
    "\n",
    "\n",
    "<img src=\"../images/numerai-logo.png\" width=\"35%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "__pyTorch VERSION: 0.2.0+42448cf\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 0\n",
      "__Devices\n",
      "OS:  linux2\n",
      "Python:  2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "PyTorch:  0.2.0+42448cf\n",
      "Numpy:  1.13.1\n",
      "2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "0.0\n",
      "svmem(total=67469099008, available=58820988928, percent=12.8, used=7999918080, free=54381559808, active=10602860544, inactive=1363619840, buffers=1100660736, cached=3986960384, shared=99926016)\n",
      "memory GB: 0.218952178955\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "# %%timeit\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import logging\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "\n",
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install psutil\n",
    "import psutil\n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "\n",
    "cpuStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:USE CUDA=False\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "lgr.info(\"USE CUDA=\" + str (use_cuda))\n",
    "\n",
    "# ! watch -n 0.1 'ps f -o user,pgrp,pid,pcpu,pmem,start,time,command -p `lsof -n -w -t /dev/nvidia*`'\n",
    "# sudo apt-get install dstat #install dstat\n",
    "# sudo pip install nvidia-ml-py #install Python NVIDIA Management Library\n",
    "# wget https://raw.githubusercontent.com/datumbox/dstat/master/plugins/dstat_nvidia_gpu.py\n",
    "# sudo mv dstat_nvidia_gpu.py /usr/share/dstat/ #move file to the plugins directory of dstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN params\n",
    "PIN_MEMORY=use_cuda # True IF CUDA\n",
    "\n",
    "# Data params\n",
    "TARGET_VAR= 'target'\n",
    "TOURNAMENT_DATA_CSV = 'numerai_tournament_data.csv'\n",
    "TRAINING_DATA_CSV = 'numerai_training_data.csv'\n",
    "BASE_FOLDER = 'numerai/'\n",
    "\n",
    "# fix seed\n",
    "seed=17*19\n",
    "np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Load a CSV file for Binary classification (numpy)\n",
    "\n",
    "As mentioned, NumerAI provided **numerai_training_data.csv** and **numerai_tournament_data.csv.**\n",
    "\n",
    "- Training_data.csv is labeled\n",
    "- Numerai_tournament_data.csv has lebles for the **validation set** and no labels for the **test set**. See belo how I seperate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72774</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.48937</td>\n",
       "      <td>0.56969</td>\n",
       "      <td>0.59150</td>\n",
       "      <td>0.46432</td>\n",
       "      <td>0.42291</td>\n",
       "      <td>0.49616</td>\n",
       "      <td>0.53542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42195</td>\n",
       "      <td>0.62651</td>\n",
       "      <td>0.51604</td>\n",
       "      <td>0.42938</td>\n",
       "      <td>0.56744</td>\n",
       "      <td>0.60008</td>\n",
       "      <td>0.46966</td>\n",
       "      <td>0.50322</td>\n",
       "      <td>0.42803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140123</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.57142</td>\n",
       "      <td>0.43408</td>\n",
       "      <td>0.58771</td>\n",
       "      <td>0.44570</td>\n",
       "      <td>0.41471</td>\n",
       "      <td>0.49137</td>\n",
       "      <td>0.52791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46301</td>\n",
       "      <td>0.55103</td>\n",
       "      <td>0.39053</td>\n",
       "      <td>0.48856</td>\n",
       "      <td>0.54305</td>\n",
       "      <td>0.59213</td>\n",
       "      <td>0.44935</td>\n",
       "      <td>0.56685</td>\n",
       "      <td>0.59645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46882</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.75694</td>\n",
       "      <td>0.59942</td>\n",
       "      <td>0.36154</td>\n",
       "      <td>0.65571</td>\n",
       "      <td>0.60520</td>\n",
       "      <td>0.45317</td>\n",
       "      <td>0.49847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68057</td>\n",
       "      <td>0.43763</td>\n",
       "      <td>0.46322</td>\n",
       "      <td>0.63211</td>\n",
       "      <td>0.32947</td>\n",
       "      <td>0.35632</td>\n",
       "      <td>0.56316</td>\n",
       "      <td>0.33888</td>\n",
       "      <td>0.40120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20833</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.46059</td>\n",
       "      <td>0.50856</td>\n",
       "      <td>0.64215</td>\n",
       "      <td>0.41382</td>\n",
       "      <td>0.39550</td>\n",
       "      <td>0.49282</td>\n",
       "      <td>0.54697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38108</td>\n",
       "      <td>0.65446</td>\n",
       "      <td>0.54926</td>\n",
       "      <td>0.36297</td>\n",
       "      <td>0.61482</td>\n",
       "      <td>0.64292</td>\n",
       "      <td>0.52910</td>\n",
       "      <td>0.53582</td>\n",
       "      <td>0.47027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5381</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.61195</td>\n",
       "      <td>0.66684</td>\n",
       "      <td>0.45877</td>\n",
       "      <td>0.56730</td>\n",
       "      <td>0.51889</td>\n",
       "      <td>0.41257</td>\n",
       "      <td>0.56030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54803</td>\n",
       "      <td>0.59120</td>\n",
       "      <td>0.58160</td>\n",
       "      <td>0.51828</td>\n",
       "      <td>0.43870</td>\n",
       "      <td>0.47011</td>\n",
       "      <td>0.56007</td>\n",
       "      <td>0.36374</td>\n",
       "      <td>0.31552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   era data_type  feature1  feature2  feature3  feature4  feature5  \\\n",
       "0   72774  era1     train   0.48937   0.56969   0.59150   0.46432   0.42291   \n",
       "1  140123  era1     train   0.57142   0.43408   0.58771   0.44570   0.41471   \n",
       "2   46882  era1     train   0.75694   0.59942   0.36154   0.65571   0.60520   \n",
       "3   20833  era1     train   0.46059   0.50856   0.64215   0.41382   0.39550   \n",
       "4    5381  era1     train   0.61195   0.66684   0.45877   0.56730   0.51889   \n",
       "\n",
       "   feature6  feature7   ...    feature13  feature14  feature15  feature16  \\\n",
       "0   0.49616   0.53542   ...      0.42195    0.62651    0.51604    0.42938   \n",
       "1   0.49137   0.52791   ...      0.46301    0.55103    0.39053    0.48856   \n",
       "2   0.45317   0.49847   ...      0.68057    0.43763    0.46322    0.63211   \n",
       "3   0.49282   0.54697   ...      0.38108    0.65446    0.54926    0.36297   \n",
       "4   0.41257   0.56030   ...      0.54803    0.59120    0.58160    0.51828   \n",
       "\n",
       "   feature17  feature18  feature19  feature20  feature21  target  \n",
       "0    0.56744    0.60008    0.46966    0.50322    0.42803       1  \n",
       "1    0.54305    0.59213    0.44935    0.56685    0.59645       1  \n",
       "2    0.32947    0.35632    0.56316    0.33888    0.40120       0  \n",
       "3    0.61482    0.64292    0.52910    0.53582    0.47027       0  \n",
       "4    0.43870    0.47011    0.56007    0.36374    0.31552       1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Feature enrichement\n",
    "- This would be usually not required when using NN's; it is here for demonstration purposes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def genBasicFeatures(inDF):\n",
    "#     print('Generating basic features ...')\n",
    "#     df_copy=inDF.copy(deep=True)\n",
    "#     magicNumber=21\n",
    "#     feature_cols = list(inDF.columns)\n",
    "\n",
    "#     inDF['x_mean'] = np.mean(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_median'] = np.median(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_std'] = np.std(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_skew'] = scipy.stats.skew(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_kurt'] = scipy.stats.kurtosis(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_var'] = np.var(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_max'] = np.max(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_min'] = np.min(df_copy.ix[:, 0:magicNumber], axis=1)    \n",
    "\n",
    "#     return inDF\n",
    "\n",
    "def addPolyFeatures(inDF, deg=2):\n",
    "    print('Generating poly features ...')\n",
    "    df_copy=inDF.copy(deep=True)\n",
    "    poly=PolynomialFeatures(degree=deg)\n",
    "    p_testX = poly.fit(df_copy)\n",
    "    # AttributeError: 'PolynomialFeatures' object has no attribute 'get_feature_names'\n",
    "    target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(df_copy.columns,p) for p in poly.powers_]]\n",
    "    df_copy = pd.DataFrame(p_testX.transform(df_copy),columns=target_feature_names)\n",
    "        \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Train / Validation / Test Split\n",
    "- Numerai provides a data set that is allready split into train, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train, Validation, Test Split\n",
    "def loadDataSplit():\n",
    "    df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    df_test_valid = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "\n",
    "    answers_1_SINGLE = df_train[TARGET_VAR]\n",
    "    df_train.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    df_train.drop('id', axis=1,inplace=True)\n",
    "    df_train.drop('era', axis=1,inplace=True)\n",
    "    df_train.drop('data_type', axis=1,inplace=True)    \n",
    "    \n",
    "    # Add polynomial features    \n",
    "#     df_train=genBasicFeatures(df_train)\n",
    "#     df_train = addPolyFeatures(df_train)\n",
    "\n",
    "    df_train.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=False,  index = False)    \n",
    "    df_train= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=None, dtype=np.float32)    \n",
    "    df_train = pd.concat([df_train, answers_1_SINGLE], axis=1)\n",
    "    feature_cols = list(df_train.columns[:-1])\n",
    "#     print (feature_cols)\n",
    "    target_col = df_train.columns[-1]\n",
    "    trainX, trainY = df_train[feature_cols], df_train[target_col]\n",
    "    \n",
    "    \n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    # Validation set\n",
    "    df_validation_set=df_test_valid.loc[df_test_valid['data_type'] == 'validation'] \n",
    "    df_validation_set=df_validation_set.copy(deep=True)\n",
    "    answers_1_SINGLE_validation = df_validation_set[TARGET_VAR]\n",
    "    df_validation_set.drop(TARGET_VAR, axis=1,inplace=True)    \n",
    "    df_validation_set.drop('id', axis=1,inplace=True)\n",
    "    df_validation_set.drop('era', axis=1,inplace=True)\n",
    "    df_validation_set.drop('data_type', axis=1,inplace=True)\n",
    "    \n",
    "   # Add polynomial features    \n",
    "#     df_validation_set=genBasicFeatures(df_validation_set)\n",
    "#     df_validation_set = addPolyFeatures(df_validation_set)\n",
    "    \n",
    "    df_validation_set.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=False,  index = False)    \n",
    "    df_validation_set= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=None, dtype=np.float32)    \n",
    "    df_validation_set = pd.concat([df_validation_set, answers_1_SINGLE_validation], axis=1)\n",
    "    feature_cols = list(df_validation_set.columns[:-1])\n",
    "\n",
    "    target_col = df_validation_set.columns[-1]\n",
    "    valX, valY = df_validation_set[feature_cols], df_validation_set[target_col]\n",
    "                            \n",
    "    # Test set for submission (not labeled)    \n",
    "    df_test_set = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "#     df_test_set=df_test_set.loc[df_test_valid['data_type'] == 'live'] \n",
    "    df_test_set=df_test_set.copy(deep=True)\n",
    "    df_test_set.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    tid_1_SINGLE = df_test_set['id']\n",
    "    df_test_set.drop('id', axis=1,inplace=True)\n",
    "    df_test_set.drop('era', axis=1,inplace=True)\n",
    "    df_test_set.drop('data_type', axis=1,inplace=True)   \n",
    "    \n",
    "    # Add polynomial features    \n",
    "#     df_test_set=genBasicFeatures(df_test_set)\n",
    "#     df_test_set = addPolyFeatures(df_test_set)\n",
    "   \n",
    "    \n",
    "    feature_cols = list(df_test_set.columns) # must be run here, we dont want the ID    \n",
    "#     print (feature_cols)\n",
    "    df_test_set = pd.concat([tid_1_SINGLE, df_test_set], axis=1)            \n",
    "    testX = df_test_set[feature_cols].values\n",
    "        \n",
    "    return trainX, trainY, valX, valY, testX, df_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108405, 21)\n",
      "(108405,)\n",
      "(16686, 21)\n",
      "(16686,)\n",
      "(45668, 21)\n",
      "(45668, 22)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "# # Number of features for the input layer\n",
    "N_FEATURES=trainX.shape[1]\n",
    "print (trainX.shape)\n",
    "print (trainY.shape)\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "print (testX.shape)\n",
    "print (df_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create PyTorch GPU tensors from numpy arrays\n",
    "\n",
    "- Note how we transfrom the np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def XnumpyToTensor(x_data_np):\n",
    "    x_data_np = np.array(x_data_np.values, dtype=np.float32)        \n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")    \n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")\n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "    \n",
    "    print(type(X_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))    \n",
    "    return X_tensor\n",
    "\n",
    "\n",
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def YnumpyToTensor(y_data_np):    \n",
    "    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")            \n",
    "    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")        \n",
    "    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n",
    "\n",
    "    print(type(Y_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))    \n",
    "    return Y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The NN model\n",
    "\n",
    "### MLP model\n",
    "- A multilayer perceptron is a logistic regressor where instead of feeding the input to the logistic regression you insert a intermediate layer, called the hidden layer, that has a nonlinear activation function (usually tanh or sigmoid) . One can use many such hidden layers making the architecture deep.\n",
    "\n",
    "- Here we define a simple MLP structure. We map the input feature vector to a higher space, then later gradually decrease the dimension, and in the end into a 1-dimension space. Because we are calculating the probability of each genre independently, after the final layer we need to use a sigmoid layer. \n",
    "\n",
    "###  Initial weights selection\n",
    "\n",
    "- There are many ways to select the initial weights to a neural network architecture. A common initialization scheme is random initialization, which sets the biases and weights of all the nodes in each hidden layer randomly.\n",
    "\n",
    "- Before starting the training process, an initial value is assigned to each variable. This is done by pure randomness, using for example a uniform or Gaussian distribution. But if we start with weights that are too small, the signal could decrease so much that it is too small to be useful. On the other side, when the parameters are initialized with high values, the signal can end up to explode while propagating through the network.\n",
    "\n",
    "- In consequence, a good initialization can have a radical effect on how fast the network will learn useful patterns.For this purpose, some best practices have been developed. One famous example used is **Xavier initialization**. Its formulation is based on the number of input and output neurons and uses sampling from a uniform distribution with zero mean and all biases set to zero.\n",
    "\n",
    "- In effect (according to theory) initializing the weights of the network to values that would be closer to the optimal, and therefore require less epochs to train.\n",
    "\n",
    "### References: \n",
    "* **`nninit.xavier_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a uniform distribution.\n",
    "* **`nninit.xavier_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a normal distribution.\n",
    "* **`nninit.kaiming_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.](https://arxiv.org/abs/1502.01852) using a uniform distribution.\n",
    "* **`nninit.kaiming_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (21 -> 128)\n",
      "  (1): Dropout (p = 0.1)\n",
      "  (2): Sigmoid ()\n",
      "  (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (4): Linear (128 -> 2)\n",
      "  (5): Dropout (p = 0.1)\n",
      "  (6): Sigmoid ()\n",
      "  (7): Linear (2 -> 4)\n",
      "  (8): Dropout (p = 0.1)\n",
      "  (9): Sigmoid ()\n",
      "  (10): Linear (4 -> 8)\n",
      "  (11): Dropout (p = 0.1)\n",
      "  (12): Sigmoid ()\n",
      "  (13): Linear (8 -> 16)\n",
      "  (14): Dropout (p = 0.1)\n",
      "  (15): Sigmoid ()\n",
      "  (16): Linear (16 -> 32)\n",
      "  (17): Dropout (p = 0.1)\n",
      "  (18): Sigmoid ()\n",
      "  (19): Linear (32 -> 1)\n",
      "  (20): Sigmoid ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# p is the probability of being dropped in PyTorch\n",
    "dropout = torch.nn.Dropout(p=1 - 0.90)\n",
    "LR = 0.005\n",
    "MOMENTUM= 0.9\n",
    "\n",
    "# class Net2(nn.Module):\n",
    "#     def __init__(self, n_feature, n_hidden, n_output,initKernel='uniform'):\n",
    "#         super(Net2, self).__init__()\n",
    "#         self.dis = nn.Sequential(\n",
    "#             nn.Linear(n_feature, n_hidden),\n",
    "#             dropout,\n",
    "#             nn.LeakyReLU(0.1),\n",
    "                                    \n",
    "#             nn.Linear(n_hidden, int(n_hidden /2)),\n",
    "#             dropout,\n",
    "#             nn.LeakyReLU(0.1),\n",
    "            \n",
    "#             nn.Linear(int(n_hidden /2), int(n_hidden /4)),\n",
    "#             dropout,\n",
    "#             nn.LeakyReLU(0.1),\n",
    "            \n",
    "#             nn.Linear(int(n_hidden /4), 1),            \n",
    "#             nn.Sigmoid()\n",
    "#         )        \n",
    "#     def forward(self, x):\n",
    "#         x = self.dis(x)\n",
    "#         return x\n",
    "\n",
    "# net = Net(n_feature=N_FEATURES, n_hidden=1024, n_output=1)   # define the network\n",
    "# net = Net2(n_feature=N_FEATURES, n_hidden=512, n_output=1)   # define the network\n",
    "\n",
    "\n",
    "hiddenLayer1Size=128\n",
    "hiddenLayer2Size=int(hiddenLayer1Size/64)\n",
    "hiddenLayer3Size=int(hiddenLayer1Size/32)\n",
    "hiddenLayer4Size=int(hiddenLayer1Size/16)\n",
    "hiddenLayer5Size=int(hiddenLayer1Size/8)\n",
    "hiddenLayer6Size=int(hiddenLayer1Size/4)\n",
    "\n",
    "linear1=torch.nn.Linear(N_FEATURES, hiddenLayer1Size, bias=True) \n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "\n",
    "linear2=torch.nn.Linear(hiddenLayer1Size, hiddenLayer2Size)\n",
    "torch.nn.init.xavier_uniform(linear2.weight)\n",
    "\n",
    "linear3=torch.nn.Linear(hiddenLayer2Size, hiddenLayer3Size)\n",
    "torch.nn.init.xavier_uniform(linear3.weight)\n",
    "\n",
    "linear4=torch.nn.Linear(hiddenLayer3Size, hiddenLayer4Size)\n",
    "torch.nn.init.xavier_uniform(linear4.weight)\n",
    "\n",
    "linear5=torch.nn.Linear(hiddenLayer4Size, hiddenLayer5Size)\n",
    "torch.nn.init.xavier_uniform(linear5.weight)\n",
    "\n",
    "linear6=torch.nn.Linear(hiddenLayer5Size, hiddenLayer6Size)\n",
    "torch.nn.init.xavier_uniform(linear6.weight)\n",
    "\n",
    "linear7=torch.nn.Linear(hiddenLayer6Size, 1)\n",
    "torch.nn.init.xavier_uniform(linear7.weight)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "tanh=torch.nn.Tanh()\n",
    "relu=torch.nn.LeakyReLU()\n",
    "\n",
    "net = torch.nn.Sequential(linear1,dropout,tanh,nn.BatchNorm1d(hiddenLayer1Size),\n",
    "                          linear2,dropout,tanh,\n",
    "                          linear3,dropout,tanh,\n",
    "                          linear4,dropout,tanh,\n",
    "                          linear5,dropout,tanh,\n",
    "                          linear6,dropout,tanh,\n",
    "                          linear7,sigmoid\n",
    "                          )\n",
    "\n",
    "\n",
    "lgr.info(net)  # net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Print the full net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (21 -> 128), weights=((128L, 21L), (128L,)), parameters=2816\n",
      "  (1): Dropout (p = 0.1), weights=(), parameters=0\n",
      "  (2): Sigmoid (), weights=(), parameters=0\n",
      "  (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True), weights=((128L,), (128L,)), parameters=256\n",
      "  (4): Linear (128 -> 2), weights=((2L, 128L), (2L,)), parameters=258\n",
      "  (5): Dropout (p = 0.1), weights=(), parameters=0\n",
      "  (6): Sigmoid (), weights=(), parameters=0\n",
      "  (7): Linear (2 -> 4), weights=((4L, 2L), (4L,)), parameters=12\n",
      "  (8): Dropout (p = 0.1), weights=(), parameters=0\n",
      "  (9): Sigmoid (), weights=(), parameters=0\n",
      "  (10): Linear (4 -> 8), weights=((8L, 4L), (8L,)), parameters=40\n",
      "  (11): Dropout (p = 0.1), weights=(), parameters=0\n",
      "  (12): Sigmoid (), weights=(), parameters=0\n",
      "  (13): Linear (8 -> 16), weights=((16L, 8L), (16L,)), parameters=144\n",
      "  (14): Dropout (p = 0.1), weights=(), parameters=0\n",
      "  (15): Sigmoid (), weights=(), parameters=0\n",
      "  (16): Linear (16 -> 32), weights=((32L, 16L), (32L,)), parameters=544\n",
      "  (17): Dropout (p = 0.1), weights=(), parameters=0\n",
      "  (18): Sigmoid (), weights=(), parameters=0\n",
      "  (19): Linear (32 -> 1), weights=((1L, 32L), (1L,)), parameters=33\n",
      "  (20): Sigmoid (), weights=(), parameters=0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Taken from https://stackoverflow.com/questions/42480111/model-summary-in-pytorch/42616812\n",
    "from torch.nn.modules.module import _addindent\n",
    "import torch\n",
    "import numpy as np\n",
    "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
    "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
    "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
    "    for key, module in model._modules.items():\n",
    "        # if it contains layers let call it recursively to get params and weights\n",
    "        if type(module) in [\n",
    "            torch.nn.modules.container.Container,\n",
    "            torch.nn.modules.container.Sequential\n",
    "        ]:\n",
    "            modstr = torch_summarize(module)\n",
    "        else:\n",
    "            modstr = module.__repr__()\n",
    "        modstr = _addindent(modstr, 2)\n",
    "\n",
    "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
    "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
    "\n",
    "        tmpstr += '  (' + key + '): ' + modstr \n",
    "        if show_weights:\n",
    "            tmpstr += ', weights={}'.format(weights)\n",
    "        if show_parameters:\n",
    "            tmpstr +=  ', parameters={}'.format(params)\n",
    "        tmpstr += '\\n'   \n",
    "\n",
    "    tmpstr = tmpstr + ')'\n",
    "    return tmpstr\n",
    "\n",
    "lgr.info(torch_summarize(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Loss and Optimizer\n",
    "\n",
    "###  BCELoss\n",
    "- In addition, we will calculate the binary cross entropy loss (BCELoss). Luckily we have one loss function already present. For details please checkout http://pytorch.org/docs/master/nn.html. \n",
    "\n",
    "- ** NOTE this BCELoss may not be numerical stable, although it's fine during my training process.**\n",
    "\n",
    "### Optimization\n",
    "\n",
    "- if return F.log_softmax(x) then loss = F.nll_loss(output, target) (MNIST)\n",
    "- print(nn.BCEWithLogitsLoss()(o, t)) is equivalent to print(nn.BCELoss()(sigmoid(o), t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ! pip install sympy\n",
    "import sympy as sp\n",
    "sp.interactive.printing.init_printing(use_latex=True)\n",
    "from IPython.display import display, Math, Latex\n",
    "maths = lambda s: display(Math(s))\n",
    "latex = lambda s: display(Latex(s))\n",
    "\n",
    "#the loss function is as follows:\n",
    "maths(\"\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:<torch.optim.adam.Adam object at 0x7f3145279fd0>\n",
      "INFO:__main__:BCELoss (\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.02)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=5e-4)\n",
    "#L2 regularization can easily be added to the entire model via the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-4) #  L2 regularization\n",
    "\n",
    "loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "# http://andersonjo.github.io/artificial-intelligence/2017/01/07/Cost-Functions/\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    net.cuda()\n",
    "    loss_func.cuda()\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "lgr.info (optimizer)\n",
    "lgr.info (loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Training in batches  + Measuring the performance of the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108405, 21)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.FloatTensor'>\n",
      "(108405, 21)\n",
      "<type 'numpy.ndarray'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.FloatTensor'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.FloatTensor'> <class 'torch.FloatTensor'>\n",
      "0 [ 0.71060389]\n",
      "ACC=0.0, LOG_LOSS=0.69867899879, ROC_AUC=0.497980599888 \n",
      "10 [ 0.69343209]\n",
      "ACC=0.0, LOG_LOSS=0.694105538878, ROC_AUC=0.497922154782 \n",
      "20 [ 0.6936968]\n",
      "ACC=0.0, LOG_LOSS=0.694118933489, ROC_AUC=0.49802595059 \n",
      "30 [ 0.69372934]\n",
      "ACC=0.0, LOG_LOSS=0.693820688951, ROC_AUC=0.497283215447 \n",
      "40 [ 0.69353294]\n",
      "ACC=0.0, LOG_LOSS=0.693213948683, ROC_AUC=0.503692809771 \n",
      "50 [ 0.69338626]\n",
      "ACC=0.0, LOG_LOSS=0.693241792217, ROC_AUC=0.501876798846 \n",
      "60 [ 0.69339365]\n",
      "ACC=0.0, LOG_LOSS=0.693322152612, ROC_AUC=0.499633460516 \n",
      "70 [ 0.69337577]\n",
      "ACC=0.0, LOG_LOSS=0.69318881838, ROC_AUC=0.501153412137 \n",
      "80 [ 0.69319087]\n",
      "ACC=0.0, LOG_LOSS=0.693147965361, ROC_AUC=0.50225454027 \n",
      "90 [ 0.69324118]\n",
      "ACC=0.0, LOG_LOSS=0.693218318819, ROC_AUC=0.500157307131 \n",
      "100 [ 0.6931473]\n",
      "ACC=0.0, LOG_LOSS=0.693202363768, ROC_AUC=0.499151727553 \n",
      "110 [ 0.69314796]\n",
      "ACC=0.0, LOG_LOSS=0.693168735753, ROC_AUC=0.500775763132 \n",
      "120 [ 0.69313252]\n",
      "ACC=0.0, LOG_LOSS=0.693148526465, ROC_AUC=0.500932436265 \n",
      "130 [ 0.69308311]\n",
      "ACC=0.0, LOG_LOSS=0.693119374237, ROC_AUC=0.502583974773 \n",
      "140 [ 0.69319689]\n",
      "ACC=0.0, LOG_LOSS=0.693141412501, ROC_AUC=0.500707216605 \n",
      "150 [ 0.69318521]\n",
      "ACC=0.0, LOG_LOSS=0.693181678925, ROC_AUC=0.497332699307 \n",
      "160 [ 0.69319105]\n",
      "ACC=0.0, LOG_LOSS=0.693125910377, ROC_AUC=0.500746246217 \n",
      "170 [ 0.69313073]\n",
      "ACC=0.0, LOG_LOSS=0.693121279762, ROC_AUC=0.50111287846 \n",
      "180 [ 0.69313586]\n",
      "ACC=0.0, LOG_LOSS=0.693113189288, ROC_AUC=0.501397069147 \n",
      "190 [ 0.69310039]\n",
      "ACC=0.0, LOG_LOSS=0.693118406365, ROC_AUC=0.501336372795 \n",
      "GPU: 450.113 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQeFmZk15KAwM7OGHBRmZtbQ/wdZjyQ2T6GihgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31688e5ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4FFX3wPHvIfQqEJQSmhB6CRgRpKmoFAsqiiCiIEhH\nEBsKYuMVBRULKC82mjRBgVcBK6iolNB7kSIBlNBrgCTn98dM+C0h2WxCNptyPs8zDzv93N0wZ++9\ns3dEVTHGGGOSkiPQARhjjMnYLFEYY4zxyhKFMcYYryxRGGOM8coShTHGGK8sURhjjPHKEoUxxhiv\nLFEYY4zxyhJFNiQiu0Xk1kSWXyUiH4nIPyJyRkTWi0jXRLbrICLLROS0iBx0X/cREUnmvBNEZHgS\n60REnhGR7SJyVkT+FpERIpLHY5sQEZktIodE5LiIbBCRLh7ru4nIFhE5KSL/ish8ESmUwvdGRORN\nETnsTm96K5eIlBCRqW48R0XkC491ZURkrogcEZFIEenlsS5YRH53z3FMRP4UkcYe62uJyHduWS/7\nVayI9BORCBE5JyITElnfXkQ2u+/FJhG5J4n4fxIRFZGcHssqiMgi929gS8K/FRG5VkS+cY99SERG\neqybIiIHROSEiGwTke4J9s0vIh96fIa/eqx7WUQuiMgpj+napN57k45U1aZsNgG7gVsTLMsNRADz\ngYpALqAV8C8wyGO7p9xl9wOFAAHqAV8AeZI57wRgeBLrPgC2A42AnEBNYDkw12ObRcC7QAF3m3pA\na3ddczeueu58MeBRoFAK35uewFYgBCgDbAJ6edn+N+AdoIj7ntVLJN5cQF3gCHCzuy4vUBXny5oA\n97jrc7rrqwLdgLbOf9PLznufu89HwIQE68oA54HW7rHvAM4AVyfYrhPwK6Dx53WX/+mWKR/QDjgG\nlPD4O/kLGOR+DnmBOh771oz/OwCqAf8A13msnwJMB0oAQQnWvQxMCfT/D5sS+TsPdAA2BeBDTzxR\ndAMOAgUSLH8QOAUUdi+Gp4F2qTxvookCCAVigQYJlpcFzgG3uPOngLAkjv00MCcN3ps/gB4J3pel\nSWx7u/teBiWyrqB7AS7hsWw8MDmRbXMAd7nbJ7yYV04sUXisH55IorgBOJhgWRTQyGO+CLANaOiZ\nKIAq7nteyGPb33CTJdAD+M3H97IqcABo785XA04AhZPY3hJFBp2s6cnEuw1YoKqnEyyfjfOtsZE7\n5QHmpvG5WwCRqrrcc6Gq7gWWurHhvh7rNn2VS3CMZUBLEXlFRBp7NlkBiMhgt4kn0clj05rAWo/5\nte6yxDTEqX1MdJuQVohI8/hTJvg3/nWtBHGtA6KBecAnqnowiXOlRASwWUTuFpEgt9npHLDOY5vX\ncWoj/yTYtyawU1VPeizzfA8aArtFZIHbfLRYRGonKNOHInIG2IKTKOa7qxoAe4BX3H3Xi0i7BOe/\ny22q2ygivVNVepPmLFGYeME4/6kvoaoxwCF3fTBwyF0GgIj84V5sz4pIs7Q8t+uAux7gAZxvty8C\nu0RkjYhc78b5G05zTH3gW+CwiLwjIkHu+jdU9aqkJo/zFQSOe8wfBwom0U8RglOrWASUBN4G5opI\nsHuh/R14UUTyikh9nGac/J4HUNU6OLW1h4Alyb1RvlDVWGASMBUnQUwFesZ/CRCRcKAxTnNfQgnL\njzsf39cTAnQA3gdK47zXc0Ukt8f5+7jbNwW+cmOI37eWe7zSQD+cJFvdXT8TqI7TLPU4MExEOqb8\nHTBpzRKFiXcIKJVwodvJGeyuPwwEe3Z8quqN7oX2MKn/e0r03K5S7npU9aiqDlbVmsA1wBpgTvxF\nXFUXqOpdOP0TbYEuQPdEj5q0+Ga2eIWBU6qa2DDLZ4Hdqvqpql5Q1enAXpyLMDh9ABXdZR/htM9H\nJjyIqkar6jRgsIjUTWG8l3E7n0cCN+H0KTQHPhGRMBHJAXwIDPBM+B4Slh93Pr6GcRZY4r7X54G3\ngOI4F3jPMsWq6hKc5NDbY98LOM2P51X1F5wke7u7zyZV3e/u+wfwHk5fmAkwSxQm3o9AaxEpkGB5\nO5xvhEtxOjnP4VyE09LPQFkRaeC5UETK4jR1/JRwB1U9hHORKo2TGDzXxanqT+5xa7nHeiHB3TSX\nTB67b8TpeI5X112WmHU47fuXnN4jjj2qeqeqllDVG3AS7nKSlgtIi7t8woBfVTXCfS9W4DTN3Ypz\n0Q8HZojIP8AKd59IEWmKU9Zr5dK7xTzfg8TK7E1OoJLHvgl5O5ZyadOdCZRAd5LYlP4TTgdsa5y+\nh/gpD7AKpz25As5FqyXOnUTPeOz7LJfe9ZQD58J0FLgpmfNOAEYkOG9ud92HOHc9NcS5Gyb+rqdv\nPfZ/E+fCn9M991hgu7uuLU6TSFGci0sDnA7cTil8b3oBm3HuHCqNc4FM9K4nnAR1FOfuqiD3PTkC\nBLvrq7tx5gYexqkZxd891BBo4q7LBzyH8629tLte3PenBs4FMy8ed5W570Fe9/2c7L6O75Bu7p4r\nzJ2vh1Pju909bkmP6Xr3+GU8PoulOEk4L3Avl971VBXnDqpb3TI/iXMXVG7gavczKOiua4lz88Pd\n7r65gB04TYc5cWpeJ4FqHp+h5+e3D3g00P9fbLK7nrLlhJMoNME03L3w/RcnEZx1L5LdE9m/E85F\n/Ix7MV6GczdM7mTOOyGR8y5x1+VwL5Y73HPvxWk+yeuxf/wttKfc834DVHfXNcOpeRxyLz7bgGdT\n8d6Ie94j7jQSEI/1p4CmHvNNgfXu8ogE6wa6cZ7G6X8I91jXHKeT+KR7nl+AZh7rKyTyXu32WP9y\nIutf9ljfz30vTwI7gaeSKG/8eXImWLbY/Ry2cvkdcve5xz7hblfTXV7CLccxd9164PEE+9bEqZme\nxrn1+F6PddNwEtopnI7wJwL9f8UmZxL3AzLGGGMS5bc+ChH5TJxf7W5IYn0nEVnn3iL3R1p04hlj\njEl7/uzMnoDzy96k7AKaq2pt4DWcHyOZTM69/z2xDuNOgY7NGJM6fm16EpEKwDeqWiuZ7YoCG1S1\njN+CMcYYkyo5k98kXXQDFiS1UkR64HSWUqBAgeuqVauWXnEZY0yWsHLlykOqWiI1+wY8UYjIzTiJ\noklS26jqeNymqfDwcI2IiEin6IwxJmsQkT2p3TegiUJE6gCf4IwAejiQsRhjjElcwH6Z7Q7q9hXQ\nWVW3BSoOY4wx3vmtRiEi03DGmgkWkUjgJZxfZqKq44BhOGPEfOgO1ROjquH+iscYY0zq+C1RqKrX\nUR9VtTspH7DNGGNMOrNBAY0xxnhlicIYY4xXliiMMcZ4ZYnCGGOMV5YojDHGeGWJwhhjjFeWKIwx\nxnhlicIYY4xXliiMMcZ4ZYnCGGOMV5YojDHGeGWJwhhjjFeWKIwxxnhlicIYY4xXliiMMcZ4ZYnC\nGGOMV5YojDHGeGWJwhhjjFeWKIwxxnhlicIYY4xXliiMMcZ4ZYnCGGOMV5YojDHGeGWJwhhjjFeW\nKIwxxnjlt0QhIp+JyEER2ZDEehGR90Vkh4isE5H6/orFGGNM6vmzRjEBaOVlfWsg1J16AB/5MRZj\njEmR48cDHUHG4bdEoaq/Ake8bNIWmKSOpcBVIlLKX/EYY4wvYs7F8scDo3ms1AJWrQp0NBlDIPso\nygB7PeYj3WWXEZEeIhIhIhFRUVHpEpwxJvvZOHMjm4s15sZZg3j0qjlcfXWgI8oYMkVntqqOV9Vw\nVQ0vUaJEoMMxxmQxZ07G8vNNrxL6YD1Kn/2L33pP5c694wgJCXRkGUMgE8U+oKzHfIi7zBhj0s26\ndVDvuhyc/WUZy8o+gG7cRNMPO5IjSAIdWoYRyEQxD3jEvfupIXBcVQ8EMB5jTDYSd+oMy24ZTPsG\nuzlyVMg3/yua/v0FwdWt1SKhnP46sIhMA24CgkUkEngJyAWgquOA+UAbYAdwBujqr1iMMcbTvi8W\nw+PdueHsX/SqFEKb+f2oUiVPoMPKsPyWKFS1YzLrFejrr/MbY0xCeuw4G+94llp/jOcvqcT/nvyZ\nAW/fjFgrk1eZojPbGGOu1Pr1MK3O61T/4xNmVXiaXJvWcdc7liR84bcahTHGZASHNkcx5uVDvDar\nOiGFXiDPc/dz3+vXk8O+JvvMEoUxJmtSZd3z0ygz8gnu1vIc6hPBq68VoVix6wMdWaZjicIYk+Wc\n3BzJzpa9qbv3G9blbUCBKZ8ypp21MaWWVb6MMVnKsnGroWYNQvf+xDe3vEOVQ39QtV2tQIeVqVmi\nMMZkCWeOX6B3b2jSuxbzinRm66wN3PnTk+QtEBTo0DI9SxTGmMwtJobtPd/iUIlqTB93lN79c3Hf\n/rHUa3dtoCPLMqyPwhiTaUX9vJ4TD3Qj9MgKfsh/N3O+uEDzBwIdVdZjNQpjTKajMbGsaPMSV7Wo\nT6Eju5nZbgZNoubQ/AEb7tUfLFEYYzKVnTuh+c05OLgggl9KdeDkss20n9WefPntriZ/sURhjMkU\nYk+cJqLFs9xZcxdr1gr73v+KWyInU6lB8UCHluVZH4UxJsPb89lP5OzzOOHndtGvZgXuXtiHkBAb\nxC+9WI3CGJNhXYg6xurwxynf7VaiL+Tkh6G/0Ht9H3ugUDqzRGGMyZBWr4YptUZQe+XnzKn2HIV2\nruW215rZIH4BYInCGJOhRP99kNE9NnP99fA6Q/jtrWXcs/kNri6fL9ChZVuWKIwxGYMq216aQnTF\n6jT7+GEe6aws31KYm5+6LtCRZXvWmW2MCbi43X+zs2UvqmxbwMo8jYge8ymfdbc2pozCEoUxJqD2\nf7OKq+5pTqnYOD4Pe4/7F/Wl0FU2PlNGYk1PxpiAiIs+z8cfQ80OtZmcowsLRm6gy6onLElkQFaj\nMMakr5gY/h74DjJ+HM9eWEnYTUVpNeEDypcPdGAmKVajMMakm+hla4kMuYFyY59jY1Bd3ht1gZ9+\nwpJEBmc1CmOM/8XGsrfbS5Sc+Ca5KMZ/b/2SjrPaUbiIdVhnBpYojDF+deYMvDg0BzdNXMu5Ap0I\nnvQOPe8rFuiwTApYojDG+MepU/zV+SUei+jLr5HXcr7HbF5/KzeFCgU6MJNSfu2jEJFWIrJVRHaI\nyOBE1pcTkUUislpE1olIG3/GY4xJH/9O+YF/r6lNpTnvcEvMdyxaBB/815JEZuVTohCR3CJSOSUH\nFpEgYCzQGqgBdBSRGgk2GwrMVNV6QAfgw5ScwxiTsUQfOMra6x7jms63c+xsHr7o9RvP7+nNTTcF\nOjJzJZJNFCJyB7Ae+MGdDxORr304dgNgh6ruVNXzwHSgbYJtFCjsvi4C7Pc1cGNMxrJgAUyq+QY1\nV01idpXnybdlDZ0+akLu3IGOzFwpX2oUrwI3AMcAVHUN4Evtogyw12M+0l3m6WXgYRGJBOYD/RM7\nkIj0EJEIEYmIiory4dTGmPSyb9W/9LtlE23awLhiQ1gxdgXttr5OuSp5Ax2aSSO+JIoLqnoswTJN\no/N3BCaoagjQBpgsIpfFpKrjVTVcVcNLlCiRRqc2xlwJjVOWPD6R/OHV6fZLZ0a+qSzdVJhGfeoF\nOjSTxny562mziLQHcohIReAJYKkP++0DynrMh7jLPHUDWgGo6p8ikhcIBg76cHxjTIDs+303/7Tt\nSZPD37OuUGOumvEJz7S230RkVb7UKPoB1wFxwFfAOWCAD/utAEJFpKKI5MbprJ6XYJu/gRYAIlId\nyAtY25IxGVRcHHz5/EqKNKlFlcN/8MsDY6h15Fcqtq4W6NCMH/mSKFqq6nOqWs+dBuPcyeSVqsbg\nJJnvgM04dzdtFJFXReRud7OngMdFZC0wDeiiqmnVrGWMSUM7Np7j5puh4xt1+b5sd479toHmM/uS\nI6eNBJTVSXLXZRFZpar1EyxbqaoBeZpIeHi4RkREBOLUxmRLsdEX+OO+UZRbOJ7mBVfx4uhiPPYY\n9kjSTMa9boenZt8k+yhEpCVO/0EZEXnHY1VhnGYoY0wW99es1cQ8+hhNz6zh91L3s/T7OErWCnRU\nJr1568w+CGwAooGNHstPApf9ytoYk3WcORHDyjuG0WjJSA5LCZY8OZvGb99ntYhsKslEoaqrgdUi\n8oWqRqdjTMaYAPr+e+jVM4h3d29gUdlHqP/z2zSpXDTQYZkA8uX22DIi8h+cYTgu/oJGVav4LSpj\nTLqL2nmSiDbD6Lu1P7mqXEvh72dz0225Ah2WyQB8uV1hAvA5IDh3O80EZvgxJmNMOlKFhU9+R3Ro\nLVpufY/37viBtWuxJGEu8iVR5FfV7wBU9S9VHYoPt8caYzK+bX8e5ruSj9Lq3VbE5cnP318s4a5v\nepLXRt8wHnxpejrnDqvxl4j0wvl1tQ0WbEwmdu4cjBgBBV8byYC4qay5Ywh1Zg4lR37LEOZyviSK\nJ4ECOEN3/AdnlNfH/BmUMcZ//vzqAK8/dZhvdtfisQeGcqLXQ4TdUjfQYZkMLNlEoarL3Jcngc4A\nIpJwFFhjTAZ35LAy554J3LtkEK/nrkS/BSto2aoQYEnCeOe1j0JErheRe0Qk2J2vKSKTgGXe9jPG\nZByqMGf0LtaXup3HljzG0bJ1qLx8Ki1b2Y8ijG+STBQiMgL4AugELBSRl4FFwFrAbo01JhPYvRsG\nNlvJbYNqER67jMghH3Ht7kXkq2v/hY3vvDU9tQXqqupZESmG8xCi2qq6M31CM8ak1oUL8N6b0Qx7\nPS+5pC6dm/Wk3sQnCalQNvmdjUnAW9NTtKqeBVDVI8A2SxLGZHy/L77ARyHDeeDFqrS7+QgbtuQk\n/Jd3CLIkYVLJW43iWhH5yn0tQEWPeVT1Pr9GZoxJkcOH4cPHIrh7XjeeYB37Grdn8sQ451FgxlwB\nb4miXYL5Mf4MxBiTel9/GUPkoy/wwtm3OV3gGs5+/DVlOt4T6LBMFuFtUMCf0jMQY0zKHTwI/fvD\nzJlBLCqylWOtH6P4p6PgqqsCHZrJQnz5wZ0xJoNRhS8/PcGx/kNZH/sEw4dXpvGTs8iV38ZnMmnP\nEoUxmcy+ffDxvfPptqInpdnPnS/VovSQyoAlCeMfPicKEcmjquf8GYwxJmmqMOXdQ+R+biAvX/iC\nw9fUgK9mUfrGGwIdmsnikh09VkQaiMh6YLs7X1dEPvB7ZMaYi3btgttvh/2DRtEuZgZH+r9E8T2r\nCLIkYdKBL8OMvw/cCRwGUNW1wM3+DMoY44iLg8//s58Ha6xn2TIIHj2UHKtXUez9lyFPnkCHZ7IJ\nX5qecqjqHrn0YbmxforHGONatVJZ+MCn9Nn1NE0KVSLvhgjKlisE1A50aCab8aVGsVdEGgAqIkEi\nMhDY5ue4jMm2jh+HVx7dydHwW3lh1+OcqxZG5ZUzKFvOBvEzgeFLjaI3TvNTOeBf4Ed3mTEmDanC\n1Kkw6YkIvj7SDMmVkzMj/8s1T3SHHL58pzPGP3xJFDGq2sHvkRiTjW3dCgN7nmXhL/loGB7GiTZ9\nKDliIISEBDo0Y3xqelohIvNF5FERSdEjUEWklYhsFZEdIjI4iW3ai8gmEdkoIlNTcnxjMrvoaHh1\n6Hlm1HyFj3+twmejDrNkaU5KTn7LkoTJMHx5wl0lEbkR6AC8IiJrgOmqOt3bfiISBIwFbgMicRLO\nPFXd5LFNKPA80FhVj4rI1VdQFmMylR9+gHGPLeflyG7UZgNn732Irl2BoEBHZsylfGr4VNU/VPUJ\noD5wAueBRslpAOxQ1Z2qeh6YjvOMC0+PA2NV9ah7noM+R25MJhUVBQ+1j2Ht7U8zM7IRocFH4X//\nI99XX0Dx4oEOz5jL+PKDu4Ii0klE/gcsB6KAG304dhmchx3Fi3SXeaoCVBGR30VkqYi0SiKGHiIS\nISIRUVFRPpzamIxp9myoUQNmzwnizqo70O6Pk3fHRrjzzkCHZkySfOnM3gD8Dxipqr/54fyhwE1A\nCPCriNRW1WOeG6nqeGA8QHh4uKZxDMb43eHD8EyP49T/agiNaw7kP4srU63qLMhpw62ZjM+Xv9Jr\nVTUuFcfeB3g+UivEXeYpElimqheAXSKyDSdxrEjF+YzJkL79FqY//A0jjvWitBygV/8wctasjI3J\naTKLJJueRORt9+VsEfkq4eTDsVcAoSJSUURy43SGz0uwzRyc2gQiEozTFGWPWzVZwtGj0L9DFMfv\nfIjJx+6ieGgxcixbSs6e3QMdmjEp4u0rzQz331Q92U5VY0SkH/Adzn0cn6nqRhF5FYhQ1XnuuttF\nZBPOsCDPqOrh1JzPmIzkf/+Dnj3hyX/eon2OWcQMeYV8QwdD7tyBDs2YFBNV703+ItJPVccktyy9\nhIeHa0RERCBObUyyDh+GVx6PZPHXR5A6dZg49hRhRfdAzZqBDs1kcyKyUlXDU7OvL42kj3F5raJb\nIsuMybZUYeb0OCJ6fszwk89wqlQowcsjyJ2nIGBJwmRuSSYKEXkQp1+hYoI+iULAscT3Mib7OX4c\nhrTfzv3fP84ofuHkDS0oPXU85LFB/EzW4K1GsRznGRQhOL+wjncSWO3PoIzJDFRh8mSYPCCCecea\nQp48xH3wCYW6PwZiScJkHUkmClXdBezCGS3WGONh927o0/UsCxY7g/gdq/EEpUYMgNKlAx2aMWnO\nW9PTL6raXESOAp493gKoqhbze3TGZDBxcTDuvXMcf+51Po75lB9GreGRQcHkyPFmoEMzxm+8NT3F\nP+40OD0CMSaj274d3n5gKf3XdqMmmzh978N0eSyHjyOmGZN5Jfkn7vFr7LJAkKrGAo2AnkCBdIjN\nmAwhNhbeGRnDguqD+HDtjVQoegL95lsKfDUZilnF2mR9vnwXmoPzGNRKwOc4Q2zYcyNMtrB5MzRr\nBk89F8T1JXZz9pFeFNi9EbmjTaBDMybd+PI7ijhVvSAi9wEfqOr7ImJ3PZksLToa3n35GMVHDeZs\n/qeYNCmUhh2/RHLawyJM9uPTo1BF5AGgM3CPuyyX/0IyJrAWLoQ5Xecy7J/eXCMHeeDl67mqcyj2\nRCGTXfnS9PQYTsf2SFXdKSIVgWn+DcuY9BcZCd3v+pfjrR9k3D/3UOjaqwlasYyrnuoW6NCMCahk\nE4WqbgCeACJEpBqwV1X/4/fIjElHX38NdepA9YXv0C5oDjGv/IdCW1bAddcFOjRjAi7ZpicRaQpM\nxnmWhAAlRaSzqv7u7+CM8beoKHh74F4WTD1Cubp1aTvhRXLm6QLVqwc6NGMyDF/6KEYDbVR1E4CI\nVMdJHKkahdCYjGL2l3H88cg4Xo5+jr7XVKXEnyvIm68gYEnCGE++9FHkjk8SAKq6GbBB9U2mFRcH\n7/fbRon2N/F2dF/kxkaUXTqLvPlsfCZjEuNLjWKViIwDprjznbBBAU0mtXs3jGq/grdXNCU2dz5i\nxnxGwe5dbBA/Y7zwpUbRC+fxpM+6006cX2cbk2nExcGHo05TqxZM2VSfTS2fJP+uTeR8vKslCWOS\n4bVGISK1gUrA16o6Mn1CMiZtbVkTzbI7X6Ptvgn8cstaRn4WTPnyIwIdljGZRpI1ChF5AWf4jk7A\nDyLyWLpFZUwauHABJvb8A+rV49F9rxPd5DamfxlE+fKBjsyYzMVbjaITUEdVT4tICWA+8Fn6hGXM\nlVm9IobNbZ6i86EPOJy/LEc/XUilDi0DHZYxmZK3PopzqnoaQFWjktnWmAwhOhpeeAGubxhE4ZP7\n2NW6LyX+2UBRSxLGpJq3GsW1Hs/KFqCS57OzVfU+v0ZmTAotXXCUvzs+x5fHn+GRrqE0HjmDosE2\nPpMxV8pbomiXYH6MPwMxJrVOnoSZHb6izfy+hBNFjUGNqPW2DeJnTFrx9szsn9IzEGNSShW++vAf\n8jzdj27Rs4kMDuP8nPnUalwv0KEZk6X4td9BRFqJyFYR2SEig71s105EVERsWBDjk/XroWlT2NFv\nNLed+4a9vV8nZP9y8luSMCbN+S1RiEgQMBZoDdQAOopIjUS2KwQMAJb5KxaTdZw/D+89uZtu9Vez\ndStcM2YYuTaupeyHz0Mue0yKMf7gyxAeAIhIHlU9l4JjNwB2qOpOd//pQFtgU4LtXgPeBJ5JwbFN\nNrRyRRw/3DOWfvuf565i1Si8aQXBJQoAVQMdmjFZWrI1ChFpICLrge3ufF0R+cCHY5cB9nrMR7rL\nPI9dHyirqt8mE0MPEYkQkYioqCgfTm2ykuhoGN1jM+caNGXw/ic4Xb8p166aTXAJG3rDmPTgS9PT\n+8CdwGEAVV2L88S7KyIiOYB3gKeS21ZVx6tquKqGlyhR4kpPbTKRpUvh0erL6fNxGHXybOH0R5O4\nJmI+9vNqY9KPL4kih6ruSbAs1of99gFlPeZD3GXxCgG1gMUishtoCMyzDm0DzvAbI4aconFjWBZz\nHZEdnqHgnk0U6NXZBvEzJp350kexV0QaAOp2UPcHtvmw3wog1H3G9j6gA/BQ/EpVPQ4Ex8+LyGLg\naVWN8D18kxV9Nzea3V1focvRCey6Zx1vTSxB4cLDAx2WMdmWLzWK3sAgoBzwL843/97J7aSqMUA/\n4DtgMzBTVTeKyKsicnfqQzZZVWQkDL1pCRXuqUvPo28Qc1sbxn+ei8KFAx2ZMdmbqGqgY0iR8PBw\njYiwSkdWEhMDY96NId8LA+l5YSxHi1Sg4LSPydX61kCHZkyWISIrVTVVTfvJNj2JyMfAZdlEVXuk\n5oTGeFq2DHr2hLVrc/JbyX853moART8YDgULBjo0Y4zLlz6KHz1e5wXu5dLbXo1JsaNH4fWnDlP9\n82cpfPWzzJ5dlcZtZyBBNkixMRlNsolCVWd4zovIZGCJ3yIyWd7cOco3XWYx/Hg/gnMcoeMrTcl3\nX1VsJHtjMqbU/M+sCFyT1oGYrO/QIehz7wHi7r2Pj4+3p2D1sgStXkm+Xl0CHZoxxgtffpl9VESO\nuNMx4Afgef+HZrKS2bOhZk2oOPdd7sy5kJjXR1Jg3VKoUyfQoRljkuG16UlEBKjL//9QLk4z221S\nJqAOHoRXuu7iz/lHCalfn1Zzh5GreHcIDQ10aMYYH3lNFKqqIjJfVWulV0Am65g1I5Y13ccw8tQL\nnChdneAYBeFDAAAXbUlEQVQ/V5ArdwHAkoQxmYkvfRRrRMQG+Tc+O3AABty2iTIdmjD81EDimjSn\n1NKvyZXbht4wJjNKskYhIjndX1fXA1aIyF/AaZznZ6uq1k+nGE0moQoTJ8KU/sv49lQzYvMXIvaj\nKRTq/JCNz2RMJuat6Wk5UB+w4TZMsvbsgYHdTjLnp0I0axzOqbrPUfylfnD11YEOzRhzhbwlCgFQ\n1b/SKRaTCcXFwfh3z3B28MuMi5nEnSPW0/XZEuTI8WqgQzPGpBFviaKEiAxKaqWqvuOHeEwmsnUr\nfHD/LwzY0J1QdnCy4+N0653bfjdnTBbjLVEEAQVxaxbGxFOFd9+KocDg/oyJG8fJEtei036iUItb\nAh2aMcYPvCWKA6pq7QfmEvv2Qbdu8N13Ofm19FFO3zWIQu+8BvnzBzo0Y4yfJNtHYQw4tYi5nx7i\nTJ+n+SfoeT78sCpNeky1QfyMyQa8JYoW6RaFydB27VSmtp1Bjw39KSrHuOW1mynZ2wbxMya7SPJ/\nuqoeSc9ATMYTFweTRuxjY5V7GLKhI3HlKqIRqyj53KOBDs0Yk47sK6FJ1O7dcNttsP+FD7hVf+Do\nkLe4Zuef5KpfO9ChGWPSmSUKc4m4OJj00l88XH0ly5fD1e+/SJ4t6yg6/CkICgp0eMaYAPDlCXcm\nm/hrWywLW79H151DaVi4BnnWrqB8hQJA5UCHZowJIKtRGOLiYMrgDRypfiN9dz7Fobq3ErpxLuUr\n2I1vxhirUWR7O3bAqPuX8cHappzNXYTD70yjXJ8HbRA/Y8xFVqPIpmJj4YP/nKB2bfhyVzib7hlC\n4cjNFO/bwZKEMeYSliiyoT2bz/BlhadpPzSU+5sdZP2mIMK+fgkpERzo0IwxGZBfE4WItBKRrSKy\nQ0QGJ7J+kIhsEpF1IvKTiJT3ZzzZnSrMf3YRcbVq0yHybY7ddC+TZualTJlAR2aMycj8lihEJAgY\nC7QGagAdRaRGgs1WA+GqWgeYBYz0VzzZ3Y4tMXx/bU/ajLqFnLlzsP+LRVRdNA4pUjjQoRljMjh/\n1igaADtUdaeqngemA209N1DVRap6xp1dCoT4MZ5s6fRpeOEFqFEnJ8f/Ps7y5s9QJmotpR+6KdCh\nGWMyCX/e9VQG2OsxHwnc4GX7bsACP8aTrajC/AkHie73NF+deYGHHq1Gs9enUrK0dUsZY1ImQ9we\nKyIPA+FA8yTW9wB6AJQrVy4dI8uc/tqhfHnvVLpvGEAROUGtIbdRdXg17N4FY0xq+PPKsQ8o6zEf\n4i67hIjcCgwB7lbVc4kdSFXHq2q4qoaXKFHCL8FmBXFxMPXNvWyvdheDNzzM+fKhyJo1VB3eOdCh\nGWMyMX8mihVAqIhUFJHcQAdgnucGIlIP+C9Okjjox1iyvF27oFkz+HvwWJrrIo6+9C6l/1pCzjoJ\n7x8wxpiU8VuiUNUYoB/wHbAZmKmqG0XkVRG5291sFM7jVr8UkTUiMi+Jw5kkxMXB5GHbeaRGBOvW\nQbHRw8izbQNFXx5gg/gZY9KEX/soVHU+MD/BsmEer2/15/mzum2bYvjxjtF03T2MGwrXIu+65ZQr\nnx+oGOjQjDFZiPVuZkKxsTBh0DpO1mpEn93PElWvJaGb5lKuvA29YYxJexnirifjuzVr4P1Oy/jv\npiaczlOMo+/PpNzj99v4TMYYv7EaRSZx8iS8Mug49evD7D3hbHngRYpEbqJojwcsSRhj/MpqFJnA\nyl9Ps/7uIfQ+PpV/7tvA8PFXU7z4sOR3NMaYNGA1igwsOho+6fgjxZrXosvx94i5tz0fTchH8eKB\njswYk51YjSKDWrI4hn/a9qT7ic84ULgKJ6f9Suk2TQMdljEmG7IaRQZz8iT06wdNb85Jzthodj04\nmFL/rKGQJQljTIBYjSID+Xnav5zoPoifzwxlwIDq3PraFAoWso5qY0xgWaLIAA4fUmbdM4X7fx9I\nITlFzWGtCX2lOmBJwhgTeJYoAkgVvh33N3kH9qLn+QX8HdKIQt98Smjd6oEOzRhjLrI+igA5cADu\nuw/W9/mIG2N+Zd9z71Nu92/ktiRhjMlgLFGkM1WY9fpWOoUuZ+FCyDv8RXJv3UCZN/rbIH7GmAzJ\nmp7S0b+RF/jfzW/z8I6XqVWwNkFrlxNaJT9QIdChGWNMkqxGkQ5UYcHrq/mnwg103/E8+8PuoMqW\neYRWsc5qY0zGZ4nCzw4cgMHN/+S2IdcTkmM/e0fP4trVs8lRplSgQzPGGJ9YovATVZg+7hg1a8IH\ny29gaatXuGrfJsoObBfo0IwxJkUsUfjB4T2n+LbyE7ToHcqNlf5l9docNFkwhKASxQIdmjHGpJgl\nijS2ZuT3nKlUizY7x7C3cUfm/liAqlUDHZUxxqSe3fWURv6NvMDWm3rQ7K8J7MxdlR0f/0b9ro0D\nHZYxxlwxq1FcIVWYNAmq1MxF5M7zfBc+hJIH1lDFkoQxJouwGsUVOLjuH7a2Hsgb+4dRp0kNrvt4\nClWr2S2vxpisxWoUqRAXq/zSdQK5w6pz/f45vNVpDYsXY0nCGJMlWY0ihY6s2s3OW3vQ/OgPrC3c\nhILTPqFNG+utNpnPhQsXiIyMJDo6OtChmDSUN29eQkJCyJUrV5od0xKFj2Ji4K23IOew8fS88CdL\nOo7lxkm9yJHTKmUmc4qMjKRQoUJUqFABEasNZwWqyuHDh4mMjKRixYppdly7yvlg27wtdKu9nOef\nh99veZG/5m6kydQ+liRMphYdHU3x4sUtSWQhIkLx4sXTvJbo1yudiLQSka0iskNEBieyPo+IzHDX\nLxORCv6MJ6UunLnAz7e+Tvm2dRmwox8zZyhfL8xH2N3lAh2aMWnCkkTW44/P1G+JQkSCgLFAa6AG\n0FFEaiTYrBtwVFUrA6OBN/0VT0ptnbaKv4IbcMtPQ1hV9h7KrfkfD7S3/1TGmOzHnzWKBsAOVd2p\nqueB6UDbBNu0BSa6r2cBLSQDfMWZ9dSfVHqoAUXP/cPS576m0d8zCK55TaDDMiZLmjNnDiLCli1b\nLi5bvHgxd9555yXbdenShVmzZgFOR/zgwYMJDQ2lfv36NGrUiAULFlxxLCNGjKBy5cpUrVqV7777\nLtFtunTpQsWKFQkLCyMsLIw1a9YATv/AE088QeXKlalTpw6rVq26uE+rVq246qqrLitTt27dqFu3\nLnXq1OH+++/n1KlTAIwbN47atWsTFhZGkyZN2LRp08V91q1bR6NGjahZsya1a9dOl5sR/JkoygB7\nPeYj3WWJbqOqMcBxoHjCA4lIDxGJEJGIqKgoP4X7/2ZH3sAn5YeTe/smGr5xj9/PZ0x2Nm3aNJo0\nacK0adN83ufFF1/kwIEDbNiwgVWrVjFnzhxOnjx5RXFs2rSJ6dOns3HjRhYuXEifPn2IjY1NdNtR\no0axZs0a1qxZQ1hYGAALFixg+/btbN++nfHjx9O7d++L2z/zzDNMnjz5suOMHj2atWvXsm7dOsqV\nK8eYMWMAeOihh1i/fj1r1qzh2WefZdCgQQDExMTw8MMPM27cODZu3MjixYvT9O6mpGSKu55UdTww\nHiA8PFz9fb5pM3IAl3WpGJNlDRwI7hfjNBMWBu++632bU6dOsWTJEhYtWsRdd93FK6+8kuxxz5w5\nw8cff8yuXbvIkycPANdccw3t27e/onjnzp1Lhw4dyJMnDxUrVqRy5cosX76cRo0a+bz/I488gojQ\nsGFDjh07xoEDByhVqhQtWrRg8eLFl+1TuHBhwKmNnD179mL/QvxygNOnT19c/v3331OnTh3q1q0L\nQPHil32v9gt/1ij2AWU95kPcZYluIyI5gSLAYT/GZIzJQObOnUurVq2oUqUKxYsXZ+XKlcnus2PH\nDsqVK3fJxTQpTz755MUmIs/pjTfeuGzbffv2Ubbs/1+yQkJC2Lcv4SXLMWTIEOrUqcOTTz7JuXPn\nUry/p65du1KyZEm2bNlC//79Ly4fO3YslSpV4tlnn+X9998HYNu2bYgILVu2pH79+owcOTLZ46cF\nf9YoVgChIlIRJyF0AB5KsM084FHgT+B+4GdV9XuNwRhzqeS++fvLtGnTGDBgAAAdOnRg2rRpXHfd\ndUneuZPSLszRo0dfcYwJjRgxgpIlS3L+/Hl69OjBm2++ybBhw1J9vM8//5zY2Fj69+/PjBkz6Nq1\nKwB9+/alb9++TJ06leHDhzNx4kRiYmJYsmQJK1asIH/+/LRo0YLrrruOFi1apFXxEuW3GoXb59AP\n+A7YDMxU1Y0i8qqI3O1u9ilQXER2AIOw9h5jso0jR47w888/0717dypUqMCoUaOYOXMmqkrx4sU5\nevToZdsHBwdTuXJl/v77b06cOJHsOVJSoyhTpgx79/5/t2pkZCRlyiTsVoVSpUohIuTJk4euXbuy\nfPnyFO2fmKCgIDp06MDs2bMvW9ehQwfmzJkDOLWUZs2aERwcTP78+WnTps0lneb+4tffUajqfFWt\noqqVVPU/7rJhqjrPfR2tqg+oamVVbaCqO/0ZjzEm45g1axadO3dmz5497N69m71791KxYkV+++03\nQkND2b9/P5s3bwZgz549rF27lrCwMPLnz0+3bt0YMGAA58+fByAqKoovv/zysnOMHj36Yqez5zR4\n8OXfSe+++26mT5/OuXPn2LVrF9u3b6dBgwaXbXfgwAHA6VeYM2cOtWrVurj/pEmTUFWWLl1KkSJF\nKFUq6Uceqyo7duy4+HrevHlUq1YNgO3bt1/c7ttvvyU0NBSAli1bsn79es6cOUNMTAy//PILNWok\n/NVB2ssUndnGmKxn2rRpPPfcc5csa9euHdOmTaNZs2ZMmTKFrl27Eh0dTa5cufjkk08oUqQIAMOH\nD2fo0KHUqFGDvHnzUqBAAV599dUriqdmzZq0b9+eGjVqkDNnTsaOHUtQUBAAbdq04ZNPPqF06dJ0\n6tSJqKgoVJWwsDDGjRt3cZv58+dTuXJl8ufPz+eff37x2E2bNmXLli2cOnWKkJAQPv30U2677TYe\nffRRTpw4gapSt25dPvroIwDGjBnDjz/+SK5cuShatCgTJzq/IihatCiDBg3i+uuvR0Ro06YNd9xx\nxxWV2xeS2boEwsPDNSIiItBhGJPpbd68merVqwc6DOMHiX22IrJSVcNTczwbrMgYY4xXliiMMcZ4\nZYnCmGwsszU9m+T54zO1RGFMNpU3b14OHz5sySILiX8eRd68edP0uHbXkzHZVEhICJGRkaTH+Gkm\n/cQ/4S4tWaIwJpvKlStXmj4FzWRd1vRkjDHGK0sUxhhjvLJEYYwxxqtM98tsEYkC9qTDqYKBQ+lw\nnvSQlcoCWas8WakskLXKk5XKAlBVVQulZsdM15mtqiXS4zwiEpHan7tnNFmpLJC1ypOVygJZqzxZ\nqSzglCe1+1rTkzHGGK8sURhjjPHKEkXSxgc6gDSUlcoCWas8WakskLXKk5XKAldQnkzXmW2MMSZ9\nWY3CGGOMV5YojDHGeJXtE4WItBKRrSKyQ0Que5CuiOQRkRnu+mUiUiH9o/SND2UZJCKbRGSdiPwk\nIuUDEaevkiuPx3btRERFJMPeyuhLWUSkvfv5bBSRqekdY0r48LdWTkQWichq9++tTSDi9IWIfCYi\nB0VkQxLrRUTed8u6TkTqp3eMvvKhLJ3cMqwXkT9EpK5PB1bVbDsBQcBfwLVAbmAtUCPBNn2Ace7r\nDsCMQMd9BWW5Gcjvvu6dUcvia3nc7QoBvwJLgfBAx30Fn00osBoo6s5fHei4r7A844He7usawO5A\nx+2lPM2A+sCGJNa3ARYAAjQElgU65isoy40ef2OtfS1Ldq9RNAB2qOpOVT0PTAfaJtimLTDRfT0L\naCEiko4x+irZsqjqIlU9484uBdJ2LOK05ctnA/Aa8CYQnZ7BpZAvZXkcGKuqRwFU9WA6x5gSvpRH\ngcLu6yLA/nSML0VU9VfgiJdN2gKT1LEUuEpESqVPdCmTXFlU9Y/4vzFScA3I7omiDLDXYz7SXZbo\nNqoaAxwHiqdLdCnjS1k8dcP5lpRRJVsetwmgrKp+m56BpYIvn00VoIqI/C4iS0WkVbpFl3K+lOdl\n4GERiQTmA/3TJzS/SOn/rczC52tAphvCw1w5EXkYCAeaBzqW1BKRHMA7QJcAh5JWcuI0P92E8y3v\nVxGprarHAhpV6nUEJqjq2yLSCJgsIrVUNS7QgRkQkZtxEkUTX7bP7jWKfUBZj/kQd1mi24hITpxq\n9OF0iS5lfCkLInIrMAS4W1XPpVNsqZFceQoBtYDFIrIbp+14Xgbt0Pbls4kE5qnqBVXdBWzDSRwZ\nkS/l6QbMBFDVP4G8OIPsZUY+/d/KLESkDvAJ0FZVfbqWZfdEsQIIFZGKIpIbp7N6XoJt5gGPuq/v\nB35Wtycog0m2LCJSD/gvTpLIyG3gkEx5VPW4qgaragVVrYDT3nq3qqZ64DM/8uXvbA5ObQIRCcZp\nitqZnkGmgC/l+RtoASAi1XESRWZ95uo84BH37qeGwHFVPRDooFJDRMoBXwGdVXWbzzsGupc+0BPO\nHQ3bcO7iGOIuexXnogPOH/iXwA5gOXBtoGO+grL8CPwLrHGneYGO+UrKk2DbxWTQu558/GwEpylt\nE7Ae6BDomK+wPDWA33HuiFoD3B7omL2UZRpwALiAU7PrBvQCenl8NmPdsq7P4H9nyZXlE+CoxzUg\nwpfj2hAexhhjvMruTU/GGGOSYYnCGGOMV5YojDHGeGWJwhhjjFeWKIwxxnhlicJkOCISKyJrPKYK\nXratkNRImSk852J3NNS17jAaVVNxjF4i8oj7uouIlPZY94mI1EjjOFeISJgP+wwUkfxXem6TfVmi\nMBnRWVUN85h2p9N5O6lqXZxBIEeldGdVHaeqk9zZLkBpj3XdVXVTmkT5/3F+iG9xDgQsUZhUs0Rh\nMgW35vCbiKxypxsT2aamiCx3ayHrRCTUXf6wx/L/ikhQMqf7Fajs7tvCfabCenes/zzu8jfk/5/t\n8Za77GUReVpE7scZS+sL95z53JpAuFvruHhxd2seY1IZ5594DE4nIh+JSIQ4z7N4xV32BE7CWiQi\ni9xlt4vIn+77+KWIFEzmPCabs0RhMqJ8Hs1OX7vLDgK3qWp94EHg/UT26wW8p6phOBfqSHf4iAeB\nxu7yWKBTMue/C1gvInmBCcCDqlobZ+C+3iJSHLgXqKmqdYDhnjur6iwgAuebf5iqnvVYPdvdN96D\nwPRUxtkKZ+iPeENUNRyoAzQXkTqq+j7OEN83q+rN7vAgQ4Fb3fcyAhiUzHlMNmejx5qM6Kx7sfSU\nCxjjtsnH4oyFlNCfwBARCQG+UtXtItICuA5YIc5jRPLhJJ3EfCEiZ4HdOMNiVwV26f+PiTMR6AuM\nwXn+xaci8g3wja8FU9UoEdnpjhm0HaiGM9RF3xTGmRsoCHi+T+1FpAfO/+tSOMNorEuwb0N3+e/u\neXLjvG/GJMkShcksnsQZp6ouTk34sgcVqepUEVkG3AHMF5GeOOP0TFTV5304Ryf1GFRQRIoltpGq\nxohIA5xB7+4H+gG3pKAs04H2wBbga1VVca7aPscJrMTpn/gAuE9EKgJPA9er6lERmYAzTllCAvyg\nqh1TEK/J5qzpyWQWRYAD6jzPoDPO4zgvISLXAjvd5pa5OE0wPwH3i8jV7jbFxPdnhW8FKohIZXe+\nM/CL26ZfRFXn4ySwxJ47fBJnKPTEfI3z1LSOOEmDlMapziBtLwINRaQaztPkTgPHReQanMdcJhbL\nUqBxfJlEpICIJFY7M+YiSxQms/gQeFRE1uI015xOZJv2wAYRWYPzrIpJ7p1GQ4HvRWQd8ANOs0yy\nVDUa6Ap8KSLrgThgHM5F9xv3eEtIvI1/AjAuvjM7wXGPApuB8qq63F2W4jjdvo+3gWdUdS3OM7e3\nAFNxmrPijQcWisgiVY3CuSNrmnueP3HeT2OSZKPHGmOM8cpqFMYYY7yyRGGMMcYrSxTGGGO8skRh\njDHGK0sUxhhjvLJEYYwxxitLFMYYY7z6P+NL4t/oX7MbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f310cdbed90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()    \n",
    "epochs=200 # change to 1500 for better results\n",
    "all_losses = []\n",
    "\n",
    "X_tensor_train= XnumpyToTensor(trainX)\n",
    "Y_tensor_train= YnumpyToTensor(trainY)\n",
    "\n",
    "print(type(X_tensor_train.data), type(Y_tensor_train.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "# From here onwards, we must only use PyTorch Tensors\n",
    "for step in range(epochs):    \n",
    "    out = net(X_tensor_train)                 # input x and predict based on x\n",
    "    cost = loss_func(out, Y_tensor_train)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    cost.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "                   \n",
    "        \n",
    "    if step % 10 == 0:        \n",
    "        loss = cost.data[0]\n",
    "        all_losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "        # Use .cpu() to move the tensor to host memory first.        \n",
    "        prediction = (net(X_tensor_train).data).float() # probabilities         \n",
    "#         prediction = (net(X_tensor).data > 0.5).float() # zero or one\n",
    "#         print (\"Pred:\" + str (prediction)) # Pred:Variable containing: 0 or 1\n",
    "#         pred_y = prediction.data.numpy().squeeze()            \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = Y_tensor_train.cpu().data.numpy()\n",
    "                        \n",
    "        tu = ((pred_y == target_y).mean(),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "        print ('ACC={}, LOG_LOSS={}, ROC_AUC={} '.format(*tu))        \n",
    "                \n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Performance of the deep learning model on the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16686, 21)\n",
      "(16686,)\n",
      "(16686, 21)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.FloatTensor'>\n",
      "(16686, 21)\n",
      "<type 'numpy.ndarray'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.FloatTensor'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.FloatTensor'> <class 'torch.FloatTensor'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "acc=0.0 log_loss=0.692716965698 roc_auc=0.524813809759 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMQFZojDGGBOQJQpjjDEB/R869F9InrqIrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f310cf34710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.eval()\n",
    "# Validation data\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "\n",
    "X_tensor_val= XnumpyToTensor(valX)\n",
    "Y_tensor_val= YnumpyToTensor(valY)\n",
    "\n",
    "\n",
    "print(type(X_tensor_val.data), type(Y_tensor_val.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "predicted_val = (net(X_tensor_val).data).float() # probabilities \n",
    "# predicted_val = (net(X_tensor_val).data > 0.5).float() # zero or one\n",
    "pred_y = predicted_val.cpu().numpy()\n",
    "target_y = Y_tensor_val.cpu().data.numpy()                \n",
    "\n",
    "print (type(pred_y))\n",
    "print (type(target_y))\n",
    "\n",
    "tu = (str ((pred_y == target_y).mean()),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "print ('\\n')\n",
    "print ('acc={} log_loss={} roc_auc={} '.format(*tu))\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# print (pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Submission on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45668, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90616.0</td>\n",
       "      <td>0.507826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148473.0</td>\n",
       "      <td>0.505317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72743.0</td>\n",
       "      <td>0.506913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32457.0</td>\n",
       "      <td>0.512687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12608.0</td>\n",
       "      <td>0.506489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  probability\n",
       "0   90616.0     0.507826\n",
       "1  148473.0     0.505317\n",
       "2   72743.0     0.506913\n",
       "3   32457.0     0.512687\n",
       "4   12608.0     0.506489"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testX, df_test_set\n",
    "# df[df.columns.difference(['b'])]\n",
    "# trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "\n",
    "print (df_test_set.shape)\n",
    "columns = ['id', 'probability']\n",
    "df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n",
    "df_pred.id.astype(int)\n",
    "\n",
    "for index, row in df_test_set.iterrows():\n",
    "    rwo_no_id=row.drop('id')    \n",
    "#     print (rwo_no_id.values)    \n",
    "    x_data_np = np.array(rwo_no_id.values, dtype=np.float32)        \n",
    "    if use_cuda:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "                    \n",
    "    X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n",
    "    predicted_val = (net(X_tensor_test).data).float() # probabilities     \n",
    "    p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n",
    "    \n",
    "    df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n",
    "\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create a CSV with the ID's and the coresponding probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/pred_0.692716965698_1505138667.16.csv\n"
     ]
    }
   ],
   "source": [
    "df_pred.id=df_pred.id.astype(int)\n",
    "\n",
    "def savePred(df_pred, loss):\n",
    "#     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n",
    "    csv_path = 'pred/pred_{}_{}.csv'.format(loss, (str(time.time())))\n",
    "    df_pred.to_csv(csv_path, columns=('id', 'probability'), index=None)\n",
    "    print (csv_path)\n",
    "    \n",
    "savePred (df_pred, log_loss(target_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Actual score on Numer.ai - screenshot of the leader board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"../images/numerai-score.jpg\" width=\"35%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
