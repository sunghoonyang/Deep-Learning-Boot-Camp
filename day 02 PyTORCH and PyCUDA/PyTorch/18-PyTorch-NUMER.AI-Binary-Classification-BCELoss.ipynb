{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 18  PyTorch NUMER.AI  Deep Learning Binary Classification using BCELoss \n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# What consists a Numerai competition?\n",
    "- Numerai provides payments based on the number of correctly predictted labels (LOGG_LOSS) in a data-set which changes every week.\n",
    "\n",
    "- Two data-sets are provided: numerai_training_data.csv and numerai_tournament_data.csv\n",
    "\n",
    "# Criteria \n",
    "- On top of LOG_LOSS, they also measure:\n",
    "* Consistency\n",
    "* Originality\t\n",
    "* Concordance \n",
    "\n",
    "\n",
    "# PyTorch and Numerai\n",
    "\n",
    "- This tutorial was written in order to demonstrate a **fully working** example of a PyTorch NN on a real world use case, namely a Binary Classification problem on the NumerAI data set. If you are interested in the sk-learn version of this problem please refer to: https://github.com/QuantScientist/deep-ml-meetups/tree/master/hacking-kaggle/python/numer-ai \n",
    "\n",
    "- For the scientific foundation behind Binary Classification and Logistic Regression, refer to: https://github.com/QuantScientist/Deep-Learning-Boot-Camp/tree/master/Data-Science-Interviews-Book\n",
    "\n",
    "- Every step, from reading the CSV into numpy arrays, converting to GPU based tensors, training and validation, are meant to aid newcomers in their first steps in PyTorch. \n",
    "\n",
    "- Additionally, commonly used Kaggle metrics such as ROC_AUC and LOG_LOSS are logged and plotted both for the training set as well as for the validation set. \n",
    "\n",
    "- Thus, the NN architecture is naive and by no means **optimized**. Hopefully, I will improve it over time and I am working on a second CNN based version of the same problem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Data\n",
    "- Download from https://numer.ai/leaderboard\n",
    "\n",
    "\n",
    "<img src=\"../images/numerai-logo.png\" width=\"35%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "__pyTorch VERSION: 0.2.0+42448cf\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "OS:  linux2\n",
      "Python:  2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "PyTorch:  0.2.0+42448cf\n",
      "Numpy:  1.13.1\n",
      "2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "0.0\n",
      "svmem(total=67469099008, available=63503302656, percent=5.9, used=3362988032, free=61743452160, active=4016717824, inactive=1136144384, buffers=281509888, cached=2081148928, shared=61988864)\n",
      "memory GB: 0.219425201416\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "# %%timeit\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import logging\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "\n",
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install psutil\n",
    "import psutil\n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "\n",
    "cpuStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:USE CUDA=True\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "lgr.info(\"USE CUDA=\" + str (use_cuda))\n",
    "\n",
    "# ! watch -n 0.1 'ps f -o user,pgrp,pid,pcpu,pmem,start,time,command -p `lsof -n -w -t /dev/nvidia*`'\n",
    "# sudo apt-get install dstat #install dstat\n",
    "# sudo pip install nvidia-ml-py #install Python NVIDIA Management Library\n",
    "# wget https://raw.githubusercontent.com/datumbox/dstat/master/plugins/dstat_nvidia_gpu.py\n",
    "# sudo mv dstat_nvidia_gpu.py /usr/share/dstat/ #move file to the plugins directory of dstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN params\n",
    "DROPOUT_PROB = 0.75\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.005\n",
    "MOMENTUM= 0.9\n",
    "PIN_MEMORY=use_cuda # True IF CUDA\n",
    "\n",
    "# Data params\n",
    "TARGET_VAR= 'target'\n",
    "TOURNAMENT_DATA_CSV = 'numerai_tournament_data.csv'\n",
    "TRAINING_DATA_CSV = 'numerai_training_data.csv'\n",
    "BASE_FOLDER = 'numerai/'\n",
    "\n",
    "# fix seed\n",
    "seed=17*19\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Load a CSV file for Binary classification (numpy)\n",
    "\n",
    "As mentioned, NumerAI provided **numerai_training_data.csv** and **numerai_tournament_data.csv.**\n",
    "\n",
    "- Training_data.csv is labeled\n",
    "- Numerai_tournament_data.csv has lebles for the **validation set** and no labels for the **test set**. See belo how I seperate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72774</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.48937</td>\n",
       "      <td>0.56969</td>\n",
       "      <td>0.59150</td>\n",
       "      <td>0.46432</td>\n",
       "      <td>0.42291</td>\n",
       "      <td>0.49616</td>\n",
       "      <td>0.53542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42195</td>\n",
       "      <td>0.62651</td>\n",
       "      <td>0.51604</td>\n",
       "      <td>0.42938</td>\n",
       "      <td>0.56744</td>\n",
       "      <td>0.60008</td>\n",
       "      <td>0.46966</td>\n",
       "      <td>0.50322</td>\n",
       "      <td>0.42803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140123</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.57142</td>\n",
       "      <td>0.43408</td>\n",
       "      <td>0.58771</td>\n",
       "      <td>0.44570</td>\n",
       "      <td>0.41471</td>\n",
       "      <td>0.49137</td>\n",
       "      <td>0.52791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46301</td>\n",
       "      <td>0.55103</td>\n",
       "      <td>0.39053</td>\n",
       "      <td>0.48856</td>\n",
       "      <td>0.54305</td>\n",
       "      <td>0.59213</td>\n",
       "      <td>0.44935</td>\n",
       "      <td>0.56685</td>\n",
       "      <td>0.59645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46882</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.75694</td>\n",
       "      <td>0.59942</td>\n",
       "      <td>0.36154</td>\n",
       "      <td>0.65571</td>\n",
       "      <td>0.60520</td>\n",
       "      <td>0.45317</td>\n",
       "      <td>0.49847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68057</td>\n",
       "      <td>0.43763</td>\n",
       "      <td>0.46322</td>\n",
       "      <td>0.63211</td>\n",
       "      <td>0.32947</td>\n",
       "      <td>0.35632</td>\n",
       "      <td>0.56316</td>\n",
       "      <td>0.33888</td>\n",
       "      <td>0.40120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20833</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.46059</td>\n",
       "      <td>0.50856</td>\n",
       "      <td>0.64215</td>\n",
       "      <td>0.41382</td>\n",
       "      <td>0.39550</td>\n",
       "      <td>0.49282</td>\n",
       "      <td>0.54697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38108</td>\n",
       "      <td>0.65446</td>\n",
       "      <td>0.54926</td>\n",
       "      <td>0.36297</td>\n",
       "      <td>0.61482</td>\n",
       "      <td>0.64292</td>\n",
       "      <td>0.52910</td>\n",
       "      <td>0.53582</td>\n",
       "      <td>0.47027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5381</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.61195</td>\n",
       "      <td>0.66684</td>\n",
       "      <td>0.45877</td>\n",
       "      <td>0.56730</td>\n",
       "      <td>0.51889</td>\n",
       "      <td>0.41257</td>\n",
       "      <td>0.56030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54803</td>\n",
       "      <td>0.59120</td>\n",
       "      <td>0.58160</td>\n",
       "      <td>0.51828</td>\n",
       "      <td>0.43870</td>\n",
       "      <td>0.47011</td>\n",
       "      <td>0.56007</td>\n",
       "      <td>0.36374</td>\n",
       "      <td>0.31552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   era data_type  feature1  feature2  feature3  feature4  feature5  \\\n",
       "0   72774  era1     train   0.48937   0.56969   0.59150   0.46432   0.42291   \n",
       "1  140123  era1     train   0.57142   0.43408   0.58771   0.44570   0.41471   \n",
       "2   46882  era1     train   0.75694   0.59942   0.36154   0.65571   0.60520   \n",
       "3   20833  era1     train   0.46059   0.50856   0.64215   0.41382   0.39550   \n",
       "4    5381  era1     train   0.61195   0.66684   0.45877   0.56730   0.51889   \n",
       "\n",
       "   feature6  feature7   ...    feature13  feature14  feature15  feature16  \\\n",
       "0   0.49616   0.53542   ...      0.42195    0.62651    0.51604    0.42938   \n",
       "1   0.49137   0.52791   ...      0.46301    0.55103    0.39053    0.48856   \n",
       "2   0.45317   0.49847   ...      0.68057    0.43763    0.46322    0.63211   \n",
       "3   0.49282   0.54697   ...      0.38108    0.65446    0.54926    0.36297   \n",
       "4   0.41257   0.56030   ...      0.54803    0.59120    0.58160    0.51828   \n",
       "\n",
       "   feature17  feature18  feature19  feature20  feature21  target  \n",
       "0    0.56744    0.60008    0.46966    0.50322    0.42803       1  \n",
       "1    0.54305    0.59213    0.44935    0.56685    0.59645       1  \n",
       "2    0.32947    0.35632    0.56316    0.33888    0.40120       0  \n",
       "3    0.61482    0.64292    0.52910    0.53582    0.47027       0  \n",
       "4    0.43870    0.47011    0.56007    0.36374    0.31552       1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Feature enrichement\n",
    "- This would be usually not required when using NN's; it is here for demonstration purposes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def genBasicFeatures(inDF):\n",
    "#     print('Generating basic features ...')\n",
    "#     df_copy=inDF.copy(deep=True)\n",
    "#     magicNumber=21\n",
    "#     feature_cols = list(inDF.columns)\n",
    "\n",
    "#     inDF['x_mean'] = np.mean(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_median'] = np.median(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_std'] = np.std(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_skew'] = scipy.stats.skew(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_kurt'] = scipy.stats.kurtosis(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_var'] = np.var(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_max'] = np.max(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_min'] = np.min(df_copy.ix[:, 0:magicNumber], axis=1)    \n",
    "\n",
    "#     return inDF\n",
    "\n",
    "def addPolyFeatures(inDF, deg=2):\n",
    "    print('Generating poly features ...')\n",
    "    df_copy=inDF.copy(deep=True)\n",
    "    poly=PolynomialFeatures(degree=deg)\n",
    "    p_testX = poly.fit(df_copy)\n",
    "    # AttributeError: 'PolynomialFeatures' object has no attribute 'get_feature_names'\n",
    "    target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(df_copy.columns,p) for p in poly.powers_]]\n",
    "    df_copy = pd.DataFrame(p_testX.transform(df_copy),columns=target_feature_names)\n",
    "        \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Train / Validation / Test Split\n",
    "- Numerai provides a data set that is allready split into train, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train, Validation, Test Split\n",
    "def loadDataSplit():\n",
    "    df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    df_test_valid = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "\n",
    "    answers_1_SINGLE = df_train[TARGET_VAR]\n",
    "    df_train.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    df_train.drop('id', axis=1,inplace=True)\n",
    "    df_train.drop('era', axis=1,inplace=True)\n",
    "    df_train.drop('data_type', axis=1,inplace=True)    \n",
    "    \n",
    "    # Add polynomial features    \n",
    "#     df_train=genBasicFeatures(df_train)\n",
    "#     df_train = addPolyFeatures(df_train)\n",
    "\n",
    "    df_train.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=False,  index = False)    \n",
    "    df_train= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=None, dtype=np.float32)    \n",
    "    df_train = pd.concat([df_train, answers_1_SINGLE], axis=1)\n",
    "    feature_cols = list(df_train.columns[:-1])\n",
    "#     print (feature_cols)\n",
    "    target_col = df_train.columns[-1]\n",
    "    trainX, trainY = df_train[feature_cols], df_train[target_col]\n",
    "    \n",
    "    \n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    # Validation set\n",
    "    df_validation_set=df_test_valid.loc[df_test_valid['data_type'] == 'validation'] \n",
    "    df_validation_set=df_validation_set.copy(deep=True)\n",
    "    answers_1_SINGLE_validation = df_validation_set[TARGET_VAR]\n",
    "    df_validation_set.drop(TARGET_VAR, axis=1,inplace=True)    \n",
    "    df_validation_set.drop('id', axis=1,inplace=True)\n",
    "    df_validation_set.drop('era', axis=1,inplace=True)\n",
    "    df_validation_set.drop('data_type', axis=1,inplace=True)\n",
    "    \n",
    "   # Add polynomial features    \n",
    "#     df_validation_set=genBasicFeatures(df_validation_set)\n",
    "#     df_validation_set = addPolyFeatures(df_validation_set)\n",
    "    \n",
    "    df_validation_set.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=False,  index = False)    \n",
    "    df_validation_set= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=None, dtype=np.float32)    \n",
    "    df_validation_set = pd.concat([df_validation_set, answers_1_SINGLE_validation], axis=1)\n",
    "    feature_cols = list(df_validation_set.columns[:-1])\n",
    "\n",
    "    target_col = df_validation_set.columns[-1]\n",
    "    valX, valY = df_validation_set[feature_cols], df_validation_set[target_col]\n",
    "                            \n",
    "    # Test set for submission (not labeled)    \n",
    "    df_test_set = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "#     df_test_set=df_test_set.loc[df_test_valid['data_type'] == 'live'] \n",
    "    df_test_set=df_test_set.copy(deep=True)\n",
    "    df_test_set.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    tid_1_SINGLE = df_test_set['id']\n",
    "    df_test_set.drop('id', axis=1,inplace=True)\n",
    "    df_test_set.drop('era', axis=1,inplace=True)\n",
    "    df_test_set.drop('data_type', axis=1,inplace=True)   \n",
    "    \n",
    "    # Add polynomial features    \n",
    "#     df_test_set=genBasicFeatures(df_test_set)\n",
    "#     df_test_set = addPolyFeatures(df_test_set)\n",
    "   \n",
    "    \n",
    "    feature_cols = list(df_test_set.columns) # must be run here, we dont want the ID    \n",
    "#     print (feature_cols)\n",
    "    df_test_set = pd.concat([tid_1_SINGLE, df_test_set], axis=1)            \n",
    "    testX = df_test_set[feature_cols].values\n",
    "        \n",
    "    return trainX, trainY, valX, valY, testX, df_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108405, 21)\n",
      "(108405,)\n",
      "(16686, 21)\n",
      "(16686,)\n",
      "(45668, 21)\n",
      "(45668, 22)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "# # Number of features for the input layer\n",
    "N_FEATURES=trainX.shape[1]\n",
    "print (trainX.shape)\n",
    "print (trainY.shape)\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "print (testX.shape)\n",
    "print (df_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create PyTorch GPU tensors from numpy arrays\n",
    "\n",
    "- Note how we transfrom the np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def XnumpyToTensor(x_data_np):\n",
    "    x_data_np = np.array(x_data_np.values, dtype=np.float32)        \n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")    \n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")\n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "    \n",
    "    print(type(X_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))    \n",
    "    return X_tensor\n",
    "\n",
    "\n",
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def YnumpyToTensor(y_data_np):    \n",
    "    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")            \n",
    "    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")        \n",
    "    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n",
    "\n",
    "    print(type(Y_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))    \n",
    "    return Y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The NN model\n",
    "\n",
    "### MLP model\n",
    "- A multilayer perceptron is a logistic regressor where instead of feeding the input to the logistic regression you insert a intermediate layer, called the hidden layer, that has a nonlinear activation function (usually tanh or sigmoid) . One can use many such hidden layers making the architecture deep.\n",
    "\n",
    "- Here we define a simple MLP structure. We map the input feature vector to a higher space, then later gradually decrease the dimension, and in the end into a 1-dimension space. Because we are calculating the probability of each genre independently, after the final layer we need to use a sigmoid layer. \n",
    "\n",
    "###  Initial weights selection\n",
    "\n",
    "- There are many ways to select the initial weights to a neural network architecture. A common initialization scheme is random initialization, which sets the biases and weights of all the nodes in each hidden layer randomly.\n",
    "\n",
    "- Before starting the training process, an initial value is assigned to each variable. This is done by pure randomness, using for example a uniform or Gaussian distribution. But if we start with weights that are too small, the signal could decrease so much that it is too small to be useful. On the other side, when the parameters are initialized with high values, the signal can end up to explode while propagating through the network.\n",
    "\n",
    "- In consequence, a good initialization can have a radical effect on how fast the network will learn useful patterns.For this purpose, some best practices have been developed. One famous example used is **Xavier initialization**. Its formulation is based on the number of input and output neurons and uses sampling from a uniform distribution with zero mean and all biases set to zero.\n",
    "\n",
    "- In effect (according to theory) initializing the weights of the network to values that would be closer to the optimal, and therefore require less epochs to train.\n",
    "\n",
    "### References: \n",
    "* **`nninit.xavier_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a uniform distribution.\n",
    "* **`nninit.xavier_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a normal distribution.\n",
    "* **`nninit.kaiming_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.](https://arxiv.org/abs/1502.01852) using a uniform distribution.\n",
    "* **`nninit.kaiming_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (21 -> 2560)\n",
      "  (1): Dropout (p = 0.05)\n",
      "  (2): LeakyReLU (0.01)\n",
      "  (3): BatchNorm1d(2560, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (4): Linear (2560 -> 320)\n",
      "  (5): Dropout (p = 0.05)\n",
      "  (6): LeakyReLU (0.01)\n",
      "  (7): Linear (320 -> 160)\n",
      "  (8): Dropout (p = 0.05)\n",
      "  (9): LeakyReLU (0.01)\n",
      "  (10): Linear (160 -> 80)\n",
      "  (11): Dropout (p = 0.05)\n",
      "  (12): LeakyReLU (0.01)\n",
      "  (13): Linear (80 -> 40)\n",
      "  (14): Dropout (p = 0.05)\n",
      "  (15): LeakyReLU (0.01)\n",
      "  (16): Linear (40 -> 1)\n",
      "  (17): Sigmoid ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# p is the probability of being dropped in PyTorch\n",
    "# At each layer, DECREASE dropout\n",
    "dropout = torch.nn.Dropout(p=1 - (DROPOUT_PROB +0.20))\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output,initKernel='uniform'):\n",
    "        super(Net2, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(n_feature, n_hidden),\n",
    "            dropout,\n",
    "            nn.LeakyReLU(0.1),\n",
    "                                    \n",
    "            nn.Linear(n_hidden, int(n_hidden /2)),\n",
    "            dropout,\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.Linear(int(n_hidden /2), int(n_hidden /4)),\n",
    "            dropout,\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.Linear(int(n_hidden /4), 1),            \n",
    "            nn.Sigmoid()\n",
    "        )        \n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x\n",
    "\n",
    "hiddenLayer1Size=2560\n",
    "hiddenLayer2Size=int(hiddenLayer1Size/8)\n",
    "hiddenLayer3Size=int(hiddenLayer1Size/16)\n",
    "hiddenLayer4Size=int(hiddenLayer1Size/32)\n",
    "hiddenLayer5Size=int(hiddenLayer1Size/64)\n",
    "\n",
    "linear1=torch.nn.Linear(N_FEATURES, hiddenLayer1Size, bias=True) \n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "\n",
    "linear2=torch.nn.Linear(hiddenLayer1Size, hiddenLayer2Size)\n",
    "torch.nn.init.xavier_uniform(linear2.weight)\n",
    "\n",
    "linear3=torch.nn.Linear(hiddenLayer2Size, hiddenLayer3Size)\n",
    "torch.nn.init.xavier_uniform(linear3.weight)\n",
    "\n",
    "linear4=torch.nn.Linear(hiddenLayer3Size, hiddenLayer4Size)\n",
    "torch.nn.init.xavier_uniform(linear4.weight)\n",
    "\n",
    "linear5=torch.nn.Linear(hiddenLayer4Size, hiddenLayer5Size)\n",
    "torch.nn.init.xavier_uniform(linear5.weight)\n",
    "\n",
    "linear6=torch.nn.Linear(hiddenLayer5Size, 1)\n",
    "torch.nn.init.xavier_uniform(linear6.weight)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "tanh=torch.nn.Tanh()\n",
    "relu=torch.nn.LeakyReLU()\n",
    "\n",
    "net = torch.nn.Sequential(linear1,dropout,relu,nn.BatchNorm1d(hiddenLayer1Size),\n",
    "                          linear2,dropout,relu,\n",
    "                          linear3,dropout,relu,\n",
    "                          linear4,dropout,relu,\n",
    "                          linear5,dropout,relu,\n",
    "                          linear6,sigmoid\n",
    "                          )\n",
    "\n",
    "# net = Net(n_feature=N_FEATURES, n_hidden=1024, n_output=1)   # define the network\n",
    "# net = Net2(n_feature=N_FEATURES, n_hidden=512, n_output=1)   # define the network\n",
    "\n",
    "lgr.info(net)  # net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Print the full net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (21 -> 2560), weights=((2560L, 21L), (2560L,)), parameters=56320\n",
      "  (1): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (2): LeakyReLU (0.01), weights=(), parameters=0\n",
      "  (3): BatchNorm1d(2560, eps=1e-05, momentum=0.1, affine=True), weights=((2560L,), (2560L,)), parameters=5120\n",
      "  (4): Linear (2560 -> 320), weights=((320L, 2560L), (320L,)), parameters=819520\n",
      "  (5): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (6): LeakyReLU (0.01), weights=(), parameters=0\n",
      "  (7): Linear (320 -> 160), weights=((160L, 320L), (160L,)), parameters=51360\n",
      "  (8): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (9): LeakyReLU (0.01), weights=(), parameters=0\n",
      "  (10): Linear (160 -> 80), weights=((80L, 160L), (80L,)), parameters=12880\n",
      "  (11): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (12): LeakyReLU (0.01), weights=(), parameters=0\n",
      "  (13): Linear (80 -> 40), weights=((40L, 80L), (40L,)), parameters=3240\n",
      "  (14): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (15): LeakyReLU (0.01), weights=(), parameters=0\n",
      "  (16): Linear (40 -> 1), weights=((1L, 40L), (1L,)), parameters=41\n",
      "  (17): Sigmoid (), weights=(), parameters=0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Taken from https://stackoverflow.com/questions/42480111/model-summary-in-pytorch/42616812\n",
    "from torch.nn.modules.module import _addindent\n",
    "import torch\n",
    "import numpy as np\n",
    "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
    "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
    "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
    "    for key, module in model._modules.items():\n",
    "        # if it contains layers let call it recursively to get params and weights\n",
    "        if type(module) in [\n",
    "            torch.nn.modules.container.Container,\n",
    "            torch.nn.modules.container.Sequential\n",
    "        ]:\n",
    "            modstr = torch_summarize(module)\n",
    "        else:\n",
    "            modstr = module.__repr__()\n",
    "        modstr = _addindent(modstr, 2)\n",
    "\n",
    "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
    "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
    "\n",
    "        tmpstr += '  (' + key + '): ' + modstr \n",
    "        if show_weights:\n",
    "            tmpstr += ', weights={}'.format(weights)\n",
    "        if show_parameters:\n",
    "            tmpstr +=  ', parameters={}'.format(params)\n",
    "        tmpstr += '\\n'   \n",
    "\n",
    "    tmpstr = tmpstr + ')'\n",
    "    return tmpstr\n",
    "\n",
    "lgr.info(torch_summarize(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Loss and Optimizer\n",
    "\n",
    "###  BCELoss\n",
    "- In addition, we will calculate the binary cross entropy loss (BCELoss). Luckily we have one loss function already present. For details please checkout http://pytorch.org/docs/master/nn.html. \n",
    "\n",
    "- ** NOTE this BCELoss may not be numerical stable, although it's fine during my training process.**\n",
    "\n",
    "### Optimization\n",
    "\n",
    "- if return F.log_softmax(x) then loss = F.nll_loss(output, target) (MNIST)\n",
    "- print(nn.BCEWithLogitsLoss()(o, t)) is equivalent to print(nn.BCELoss()(sigmoid(o), t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ! pip install sympy\n",
    "import sympy as sp\n",
    "sp.interactive.printing.init_printing(use_latex=True)\n",
    "from IPython.display import display, Math, Latex\n",
    "maths = lambda s: display(Math(s))\n",
    "latex = lambda s: display(Latex(s))\n",
    "\n",
    "#the loss function is as follows:\n",
    "maths(\"\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "INFO:__main__:<torch.optim.adam.Adam object at 0x7f34b1ae5350>\n",
      "INFO:__main__:BCELoss (\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.02)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=5e-4)\n",
    "#L2 regularization can easily be added to the entire model via the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-4) #  L2 regularization\n",
    "\n",
    "loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "# http://andersonjo.github.io/artificial-intelligence/2017/01/07/Cost-Functions/\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    net.cuda()\n",
    "    loss_func.cuda()\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "lgr.info (optimizer)\n",
    "lgr.info (loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Training in batches  + Measuring the performance of the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108405, 21)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(108405, 21)\n",
      "<type 'numpy.ndarray'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "0 [ 0.70547867]\n",
      "ACC=0.0, LOG_LOSS=1.0492387174, ROC_AUC=0.505032726659 \n",
      "10 [ 0.69426191]\n",
      "ACC=0.0, LOG_LOSS=0.694185442646, ROC_AUC=0.504384575542 \n",
      "20 [ 0.69318062]\n",
      "ACC=0.0, LOG_LOSS=0.693241840141, ROC_AUC=0.506067815493 \n",
      "30 [ 0.69305259]\n",
      "ACC=0.0, LOG_LOSS=0.692999652127, ROC_AUC=0.509238385005 \n",
      "40 [ 0.69291157]\n",
      "ACC=0.0, LOG_LOSS=0.692918589002, ROC_AUC=0.510741973855 \n",
      "50 [ 0.69277036]\n",
      "ACC=0.0, LOG_LOSS=0.69275011412, ROC_AUC=0.515590797114 \n",
      "60 [ 0.69271612]\n",
      "ACC=0.0, LOG_LOSS=0.692678969245, ROC_AUC=0.516994975212 \n",
      "70 [ 0.69263655]\n",
      "ACC=0.0, LOG_LOSS=0.692558319599, ROC_AUC=0.519586824498 \n",
      "80 [ 0.69250691]\n",
      "ACC=0.0, LOG_LOSS=0.692555135804, ROC_AUC=0.519261714629 \n",
      "90 [ 0.69247174]\n",
      "ACC=0.0, LOG_LOSS=0.692482516371, ROC_AUC=0.520201306479 \n",
      "100 [ 0.69257164]\n",
      "ACC=0.0, LOG_LOSS=0.692534995773, ROC_AUC=0.518993493038 \n",
      "110 [ 0.69244826]\n",
      "ACC=0.0, LOG_LOSS=0.692599681024, ROC_AUC=0.517760970006 \n",
      "120 [ 0.6924302]\n",
      "ACC=0.0, LOG_LOSS=0.692430208917, ROC_AUC=0.520270412797 \n",
      "130 [ 0.69246459]\n",
      "ACC=0.0, LOG_LOSS=0.692327024305, ROC_AUC=0.521852208606 \n",
      "140 [ 0.69250965]\n",
      "ACC=0.0, LOG_LOSS=0.692421391947, ROC_AUC=0.520369349371 \n",
      "150 [ 0.69250035]\n",
      "ACC=0.0, LOG_LOSS=0.69238671553, ROC_AUC=0.52132899633 \n",
      "160 [ 0.69242698]\n",
      "ACC=0.0, LOG_LOSS=0.69239370888, ROC_AUC=0.520633852413 \n",
      "170 [ 0.69225699]\n",
      "ACC=0.0, LOG_LOSS=0.692397879967, ROC_AUC=0.520090542137 \n",
      "180 [ 0.69232392]\n",
      "ACC=0.0, LOG_LOSS=0.692372095015, ROC_AUC=0.521163255575 \n",
      "190 [ 0.69237643]\n",
      "ACC=0.0, LOG_LOSS=0.692350520732, ROC_AUC=0.521232881176 \n",
      "GPU: 499.629 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34b0552790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcjXX7wPHPZWwJKbQ8JJPdYNBE2j2laN+eUloUSTuV\n0iOKR0mkfZP6SQtKWSqUJFG2sS+lhBgtZC/RDNfvj+seHdPMmTNjzpxZrvfrdV7m3Ot1z4xzzff7\nve/rK6qKc845l5USsQ7AOedcweaJwjnnXFieKJxzzoXlicI551xYniicc86F5YnCOedcWJ4onHPO\nheWJwjnnXFieKIohEVkrImdnsrySiLwkIr+IyC4RWSoiN2ayXXsRmSMif4jIxuDr20REsjnvcBHp\nn8U6EZEeIvK9iPwpIutEZICIlAnZprqIvC8iv4nIdhFZJiIdQ9Z3EpFvRWSniPwqIhNFpEIOvzci\nIgNFZHPwGhjuukSkqoi8E8SzVUTeDllXTUTGi8gWEUkRka4h6+oG6zYF6z8RkXoh69uLyMrguBtF\n5A0RqRiy/gsR2S0ivwevlRniukZEfgx+RuNE5IhI9hWR80VkpohsC34PhoV+D0WkjIi8LiI7gvX3\nhKzrEHLM34PfIRWRE4L13UVkdbDvTyLylIiUDNYdKSIjg+XbReQrEWmZk5+diyJV9VcxewFrgbMz\nLCsNJAMTgXigFNAW+BW4J2S7e4NlVwAVAAGaAW8DZbI573CgfxbrngO+B1oBJYEEYC4wPmSbacDT\nwKHBNs2AdsG6M4K4mgXvjwBuACrk8HtzC7ASqA5UA1YAXcNsPwMYAhwWfM+aZRJvKSAR2AK0Dta1\nADoFcZYC/gd8G7LvsUCV4Ovywff32ZD1XwCds4gpAdgJnB7s+w4wKsJ9rwl+7uWAw4FJwMsh6wcE\n13w40AD4BWibxbE6Aj8AEryvBVQK+fl8nv67BRwP3AMcA8QBXYDfgPKx/v/iL/VEURxfZJ4oOgEb\ngUMzLL8K+B2oGHwY/gFcnsvzZpoogDrAXqBFhuXHAnuAfwfvfweaZnHs+4BxefC9+RrokuH7MjuL\nbc8JvpdxmawrDyhQNWTZUODNLI51RLB95SyONQKYGLIs3If9Y8A7Ie9rAX8RJM1w+2ZyrMuApSHv\nfwLOCXn/v9AklGHfacDDWayrDHwGvBjm3DuAE/Lq995fuX9515NL1waYpKp/ZFj+PlAW+0u/FVAG\nGJ/H5z4LSFHVuaELVXU9MDuIjeDrF4JumRoZjjEHOFdE+orIKaFdVgAi0jPoTsn0FbJpArA45P3i\nYFlmTsJaH28E3VTzROSM9FNm+Df960ZZHOt04BdV3RwS86kish1rHVyOtU5CDQi64b4SkTOzugZV\n/QFLFHUj2DezuJYH8RyO/cWf7fdHRI4L9h2RYfk1IrIDay0kAq9kdlIRaYq1cleFic3lE08ULl0V\n4OeMC1U1DftPXSV4/RYsA0BEvg4+bP8UkdPz8tyBn4P1AP/Buj16A2tEZJGInBjEOQP767c58DGw\nWUSGiEhcsP5xVa2U1SvkfOWB7SHvtwPlsxinqI61KqYBRwNPAuNFpIqq7gS+AnqLSFkRaY592JfL\neBARqQ68gHW97KeqM1X1sOA8g7DWS7oHsO6aalhL5UMRqZXFNaRfR4UI9g2Nqw3Wfdcn5Ljpx8rs\nuKGuB2ao6poM1/SOqlbEktbLWHdhxvNWBN4E+qpqxutwMeCJwqX7Dftr8QDBYGOVYP1moEr6ACSA\nqp4cfNBuJve/T5meO3BMsB5V3aqqPVU1ATgKWASMS/8QV9VJqnoh1o1zMdZH3jmHsaR3s6WrCPyu\nqpmVWf4TWKuqr6lqqqqOAtYDpwTrO2DjPeuBl4C3gJTQA4hIVeBTrAtmZGYBqeoGYDIwKmTZHFXd\nqap7VPUNLCmdl8U1pF/Hzgj2TY/rJGxs4wpV/S7kuOnH+sdxM7geeCOz6wli+B5rqbyY4byHAB9i\n3X0Dstrf5S9PFC7dZ0A7ETk0w/LLsXGC2cCs4OuL8/jcnwPHikiL0IUicizWvTM14w6q+hswGPgX\nlhhC1+1T1anBcRsFx/pvhjtyDniF7L4c6xJJlxgsy8wSbFzhgNOHxPGjql6gqlVVtSWWcPd3rwVd\nOZ8CE1T10SzOka4kNtaQFeXvbq4DrkFEjse6DL/LZL+M+yIizYAJwE3B9zH9erZiLbyw3x8ROQX7\nuYwJe0UZrinoLhyHJdNbstnX5adYD5L4K/9fWBdGO2zsIf1VBliA3fVUE7sT51ysa6BHyL73c+Bd\nTyWApsBW4Mxszjscu2sm9Lylg3UvYnc9nYTd9ZJ+19PHIfsPxD74SwbnfgH4Plh3MdAeuxtHsLuK\nNgEdcvi96Qp8g3XL/Av7EMz0ricsQW3Fumfigu/JFv6+W6lBEGdp4FqsZVQ1WFcxuL7nszh2B6BG\n8PVxwHTgg+B9peBnUzb4XnTAbjKoG6xPwAaCT8PuEHuLYMA5gn0bBT/fq7KI6/EglsOB+ljiaJth\nm6HAiEz27QwcGXzdMPjeDgnel8JaEuOAkrH+P+KvDD+7WAfgrxj80C1RaIZX/+CD75Xgg+LP4D/y\nP+6OCT5c5gK7gg/jOdjtjKWzOe/wTM47M1hXAus7XxWcez3wBFA2ZP/0W2h/D877EdAgWHc61vL4\nDesK+Q64PxffGwnOuyV4PUFwe2ew/nfgtJD3pwFLg+XJGdZ1C+L8A5gJJIWsuyG4/j+CfdNf6cnh\nUewv6z+Cf4cS3BEFVAXmBde5jWDAP8N1XAOsC/YfDxwRyb7A/wH7MsS0PGR9GeB1LBEdcOt0sL5s\ncNyzMvne/l+wzx/Y7+Cg9J8vdnuzBr9Toec+Lauflb/y75V+f7NzzjmXqaiNUQRPb24UkWVZrO8g\nIkvEnv79WkQSM9vOOedcbEVzMHs49oRnVtYAZ6hqY+yhnaFRjMXlExFZnsWAcYdYx+acy52odj2J\nSE3gI1XN6iGj9O0OB5aparWoBeOccy5XSma/Sb7ohNWUyZSIdMEGSzn00ENPqF+/fn7F5ZxzRcL8\n+fN/U9Wqudk35olCRFpjieLUrLZR1aEEXVNJSUmanJycT9E551zRICI/5nbfmCYKEWkCDMMqgG7O\nbnvnnHP5L2ZPZgdF3T4ArtO/SwQ455wrYKLWohCRkcCZWG2gFOBh7OlLVPVlrNBYZeDFoFRPmqom\nRSse55xzuRO1RKGqV2ezvjM5L9jmnHMun3lRQOecc2F5onDOOReWJwrnnHNheaJwzjkXlicK55xz\nYXmicM45F5YnCuecc2F5onDOOReWJwrnnHNheaJwzjkXlicK55xzYXmicM45F5YnCuecc2F5onDO\nOReWJwrnnHNheaJwzjkXlicK55xzYXmicM45F5YnCuecc2F5onDOOReWJwrnnHNheaJwzjkXlicK\n55xzYXmicM45F5YnCuecc2FFLVGIyOsislFElmWxXkTkWRFZJSJLRKR5tGJxzjmXe9FsUQwH2oZZ\n3w6oE7y6AC9FMRbnnHO5FLVEoapfAlvCbHIxMELNbKCSiBwTrXiccy4SG9bt5ZUGT3Fx6UnMmhXr\naAqGWI5RVAPWh7xPCZb9g4h0EZFkEUnetGlTvgTnnCteVqyA7ucsZ/1xp3DLt/fQreY4mjSJdVQF\nQ6EYzFbVoaqapKpJVatWjXU4zrki5OefoUunvYxu1I+BU5rR6JAf2Pj0O7Re+TKHHhrr6AqGkjE8\n9wbg2JD31YNlzjkXdRs2wJNPwiuvQFpqCRbUmMPe5v+h/CtPU97/ID1ALFsUE4Drg7ufTgK2q+rP\nMYzHOVcM7NoFDz0ETWrv4uine3LLuWtZtlxIWPkBh3zwNniS+IeotShEZCRwJlBFRFKAh4FSAKr6\nMjAROA9YBewCboxWLM45t3kzDBxoLYhmO75gefnOHL37B/h3dahzB1Am1iEWWFFLFKp6dTbrFbg9\nWud3zjmAHTvg5Zfh8cdh39btfFDrfs7aMRSOqgUTPofWrWMdYoFXKAaznXMup1Rh1CioWxceeABO\nPBG+6/gYZ60ZBvfdB0uWeJKIUCwHs51zLirmz4euXSE5GU6qtYnJT/9G0/YNYPt/4bYrLGu4iHmL\nwjlXZGzcaAnixBNh3Y/K553f4ettDWg66FprYhx2mCeJXPBE4Zwr9PbuhZdesm6mV16B3jemkNL8\nIloP64DUqgVvvAEisQ6z0PKuJ+dcofbZZ9CjByxaBKefDq/etpC6N58BaWkwZAjcdRfExcU6zELN\nWxTOuUJp9Wq46ipo0wa2bYORI1KZNg3qXtYIrrsOli2D7t09SeQBTxTOuUJl40bo1g3q14ePPoK+\nvdP4rstg2j9SnxLbt0KpUvDCC3D88bEOtcjwrifnXKGwYwc89hg8+yzs3g033giPXb2Uo/7bCebN\ng4sugtTUWIdZJHmLwjlXoKWm2gB1vXrwxBNw6aWwYuleXqv+MEe1aw5r18Lo0TBuHBx5ZKzDLZK8\nReGcK7BmzoTbb7dn41q2tFzQsiWgJewhifbt4emnoXLlWIdapHmLwjlX4KxcCe3awWmnwdatMGYM\nzPrsD1q+fz+sWWO3un7wAbz5pieJfOCJwjlXYOzaBf37Q5Mm8PXXNiaxYgVcXmkq0qQxDBoEkybZ\nxmW8iF9+8a4n51zMqcLrr0OfPvDTT3DJJfDii3DMIdugew8YNgzq1IHp0+1hCZevvEXhnIuphQut\ni6lzZyhfHr74AsaOhWOOAQYMgP/7P6vqt3ixJ4kY8UThnIuJX3+Fm2+GpCT47jtrNHzzDZzRYKN9\nAdCrF8yZYzXCDzkktgEXY54onHP5at8+u921fn0rwXTnnZYoOt2klHjnLWjQAK4NivhVrAgnnBDr\nkIs9TxTOuXyzeDGccopVeG3a1G57ffppqLRjHZx/vpXeqFcP3nrLi/gVIJ4onHNR9/vvNlfQCSfA\nDz/AiBHw+efWqmDBAkhIsIHqZ56BGTOsVeEKDL/ryTkXNamp8Oqr8PDD8NtvNibx+ONwxBHAX39B\n6dLQuDF07Aj33APx8bEO2WXCWxTOuaiYNQsSE+3J6oQEey5i6FA4omKa1eKoX9+epitVCp57zpNE\nAeaJwjmXp1JS4I474NRTrctpzBiYNg1atcIGKVq2tNtdExO9iF8h4YnCOZcn9uyxJ6nr1LG7mm6+\nGZYuhcsvB9m3Fx56yO6FTUmB996zEhxexK9Q8DEK59xB+/hjuPtuG6i+5BJ46imoWTNkgxIlrDXR\noYPNOnfEEbEK1eWCtyicc7m2bh2cey5ccIENNXz6qT1VXbMm1u907702FZ0IvP8+DB/uSaIQimqi\nEJG2IrJSRFaJSM9M1tcQkWkislBElojIedGMxzmXN1Th3XehWTMbtB4yxBoMbdoEG0yZYnczDRkC\nn3xiy0qXjlm87uBElChEpLSI1M7JgUUkDngBaAc0BK4WkYYZNnsIeFdVmwHtgRdzcg7nXP5buBBO\nPtnmqz7uOJsWonv3IA9s3Qo33QTnnGPVXWfMgFtvjXXI7iBlmyhE5HxgKTAleN9URMZGcOwWwCpV\nXa2qfwGjgIszbKNAxeDrw4CfIg3cOZe/tm2zchtJSdabNGyYlWGqWzdko8cft6fpHnwQFi2yW59c\noRfJYHY/oCUwDUBVF0XYuqgGrA95nxIcJ9QjwKcicidwKHB2ZgcSkS5AF4AaNWpEcGrnXF5RhVGj\nrNWwaZM1EPr3h0qVgg1+/RU2b4aGDa2IX/v21iflioxIup5SVXVbhmWaR+e/GhiuqtWB84A3ReQf\nManqUFVNUtWkqlWr5tGpnXPZSUmBiy6Ca66B6tVh7lx4/vkgSahaVb8GDaxGU3oRP08SRU4kieIb\nEbkSKCEi8SLyFDA7gv02AMeGvK8eLAvVCXgXQFVnAWWBKhEc2zkXRarw2mvWSPjsMxg40LqZ9hdy\nXbsW2ra10hsNG8Lbb3sRvyIskkRxB3ACsA/4ANgD3B3BfvOAOkFyKY0NVk/IsM064CwAEWmAJYpN\nkYXunIuGzZvhyittIqGmTW0q0vvvh7i4YIP586FRI6vJ8fzz8OWXQXU/V1RFkijOVdUHVLVZ8OqJ\n3ckUlqqmYUnmE+Ab7O6m5SLST0QuCja7F7hZRBYDI4GOqppX3VrOuRz69FO7q3X8eBuXnjYtpATT\nnj32b2KiZZFly6yQUwl/HKuok+w+l0Vkgao2z7BsvqrGZDaRpKQkTU5OjsWpnSuyNm+2MuDDh9uQ\nwzvvWGsCsHpMgwZZRb8FC/yBuUIq+NxOys2+Wd71JCLnAm2BaiIyJGRVRawbyjlXyKna8MJdd8HO\nndCzJ/TuDeXKBRssXGjPRSxaBFdcYdPTuWIn3O2xG4FlwG5gecjyncA/nrJ2zhUumzdDly5Wm+/E\nE63BsL8VkZYGffpYOfCqVa38xmWXxTReFztZJgpVXQgsFJG3VXV3PsbknIuysWOtuuuOHZYL7r03\nw1BDXJyNQVx/PTz5JBx+eMxidbEXyQN31UTkUawMR9n0hapaN+tdnHMF0fffQ7duMHGiDVp/9llI\nK2LnTmtF3HknHH+8tSJKlYppvK5giOR2heHA/wGC3e30LjA6ijE55/LY1q32+d+okZVfGjzYajTt\nTxKffGIrn3nGCvqBJwm3XySJopyqfgKgqj+o6kNEcHuscy72VOGtt6BePXjpJXvCeuVK62oqXRob\nqLjhBnt4rlw5mDkTbrkl1mG7AiaSrqc9QVmNH0SkK/Z0dYXohuWcO1grV1pdpmnTbPbRTz8NaUGk\ne+IJuxe2Vy+bga5s2UyP5Yq3SBJFd6xg313Ao1iV15uiGZRzLvf+/BMGDLCyG+XKwcsv28D1/sHq\nn3+2lkSjRpYcrrnGHqJzLgvZJgpVnRN8uRO4DkBEqkUzKOdc7nz2mZXbWLjQZh198kk46qhgpao9\nUXfPPVCrFsybBxUqeJJw2Qo7RiEiJ4rIJSJSJXifICIjgDnh9nPO5a/t262Aa5s2NnA9ZoyNTexP\nEmvW2GRCN90ETZpYd5MX8XMRyjJRiMgA4G2gAzBZRB7B5qRYDPitsc4VEJ9/bmU33nrLepK++QYu\nvzxkg/QifnPm2Ij2tGkZZhtyLrxwXU8XA4mq+qeIHIFNQtRYVVfnT2jOuXA2bbJyG0OH2uf+e+/B\nKaeEbLB7tw1OJybanUzdu8Oxx2Z5POeyEq7rabeq/gmgqluA7zxJOBd7qvDiizbMMHSo1WmaPz8k\nSaSm2hR09erBli1QsiQMGeJJwuVauBbF8SLyQfC1APEh71FVL/ziXD778Ufo2hUmT7Yhh6eesnmD\n9ktOhk6dYMkSm1TCi/i5PBAuUVye4f3z0QzEOZe19FZEjx52m+uzz8Idd4SMR6elwX//+/dtTmPH\nwiWXxDRmV3SEKwo4NT8Dcc5l7qefrJEwebI9QP3SS1CzZoaN4uLsCbubbrK5IypVikWorojyqamc\nK6BU4c037Yal6dPhhResmN/+JLFjhw1QrFplTYsxY+DVVz1JuDwXyZPZzrl89uuv1jiYOBFOOglG\njIA6dUI2mDjR7mT66SfLJLVrexE/FzURtyhEpEw0A3HO/V3Er2FDez5i8GCr07c/Sfz2G1x7LZx/\nPlSsCF9/bbMPORdF2SYKEWkhIkuB74P3iSLyXNQjc66YSUmBCy+0J6zr1YO5c63Ka1xcyEaDBsHo\n0fDwwzZ/dcuWMYvXFR+RtCieBS4ANgOo6mKgdTSDcq44UYVhwyAhwVoRTz1lc0Y0bhxs8NNPsHSp\nff3QQ5YgHnkEyngj3+WPSBJFCVX9McOyvdEIxrniZs0aq890883QvLnlg27dglZEegZp2BA6drT3\nFSqEZBDn8kckiWK9iLQAVETiRKQb8F2U43KuSNu718YfGjf+uwTT1Kn2tDUAq1fD2WdbBmna1Lqb\nvIifi5FI7nq6Fet+qgH8CnwWLHPO5cLChdZAWLIELrjAbnutUSNkg+RkOP10K73xyivQuXPIZBLO\n5b9IEkWaqraPeiTOFXF//AF9+sDTT0OVKvbYw2WXhTQU/vwTDjnEWhC33WZ9UNWrxzRm5yCyrqd5\nIjJRRG4QkRxNgSoibUVkpYisEpGeWWxzpYisEJHlIvJOTo7vXGExfboVcR0yxFoT6aXARYC//oK+\nfa0E7ObN1pIYPNiThCswsk0UqloL6A+cACwVkXEikm0LQ0TigBeAdkBD4GoRaZhhmzrAg8ApqpoA\ndMv5JThXcO3ZY3ey/vvf1nv0+efw2mtwxBHBBnPnwgkn2F1Mp58ey1Cdy1JEHZ+q+rWq3gU0B3Zg\nExplpwWwSlVXq+pfwChsjotQNwMvqOrW4DwbI47cuQJuzhy7k6lfP3tGbvZsaJ1+Y3laGtx3H7Rq\nZVPSffghvP02VK4c05idy0wkD9yVF5EOIvIhMBfYBJwcwbGrYZMdpUsJloWqC9QVka9EZLaItM0i\nhi4ikiwiyZs2bYrg1M7Fzh9/2LTUrVrBzp1WbeONN0JaEWD3v65aZXc1LV9uo9rOFVCRDGYvAz4E\nnlDVGVE4fx3gTKA68KWINFbVbaEbqepQYChAUlKS5nEMzuWZzz+3z/7Vq+HWW+Hxx63SBmATW/fq\nZYPUtWvbaHZJL7fmCr5IfkuPV9XczH6yAQidUqt6sCxUCjBHVVOBNSLyHZY45uXifM7FzPbtNlfE\nq69aDpg+PcOQw0cf2YxDP/9sdzXVru1JwhUaWXY9iciTwZfvi8gHGV8RHHseUEdE4kWkNNAemJBh\nm3FYawIRqYJ1Rfl0q65Q+fBDe3j6tdfg/vvt+Yj9SWLTJrjmGividMQRNlDRuXNM43Uup8L9STM6\n+DdXM9upapqI3AF8AsQBr6vqchHpBySr6oRg3TkisgIrC9JDVTfn5nzO5beffrJbXadMsSesx4+H\npKQMGw0ebF1MfftCz55QunQsQnXuoIhq+C5/EblDVZ/Pbll+SUpK0uTk5Fic2rn9Ro2y6SBSU60V\n8d//huSAlBTYsgWaNIHff7eJrhMSYhqvcyIyX1Uz/ikTkUhuj70pk2WdcnMy5wq7LVusJ+nqq+2z\nf8kSewSidGlg3z4rudGwIdx4oxXxK1/ek4Qr9LLsehKRq7BxhfgMYxIVgG2Z7+Vc0TV1Ktxwg80+\n98gjdgPT/vHo77+3252mT4ezzoKhQ72Inysywo1RzMXmoKiOPWGdbiewMJpBOVeQ7Nlj00AMHmwT\nCk2YYA/S7ZecDKedZvNDDBtmc5h6knBFSJaJQlXXAGuwarHOFUtLl9qMc4sX24yjTz0F5coFK0OL\n+N11F9x9N/zrXzGN17loCHd77PTg360isiXktVVEtuRfiM7lv/RKryeeaHc3jR9vww/lyvF3Aac6\ndWwO65IlYeBATxKuyArX9ZRelaZKfgTiXEGgCmPH2sPT69fDf/4Dzz0HRx0VbDB7NnTqBCtWWAEn\nnyfCFQNZ/paHPI19LBCnqnuBVsAtwKH5EJtz+eqHH+D88638d6VKNm/1u+8GSSItzQo4nXwy7NgB\nH38Mb76ZoYCTc0VTJH8OjcOmQa0F/B9WYsPnjXBFhqqNPTRqZMlhyBBYsABOPTVko7g4WLvWynAs\nXw7nnRercJ3Ld5EUm9mnqqkichnwnKo+KyJ+15MrEtavt8/+iRPh3HPtrtb905Ju22ZPU997r41H\nvPeeJQzniplIWhRpIvIf4Drgo2BZqeiF5Fz0qVptpkaN4IsvbN7qSZNCksT48fbg3LBh8OWXtsyT\nhCumIn0yuzVWZny1iMQDI6MblnPRs24dtG1rtfmaN7dbYG+7LXj04ddf4aqr4JJL4MgjbfahTl6I\nwBVvkUyFugy4C0gWkfrAelV9NOqROZfHVK1rqVEj+OorePFFe9r6+ONDNhoyBMaNg0cfhXnzbJpS\n54q5bMcoROQ04E1sLgkBjhaR61T1q2gH51xeWbvWWhBTp9r81cOGQXx8sHL9eivilJgIvXtbSdgG\nDWIYrXMFSyRdT08B56nqKap6MnA+8Ex0w3Iu77z1FjRrZg2E55+Hzz4LksS+fdasaNjQupfSi/h5\nknDuAJEkitKquiL9jap+A3hRfVfg/fwzXHaZleCoVw/mz4fbbw/GIr77Ds480xa0amVzRnh9Jucy\nFcntsQtE5GXgreB9B7wooCvA0u9ouu8+K8f04IPQr19Ipdd586yI3yGHwOuvW1eTJwnnshRJouiK\nDWbfH7yfATwXtYicOwhbtthzEe+9Z+PQb79trQnACjgdeqjd6tS9uxXyO+aYmMbrXGEQtutJRBoD\nbYGxqnpR8BqkqrvzJzznIvfxxzap3Nix8NhjdmdrvXrA7t02eUTdulbELy4OBgzwJOFchMJVj/0v\nVr6jAzBFRDKb6c65mFu3Dtq3hwsvhMMOswTx4IPB83Fff20j2Y89Bm3a+ENzzuVCuBZFB6CJqv4H\nOBG4NX9Cci4ye/bY4w7169tkQr172xxCzZtjRfzuvtsKNu3aBZMnw/DhcPjhsQ7buUIn3BjFHlX9\nA0BVN4mI11N2BcaMGXZH6/ffW7XXIUNCym+AtRw2bLC7mh57DCpUiFmszhV24RLF8SFzZQtQK3Tu\nbFW9LKqROZeJP/6w4YZnn7VnISZNsnIcAGzdCg88AD16WBG/0aO9q8m5PBAuUVye4f3z0QzEuexM\nnQo33wxr1lhDYcCAkIbCBx/Ywk2b7LmIOnU8STiXR8LNmT01PwNxLivbt1sj4dVX7fN/+nQ4/fRg\n5S+/wB13wPvv29zVEyfa4LVzLs9EddxBRNqKyEoRWSUiPcNsd7mIqIgkRTMeV/h8/DEkJNgDdD16\nwOLFIUkCbMahjz6ycYi5cz1JOBcFUUsUIhIHvAC0AxoCV4tIw0y2qwDcDcyJViyu8Nm82aakvuAC\nu1Fp9mx44gl7mJq1a2FhUBygTx/LHg8+CKV8mhTnoiHiRCEiZXJ47BbAKlVdrap/AaOAizPZ7n/A\nQMAf4nOkpsJLL1mdvtGj4eGHrUbTiSdiRfyee87qhN98s9XqOPTQkEevnXPRkG2iEJEWIrIU+D54\nnygikZSQcK/pAAAbaUlEQVTwqAasD3mfEiwLPXZz4FhV/TibGLqISLKIJG/atCmCU7vCaPlyOOkk\nm0Sobl17JuKRR6B0aeCbb6w+01132b/vv+/1mZzLJ5G0KJ4FLgA2A6jqYmzGu4MSPJcxBLg3u21V\ndaiqJqlqUtWqVQ/21K6A2bsXBg60B+XWr7c6TV9+adNDADb20LQpfPstjBhhA9bHHRfTmJ0rTiIp\nClhCVX+UA/962xvBfhuAY0PeVw+WpasANAK+CI59NDBBRC5S1eQIju+KgDVrrHjrl19aSfCXXrIZ\nSAH4/XebH+KEE2wk+8474aijYhmuc8VSJC2K9SLSAlARiRORbsB3Eew3D6gjIvEiUhpoD0xIX6mq\n21W1iqrWVNWawGzAk0QxsW8fvPCCNRQWLbJq32PGBEli924bnK5Tx56LiIuD/v09STgXI5G0KG7F\nup9qAL8CnxFB3SdVTRORO4BPgDjgdVVdLiL9gGRVnRD+CK6oWrMGbrzRnodo2RJGjYKaNYOVM2da\nbY7vvoObbvI7mZwrALJNFKq6EWsN5JiqTgQmZljWJ4ttz8zNOVzhoWoth27doEQJGDrU5rEWwYr4\ndetmzYyaNWHKFDj77FiH7JwjgkQhIq8CmnG5qnaJSkSuSPr5Z7j+epuvunVrK+R6QBG/kiXh11+t\n4mv//jY24ZwrECLpevos5OuywKUceNurc2FNmWLzRezeDc8/D7feai0KNm+G+++3V7169uBECS9S\n7FxBE0nX0+jQ9yLyJjAzahG5IuPPP+05iEGD7AG6996DBg2wPqj3xliNpi1b7LmIevU8SThXQEXS\nosgoHvDbT1xYc+ZAhw5WbeP6660lUb481gd1220wbpzd9jplis1f6pwrsCJ5MnuriGwJXtuAKcCD\n0Q/NFUZ//WV3trZqZTPQffihjUfsH3J4+mmbbe6JJ6yAkycJ5wq8sC0KsSfhEvn7Qbl9qvqPgW3n\nwKan7toVli61O1wHD4ZKlbD7YbdutUev+/SxW53q1Il1uM65CIVtUQRJYaKq7g1eniTcP6SmwkMP\n2fTUGzfC2LEwbBhUqrAXnnnGivh16fJ3ET9PEs4VKpGMHi4SES/y7zK1aJEV8nv0UbjhBivHdMkl\nwIoVljm6dYMzzrDs4UX8nCuUsux6EpGSqpoGNAPmicgPwB/Y/Nmqqs3zKUZXAKWlWddSr15QubLd\n0XTFFcHKOXNsdqEKFeCtt+CaazxJOFeIhRujmAs0By7Kp1hcIbF8uZXgmDcPLr8cXnnFkgU7d1py\nSEqCBx6w21/3V/hzzhVW4bqeBEBVf8jslU/xuQIkNdW6mJo3t/Hp0aOtJVH5kF320FxoEb9+/TxJ\nOFdEhGtRVBWRe7JaqapDohCPK6BWrIDrroMFC+DKK+25iKpVscp+nTvDqlU261zp0rEO1TmXx8K1\nKOKA8ti8EZm9XDGgCq+9Zs/GpaTYxHKjR0PVw9OsFseZZ1rN8KlTrcrfYYfFOmTnXB4L16L4WVX7\n5VskrsDZscOeixg5Ev79b5tcrlr6ZLYlS9qzEffcA//7H5QrF9NYnXPRk+0YhSuevv0WmjWzJNG3\nL3z6KVQr85tNR7dypW30zjvw5JOeJJwr4sIlirPyLQpXYOzbB889ByeeaDcxzZgBfXorce+Nsop+\nb79tpTfAi/g5V0xk+T9dVbfkZyAu9tautbmC7rrLHqKbNw9Ojd9gT9BdfTXEx9to9g03xDpU51w+\n8j8JHampVqOvUSOYOxdeftm6mo47DmteTJliT9fNmgWNG8c6XOdcPstNmXFXhGzYYA/NzZkDF1xg\nM5HWSP0BFmyzW51697bbX2vXjnWozrkY8RZFMfb++9C0qT1pPWoUfDhuLzXGDLFWwy23/F3Ez5OE\nc8WaJ4pi6PvvrfVwxRVw9NEwcyZclbAMTj4Z7r3XBirGj/f6TM45wBNFsaIKAwfaWMSXX9qww/z5\nkLh7jtXlWL3a7ocdPz7kgQnnXHHnYxTFxPbtNiXEu+/CpZfCiy/C0eV2QOmKVsSvVy+4/XaoUiXW\noTrnChhvURQDs2bZWMT778Pjj8P7b+7i6MH3WRG/jRutiN/DD3uScM5lKqqJQkTaishKEVklIj0z\nWX+PiKwQkSUiMlVEjotmPMVNaqp9/p92mg03zJgBD7SYhjRpbE9UX3oplC0b6zCdcwVc1BKFiMQB\nLwDtgIbA1SLSMMNmC4EkVW0CjAGeiFY8xc2KFTY23a8fdOgAC+el0Wr4LVa0qUQJmDbNHpioWDHW\noTrnCrhotihaAKtUdbWq/gWMAi4O3UBVp6nqruDtbKB6FOMpFlThzTehZUt70vq99+CNN+CwyiVt\noKJHD1i82Kq+OudcBKKZKKoB60PepwTLstIJmBTFeIq8jRut2sb119ujEEs+28gVE663Cn9gRfye\neMKL+DnncqRA3PUkItcCScAZWazvAnQBqFGjRj5GVnhMmWKFXbdsgScGKvce8w4lzrrbaoW3aQP1\n63sRP+dcrkTzk2MDcGzI++rBsgOIyNlAL+AiVd2T2YFUdaiqJqlqUtWqVaMSbGH1559w221wzjlQ\nqhTMH7eeHl9eSInrr7W7mhYtsqnpnHMul6KZKOYBdUQkXkRKA+2BCaEbiEgz4BUsSWyMYixF0vLl\nVg78pZes4uuyZdBw2gs2UP300/bIdcOM9w8451zORK3rSVXTROQO4BNsWtXXVXW5iPQDklV1AjAI\nm271PbFyEetU9aJoxVRU7N0Lzz4L//2vzTw64/XvObXxdiifBH36WJ2m+PhYh+mcKyJEVWMdQ44k\nJSVpcnJyrMOImVWr4MYbrbFw8flpjGj2FBUH9/m7RrjXZ3LOZUJE5qtqUm729dHNQuS116BJE1i6\nFMb/bwljf21Fxf73w7nnehE/51zUFIi7nlx469bBfffZMxH//jeM7DaHIy87FY44woo3XXGFJwnn\nXNR4oijg3n8fbr4Z9uyBxx/czr39DqOkJNmEQrffDpUrxzpE51wR511PBdTWrXDttdZYSKj5BylX\ndOOBYXUouSUo4tenjycJ51y+8ERRAM2YAQkJMHo0vH7NZ3y5pRGHj3gGrrwSDjkk1uE554oZTxQF\nyN69NrHQWWdBhUPSWH9OJ258pw1SprTNNPT881ChQqzDdM4VM54oCoi1a22gumdPuPBCmJ1ckqMr\n7bYFixZZrXDnnIsBH8yOMVW77fWee6Dqvl/54aR7iP/fQ8jhDeCtt/xuJudczHmLIoZ+/dWqvd58\ns9Kz2pt8V6ohxy8YgyyYbxt4knDOFQDeooiR8eOhc2eotGMdq+t3Jf7bSdCqlTUvGjSIdXjOObef\ntyjy2S+/2Aykl1wCNWrArOtfIn79l1a8acYMTxLOuQLHE0U+Gj3aSjKt+nglr3edy9dfQ5VnelvZ\n1zvvtOcjnHOugPFEkQ+2bbMH565tn0rfQx5nsSRyY/LtlCmtNttczZqxDtE557LkYxRRtmgR/Oc/\nUGnNQtb/qxNHpyyEyy6zZyJ8sNo5Vwh4iyJK9u6Ffv1sYqG6m2cxlxM5eu9PMGaMFXA65phYh+ic\ncxHxRBEFCxdCixYw5OFtXHYZjFjZEunbF1asgMsvj3V4zjmXI54o8lBaGvTvD61P/J3bvr2LXyrU\nYdQzv1K5agno1cvKgjvnXCHjYxR5ZPlyuOkmOGzup3x/aBeq7FqH3HEHlD801qE559xB8RbFQdq7\nF554Alo0S+XuRTfyKedStXpZZMYMezaifPlYh+iccwfFWxQHYdUquP56mDULLrusFJfxFzToBQ89\nBGXLxjo855zLE54ockEVXnoJBt/3C4PSulF6YB8u6NEQwYv4OeeKHk8UObR5M3S8Qan88RssLtmd\n8nF/ItUvAmkIeJJwzhU9nihyIDkZ7r18LQ+t70IbpqAnnYoMGwb16sU6NOdyLDU1lZSUFHbv3h3r\nUFweKlu2LNWrV6dUqVJ5dkxPFBFQhaFD4a674ImSQ2lddhYMfgHp2hVK+P0ArnBKSUmhQoUK1KxZ\nE/Eu0yJBVdm8eTMpKSnEx8fn2XE9UWRj2zbof+23fPnxDs48pwVXD+1NSelqpV+dK8R2797tSaKI\nEREqV67Mpk2b8vS4Uf1zWETaishKEVklIj0zWV9GREYH6+eISM1oxpNTS+an8mr8Yzz6cSJj/3UH\nEz9WjjzuEE8SrsjwJFH0RONnGrVEISJxwAtAO6AhcLWINMywWSdgq6rWBp4CBkYrnpxQhQmPLEBb\ntKDHtl78ftYlVFvwIXEl/T+Vc674iWaLogWwSlVXq+pfwCjg4gzbXAy8EXw9BjhLCsCfOO/cOYvz\n+ragetwv/PbqWCp/NhqOOirWYTlXJI0bNw4R4dtvv92/7IsvvuCCCy44YLuOHTsyZswYwAbie/bs\nSZ06dWjevDmtWrVi0qRJBx3LgAEDqF27NvXq1eOTTz7JdJuOHTsSHx9P06ZNadq0KYsWLQLg7bff\npkmTJjRu3JiTTz6ZxYsX79/npptu4sgjj6RRo0YHHKtHjx7Ur1+fJk2acOmll7Jt2zYA5s6du//4\niYmJjB07FrDuwhYtWpCYmEhCQgIPP/zwQV9zJKKZKKoB60PepwTLMt1GVdOA7UDljAcSkS4ikiwi\nyXnd95aZjza15M26/an00wqqdL4k6udzrjgbOXIkp556KiNHjox4n969e/Pzzz+zbNkyFixYwLhx\n49i5c+dBxbFixQpGjRrF8uXLmTx5Mrfddht79+7NdNtBgwaxaNEiFi1aRNOmTQGIj49n+vTpLF26\nlN69e9OlS5f923fs2JHJkyf/4zht2rRh2bJlLFmyhLp16zJgwAAAGjVqRHJyMosWLWLy5Mnccsst\npKWlUaZMGT7//HMWL168f93s2bMP6rojUSgGs1V1KDAUICkpSaN9vpGjSwD/GFJxrsjq1s3mTslL\nTZvC00+H3+b3339n5syZTJs2jQsvvJC+fftme9xdu3bx6quvsmbNGsqUKQPAUUcdxZVXXnlQ8Y4f\nP5727dtTpkwZ4uPjqV27NnPnzqVVq1YR7X/yySfv//qkk04iJSVl//vTTz+dtWvX/mOfc84554B9\n0ltM5cqV27989+7d+8cdRITyQVmg1NRUUlNT82WcKZotig3AsSHvqwfLMt1GREoChwGboxiTc64A\nGT9+PG3btqVu3bpUrlyZ+fPnZ7vPqlWrqFGjBhUrVsx22+7du+/vwgl9Pf744//YdsOGDRx77N8f\nWdWrV2fDhowfWaZXr140adKE7t27s2fPnn+sf+2112jXrl228YV6/fXXD9hnzpw5JCQk0LhxY15+\n+WVKlrS/6/fu3UvTpk058sgjadOmDS1btszReXIjmi2KeUAdEYnHEkJ74JoM20wAbgBmAVcAn6tq\n1FsMzrkDZfeXf7SMHDmSu+++G4D27dszcuRITjjhhCz/Ss7pX89PPfXUQceY0YABAzj66KP566+/\n6NKlCwMHDqRPnz7710+bNo3XXnuNmTNnRnzMRx99lJIlS9KhQ4f9y1q2bMny5cv55ptvuOGGG2jX\nrh1ly5YlLi6ORYsWsW3bNi699FKWLVv2j7GPvBa1RKGqaSJyB/AJEAe8rqrLRaQfkKyqE4DXgDdF\nZBWwBUsmzrliYMuWLXz++ecsXboUEWHv3r2ICIMGDaJy5cps3br1H9tXqVKF2rVrs27dOnbs2JFt\nq6J79+5MmzbtH8vbt29Pz54Hdi9Xq1aN9ev/HlZNSUmhWrWMw6pwTDA7ZZkyZbjxxhsZPHjw/nVL\nliyhc+fOTJo0icqV/zHcmqnhw4fz0UcfMXXq1EwTYYMGDShfvjzLli0jKSlp//JKlSrRunVrJk+e\nHPVEgaoWqtcJJ5ygzrmDt2LFipie/5VXXtEuXbocsOz000/X6dOn6+7du7VmzZr7Y1y7dq3WqFFD\nt23bpqqqPXr00I4dO+qePXtUVXXjxo367rvvHlQ8y5Yt0yZNmuju3bt19erVGh8fr2lpaf/Y7qef\nflJV1X379undd9+tDzzwgKqq/vjjj1qrVi396quvMj3+mjVrNCEh4YBlkyZN0gYNGujGjRsPWL56\n9WpNTU1VVbv2Y445Rjdt2qQbN27UrVu3qqrqrl279NRTT9UPP/zwH+fK7GeL/YGeq8/dmH/w5/Tl\nicK5vBHrRHHmmWfqpEmTDlj2zDPPaNeuXVVVdebMmdqyZUtNTEzUpKQk/fTTT/dvt2fPHu3Ro4fW\nqlVLExIStEWLFjp58uSDjql///56/PHHa926dXXixIn7l7dr1043bNigqqqtW7fWRo0aaUJCgnbo\n0EF37typqqqdOnXSSpUqaWJioiYmJmroZ1X79u316KOP1pIlS2q1atV02LBhqqpaq1YtrV69+v59\nbrnlFlVVHTFihDZs2FATExO1WbNmOnbsWFVVXbx4sTZt2lQbN26sCQkJ2rdv30yvI68ThWghGxJI\nSkrS5OTkWIfhXKH3zTff0KBBg1iH4aIgs5+tiMxX1aQsdgnLK9o555wLyxOFc865sDxROFeMFbau\nZ5e9aPxMPVE4V0yVLVuWzZs3e7IoQjSYj6Js2bJ5etxCUcLDOZf3qlevTkpKSp7PXeBiK32Gu7zk\nicK5YqpUqVJ5OguaK7q868k551xYniicc86F5YnCOedcWIXuyWwR2QT8mA+nqgL8lg/nyQ9F6Vqg\naF1PUboWKFrXU5SuBaCeqlbIzY6FbjBbVavmx3lEJDm3j7sXNEXpWqBoXU9RuhYoWtdTlK4F7Hpy\nu693PTnnnAvLE4VzzrmwPFFkbWisA8hDRelaoGhdT1G6Fiha11OUrgUO4noK3WC2c865/OUtCuec\nc2F5onDOORdWsU8UItJWRFaKyCoR6ZnJ+jIiMjpYP0dEauZ/lJGJ4FruEZEVIrJERKaKyHGxiDNS\n2V1PyHaXi4iKSIG9lTGSaxGRK4Ofz3IReSe/Y8yJCH7XaojINBFZGPy+nReLOCMhIq+LyEYRWZbF\nehGRZ4NrXSIizfM7xkhFcC0dgmtYKiJfi0hiRAfO7RyqReEFxAE/AMcDpYHFQMMM29wGvBx83R4Y\nHeu4D+JaWgPlgq9vLajXEun1BNtVAL4EZgNJsY77IH42dYCFwOHB+yNjHfdBXs9Q4Nbg64bA2ljH\nHeZ6TgeaA8uyWH8eMAkQ4CRgTqxjPohrOTnkd6xdpNdS3FsULYBVqrpaVf8CRgEXZ9jmYuCN4Osx\nwFkiIvkYY6SyvRZVnaaqu4K3s4G8rUWctyL52QD8DxgI7M7P4HIokmu5GXhBVbcCqOrGfI4xJyK5\nHgUqBl8fBvyUj/HliKp+CWwJs8nFwAg1s4FKInJM/kSXM9ldi6p+nf47Rg4+A4p7oqgGrA95nxIs\ny3QbVU0DtgOV8yW6nInkWkJ1wv5KKqiyvZ6gC+BYVf04PwPLhUh+NnWBuiLylYjMFpG2+RZdzkVy\nPY8A14pICjARuDN/QouKnP7fKiwi/gwodCU83METkWuBJOCMWMeSWyJSAhgCdIxxKHmlJNb9dCb2\nV96XItJYVbfFNKrcuxoYrqpPikgr4E0RaaSq+2IdmAMRaY0lilMj2b64tyg2AMeGvK8eLMt0GxEp\niTWjN+dLdDkTybUgImcDvYCLVHVPPsWWG9ldTwWgEfCFiKzF+o4nFNAB7Uh+NinABFVNVdU1wHdY\n4iiIIrmeTsC7AKo6CyiLFdkrjCL6v1VYiEgTYBhwsapG9FlW3BPFPKCOiMSLSGlssHpChm0mADcE\nX18BfK7BSFABk+21iEgz4BUsSRTkPnDI5npUdbuqVlHVmqpaE+tvvUhVc134LIoi+T0bh7UmEJEq\nWFfU6vwMMgciuZ51wFkAItIASxSFdc7VCcD1wd1PJwHbVfXnWAeVGyJSA/gAuE5Vv4t4x1iP0sf6\nhd3R8B12F0evYFk/7EMH7Bf8PWAVMBc4PtYxH8S1fAb8CiwKXhNiHfPBXE+Gbb+ggN71FOHPRrCu\ntBXAUqB9rGM+yOtpCHyF3RG1CDgn1jGHuZaRwM9AKtay6wR0BbqG/GxeCK51aQH/PcvuWoYBW0M+\nA5IjOa6X8HDOORdWce96cs45lw1PFM4558LyROGccy4sTxTOOefC8kThnHMuLE8UrsARkb0isijk\nVTPMtjWzqpSZw3N+EVRDXRyU0aiXi2N0FZHrg687isi/QtYNE5GGeRznPBFpGsE+3USk3MGe2xVf\nnihcQfSnqjYNea3Np/N2UNVErAjkoJzurKovq+qI4G1H4F8h6zqr6oo8ifLvOF8ksji7AZ4oXK55\nonCFQtBymCEiC4LXyZlskyAic4NWyBIRqRMsvzZk+SsiEpfN6b4Eagf7nhXMqbA0qPVfJlj+uPw9\nt8fgYNkjInKfiFyB1dJ6OzjnIUFLIClodez/cA9aHs/nMs5ZhBSnE5GXRCRZbD6LvsGyu7CENU1E\npgXLzhGRWcH38T0RKZ/NeVwx54nCFUSHhHQ7jQ2WbQTaqGpz4Crg2Uz26wo8o6pNsQ/qlKB8xFXA\nKcHyvUCHbM5/IbBURMoCw4GrVLUxVrjvVhGpDFwKJKhqE6B/6M6qOgZIxv7yb6qqf4asfj/YN91V\nwKhcxtkWK/2RrpeqJgFNgDNEpImqPouV+G6tqq2D8iAPAWcH38tk4J5szuOKOa8e6wqiP4MPy1Cl\ngOeDPvm9WC2kjGYBvUSkOvCBqn4vImcBJwDzxKYROQRLOpl5W0T+BNZiZbHrAWv075o4bwC3A89j\n81+8JiIfAR9FemGquklEVgc1g74H6mOlLm7PYZylgfJA6PfpShHpgv2/PgYro7Ekw74nBcu/Cs5T\nGvu+OZclTxSusOiO1alKxFrC/5ioSFXfEZE5wPnARBG5BavT84aqPhjBOTpoSFFBETkis41UNU1E\nWmBF764A7gD+nYNrGQVcCXwLjFVVFfvUjjhOYD42PvEccJmIxAP3ASeq6lYRGY7VKctIgCmqenUO\n4nXFnHc9ucLiMOBntfkMrsOm4zyAiBwPrA66W8ZjXTBTgStE5MhgmyMk8rnCVwI1RaR28P46YHrQ\np3+Yqk7EElhm8w7vxEqhZ2YsNmva1VjSIKdxqhVp6w2cJCL1sdnk/gC2i8hR2DSXmcUyGzgl/ZpE\n5FARyax15tx+nihcYfEicIOILMa6a/7IZJsrgWUisgibq2JEcKfRQ8CnIrIEmIJ1y2RLVXcDNwLv\nichSYB/wMvah+1FwvJlk3sc/HHg5fTA7w3G3At8Ax6nq3GBZjuMMxj6eBHqo6mJszu1vgXew7qx0\nQ4HJIjJNVTdhd2SNDM4zC/t+Opclrx7rnHMuLG9ROOecC8sThXPOubA8UTjnnAvLE4VzzrmwPFE4\n55wLyxOFc865sDxROOecC+v/AZMI9Gi6snYwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34b1b489d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()    \n",
    "epochs=200 # change to 1500 for better results\n",
    "all_losses = []\n",
    "\n",
    "X_tensor_train= XnumpyToTensor(trainX)\n",
    "Y_tensor_train= YnumpyToTensor(trainY)\n",
    "\n",
    "print(type(X_tensor_train.data), type(Y_tensor_train.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "# From here onwards, we must only use PyTorch Tensors\n",
    "for step in range(epochs):    \n",
    "    out = net(X_tensor_train)                 # input x and predict based on x\n",
    "    cost = loss_func(out, Y_tensor_train)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    cost.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "                   \n",
    "        \n",
    "    if step % 10 == 0:        \n",
    "        loss = cost.data[0]\n",
    "        all_losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "        # Use .cpu() to move the tensor to host memory first.        \n",
    "        prediction = (net(X_tensor_train).data).float() # probabilities         \n",
    "#         prediction = (net(X_tensor).data > 0.5).float() # zero or one\n",
    "#         print (\"Pred:\" + str (prediction)) # Pred:Variable containing: 0 or 1\n",
    "#         pred_y = prediction.data.numpy().squeeze()            \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = Y_tensor_train.cpu().data.numpy()\n",
    "                        \n",
    "        tu = ((pred_y == target_y).mean(),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "        print ('ACC={}, LOG_LOSS={}, ROC_AUC={} '.format(*tu))        \n",
    "                \n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Performance of the deep learning model on the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16686, 21)\n",
      "(16686,)\n",
      "(16686, 21)\n",
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n",
      "(16686, 21)\n",
      "<type 'numpy.ndarray'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "acc=0.0 log_loss=0.692455057552 roc_auc=0.52346018804 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE4VzzrmI/h+/yGB1+Qd/4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34b05d0b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.eval()\n",
    "# Validation data\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "\n",
    "X_tensor_val= XnumpyToTensor(valX)\n",
    "Y_tensor_val= YnumpyToTensor(valY)\n",
    "\n",
    "\n",
    "print(type(X_tensor_val.data), type(Y_tensor_val.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "predicted_val = (net(X_tensor_val).data).float() # probabilities \n",
    "# predicted_val = (net(X_tensor_val).data > 0.5).float() # zero or one\n",
    "pred_y = predicted_val.cpu().numpy()\n",
    "target_y = Y_tensor_val.cpu().data.numpy()                \n",
    "\n",
    "print (type(pred_y))\n",
    "print (type(target_y))\n",
    "\n",
    "tu = (str ((pred_y == target_y).mean()),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "print ('\\n')\n",
    "print ('acc={} log_loss={} roc_auc={} '.format(*tu))\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# print (pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Submission on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45668, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90616.0</td>\n",
       "      <td>0.491230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148473.0</td>\n",
       "      <td>0.490555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72743.0</td>\n",
       "      <td>0.498762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32457.0</td>\n",
       "      <td>0.502975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12608.0</td>\n",
       "      <td>0.492377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  probability\n",
       "0   90616.0     0.491230\n",
       "1  148473.0     0.490555\n",
       "2   72743.0     0.498762\n",
       "3   32457.0     0.502975\n",
       "4   12608.0     0.492377"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testX, df_test_set\n",
    "# df[df.columns.difference(['b'])]\n",
    "# trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "\n",
    "print (df_test_set.shape)\n",
    "columns = ['id', 'probability']\n",
    "df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n",
    "df_pred.id.astype(int)\n",
    "\n",
    "for index, row in df_test_set.iterrows():\n",
    "    rwo_no_id=row.drop('id')    \n",
    "#     print (rwo_no_id.values)    \n",
    "    x_data_np = np.array(rwo_no_id.values, dtype=np.float32)        \n",
    "    if use_cuda:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "                    \n",
    "    X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n",
    "    predicted_val = (net(X_tensor_test).data).float() # probabilities     \n",
    "    p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n",
    "    \n",
    "    df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n",
    "\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create a CSV with the ID's and the coresponding probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/pred_0.692455057552_1505058375.08.csv\n"
     ]
    }
   ],
   "source": [
    "df_pred.id=df_pred.id.astype(int)\n",
    "\n",
    "def savePred(df_pred, loss):\n",
    "#     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n",
    "    csv_path = 'pred/pred_{}_{}.csv'.format(loss, (str(time.time())))\n",
    "    df_pred.to_csv(csv_path, columns=('id', 'probability'), index=None)\n",
    "    print (csv_path)\n",
    "    \n",
    "savePred (df_pred, log_loss(target_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Actual score on Numer.ai - screenshot of the leader board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"../images/numerai-score.jpg\" width=\"35%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
