{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 18  PyTorch NUMER.AI  Binary Classification using BCELoss \n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">\n",
    "\n",
    "\n",
    "### Data\n",
    "- Download from https://numer.ai/leaderboard\n",
    "\n",
    "<img src=\"../images/Numerai.png\" width=\"35%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "__pyTorch VERSION: 0.1.12+4eb448a\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "OS:  linux2\n",
      "Python:  2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "PyTorch:  0.1.12+4eb448a\n",
      "Numpy:  1.13.1\n",
      "2.7.12 (default, Nov 19 2016, 06:48:10) \n",
      "[GCC 5.4.0 20160609]\n",
      "0.0\n",
      "svmem(total=67469099008, available=63067299840, percent=6.5, used=3831234560, free=61351706624, active=4435632128, inactive=1119084544, buffers=270614528, cached=2015543296, shared=37376000)\n",
      "memory GB: 0.213935852051\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "# %%timeit\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import logging\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "\n",
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install psutil\n",
    "import psutil\n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "\n",
    "cpuStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:USE CUDA=True\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "lgr.info(\"USE CUDA=\" + str (use_cuda))\n",
    "\n",
    "# ! watch -n 0.1 'ps f -o user,pgrp,pid,pcpu,pmem,start,time,command -p `lsof -n -w -t /dev/nvidia*`'\n",
    "# sudo apt-get install dstat #install dstat\n",
    "# sudo pip install nvidia-ml-py #install Python NVIDIA Management Library\n",
    "# wget https://raw.githubusercontent.com/datumbox/dstat/master/plugins/dstat_nvidia_gpu.py\n",
    "# sudo mv dstat_nvidia_gpu.py /usr/share/dstat/ #move file to the plugins directory of dstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN params\n",
    "DROPOUT_PROB = 0.75\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.005\n",
    "TEST_RATIO = .11\n",
    "MOMENTUM= 0.9\n",
    "PIN_MEMORY=use_cuda # True IF CUDA\n",
    "\n",
    "# Data params\n",
    "TARGET_VAR= 'target'\n",
    "TOURNAMENT_DATA_CSV = 'numerai_tournament_data.csv'\n",
    "TRAINING_DATA_CSV = 'numerai_training_data.csv'\n",
    "BASE_FOLDER = 'numerai/'\n",
    "\n",
    "\n",
    "# fix seed\n",
    "seed=17*19\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Load a CSV file for Binary classification (numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135682</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.53352</td>\n",
       "      <td>0.64336</td>\n",
       "      <td>0.46577</td>\n",
       "      <td>0.53001</td>\n",
       "      <td>0.55734</td>\n",
       "      <td>0.45773</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51224</td>\n",
       "      <td>0.50484</td>\n",
       "      <td>0.41929</td>\n",
       "      <td>0.50954</td>\n",
       "      <td>0.47383</td>\n",
       "      <td>0.48797</td>\n",
       "      <td>0.38373</td>\n",
       "      <td>0.46233</td>\n",
       "      <td>0.33341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110546</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.54196</td>\n",
       "      <td>0.81576</td>\n",
       "      <td>0.46632</td>\n",
       "      <td>0.62320</td>\n",
       "      <td>0.52427</td>\n",
       "      <td>0.64378</td>\n",
       "      <td>0.55662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52643</td>\n",
       "      <td>0.63809</td>\n",
       "      <td>0.67121</td>\n",
       "      <td>0.49421</td>\n",
       "      <td>0.45291</td>\n",
       "      <td>0.46932</td>\n",
       "      <td>0.54445</td>\n",
       "      <td>0.30997</td>\n",
       "      <td>0.19023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76047</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.49158</td>\n",
       "      <td>0.69131</td>\n",
       "      <td>0.57816</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.43064</td>\n",
       "      <td>0.49986</td>\n",
       "      <td>0.61902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43310</td>\n",
       "      <td>0.72286</td>\n",
       "      <td>0.76257</td>\n",
       "      <td>0.36600</td>\n",
       "      <td>0.55330</td>\n",
       "      <td>0.56566</td>\n",
       "      <td>0.67528</td>\n",
       "      <td>0.34960</td>\n",
       "      <td>0.25721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66098</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.54519</td>\n",
       "      <td>0.42473</td>\n",
       "      <td>0.63472</td>\n",
       "      <td>0.39003</td>\n",
       "      <td>0.37485</td>\n",
       "      <td>0.43810</td>\n",
       "      <td>0.59557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41658</td>\n",
       "      <td>0.63417</td>\n",
       "      <td>0.50189</td>\n",
       "      <td>0.40883</td>\n",
       "      <td>0.58705</td>\n",
       "      <td>0.63785</td>\n",
       "      <td>0.56225</td>\n",
       "      <td>0.55989</td>\n",
       "      <td>0.58642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88227</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.44307</td>\n",
       "      <td>0.74076</td>\n",
       "      <td>0.52210</td>\n",
       "      <td>0.56543</td>\n",
       "      <td>0.51125</td>\n",
       "      <td>0.66457</td>\n",
       "      <td>0.42263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45851</td>\n",
       "      <td>0.58805</td>\n",
       "      <td>0.49860</td>\n",
       "      <td>0.48023</td>\n",
       "      <td>0.52606</td>\n",
       "      <td>0.53253</td>\n",
       "      <td>0.38361</td>\n",
       "      <td>0.43829</td>\n",
       "      <td>0.25014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   era data_type  feature1  feature2  feature3  feature4  feature5  \\\n",
       "0  135682  era1     train   0.53352   0.64336   0.46577   0.53001   0.55734   \n",
       "1  110546  era1     train   0.54196   0.81576   0.46632   0.62320   0.52427   \n",
       "2   76047  era1     train   0.49158   0.69131   0.57816   0.54010   0.43064   \n",
       "3   66098  era1     train   0.54519   0.42473   0.63472   0.39003   0.37485   \n",
       "4   88227  era1     train   0.44307   0.74076   0.52210   0.56543   0.51125   \n",
       "\n",
       "   feature6  feature7   ...    feature13  feature14  feature15  feature16  \\\n",
       "0   0.45773   0.41169   ...      0.51224    0.50484    0.41929    0.50954   \n",
       "1   0.64378   0.55662   ...      0.52643    0.63809    0.67121    0.49421   \n",
       "2   0.49986   0.61902   ...      0.43310    0.72286    0.76257    0.36600   \n",
       "3   0.43810   0.59557   ...      0.41658    0.63417    0.50189    0.40883   \n",
       "4   0.66457   0.42263   ...      0.45851    0.58805    0.49860    0.48023   \n",
       "\n",
       "   feature17  feature18  feature19  feature20  feature21  target  \n",
       "0    0.47383    0.48797    0.38373    0.46233    0.33341       0  \n",
       "1    0.45291    0.46932    0.54445    0.30997    0.19023       0  \n",
       "2    0.55330    0.56566    0.67528    0.34960    0.25721       1  \n",
       "3    0.58705    0.63785    0.56225    0.55989    0.58642       0  \n",
       "4    0.52606    0.53253    0.38361    0.43829    0.25014       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Feature enrichement\n",
    "- This would be usually not required when using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genBasicFeatures(inDF):\n",
    "    print('Generating basic features ...')\n",
    "    df_copy=inDF.copy(deep=True)\n",
    "    magicNumber=21\n",
    "    feature_cols = list(inDF.columns)\n",
    "#     feature_cols = list(inDF.columns[:-1])\n",
    "    # feature_cols=xgb_cols\n",
    "#     target_col = inDF.columns[-1]\n",
    "\n",
    "    inDF['x_mean'] = np.mean(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_median'] = np.median(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_std'] = np.std(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_skew'] = scipy.stats.skew(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_kurt'] = scipy.stats.kurtosis(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_var'] = np.var(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_max'] = np.max(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    inDF['x_min'] = np.min(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "    # http://stackoverflow.com/questions/16236684/apply-pandas-function-to-column-to-create-multiple-new-columns\n",
    "#     inDF=inDF.merge(df_copy.ix[:, 0:magicNumber].apply(lambda row: NumerCommonML.enrichFeatures(row), axis=1),\n",
    "#                     left_index=True, right_index=True)\n",
    "\n",
    "    print (inDF.head(1))\n",
    "    return inDF\n",
    "\n",
    "def addPolyFeatures(inDF, deg=2):\n",
    "    print('Generating poly features ...')\n",
    "    df_copy=inDF.copy(deep=True)\n",
    "    poly=PolynomialFeatures(degree=deg)\n",
    "    p_testX = poly.fit(df_copy)\n",
    "    # AttributeError: 'PolynomialFeatures' object has no attribute 'get_feature_names'\n",
    "    target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(df_copy.columns,p) for p in poly.powers_]]\n",
    "    df_copy = pd.DataFrame(p_testX.transform(df_copy),columns=target_feature_names)\n",
    "        \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Train / Validation / Test Split\n",
    "- Numerai provides a data set that is allready split into train, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train, Validation, Test Split\n",
    "def loadDataSplit():\n",
    "    df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    df_test_valid = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "\n",
    "    answers_1_SINGLE = df_train[TARGET_VAR]\n",
    "    df_train.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    df_train.drop('id', axis=1,inplace=True)\n",
    "    df_train.drop('era', axis=1,inplace=True)\n",
    "    df_train.drop('data_type', axis=1,inplace=True)    \n",
    "    \n",
    "    # Add polynomial features    \n",
    "    df_train=genBasicFeatures(df_train)\n",
    "#     df_train = addPolyFeatures(df_train)\n",
    "\n",
    "    df_train.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=False,  index = False)    \n",
    "    df_train= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=None, dtype=np.float32)    \n",
    "    df_train = pd.concat([df_train, answers_1_SINGLE], axis=1)\n",
    "    feature_cols = list(df_train.columns[:-1])\n",
    "#     print (feature_cols)\n",
    "    target_col = df_train.columns[-1]\n",
    "    trainX, trainY = df_train[feature_cols], df_train[target_col]\n",
    "    \n",
    "    \n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    # Validation set\n",
    "    df_validation_set=df_test_valid.loc[df_test_valid['data_type'] == 'validation'] \n",
    "    df_validation_set=df_validation_set.copy(deep=True)\n",
    "    answers_1_SINGLE_validation = df_validation_set[TARGET_VAR]\n",
    "    df_validation_set.drop(TARGET_VAR, axis=1,inplace=True)    \n",
    "    df_validation_set.drop('id', axis=1,inplace=True)\n",
    "    df_validation_set.drop('era', axis=1,inplace=True)\n",
    "    df_validation_set.drop('data_type', axis=1,inplace=True)\n",
    "    \n",
    "   # Add polynomial features    \n",
    "    df_validation_set=genBasicFeatures(df_validation_set)\n",
    "#     df_validation_set = addPolyFeatures(df_validation_set)\n",
    "    \n",
    "    df_validation_set.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=False,  index = False)    \n",
    "    df_validation_set= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=None, dtype=np.float32)    \n",
    "    df_validation_set = pd.concat([df_validation_set, answers_1_SINGLE_validation], axis=1)\n",
    "    feature_cols = list(df_validation_set.columns[:-1])\n",
    "\n",
    "    target_col = df_validation_set.columns[-1]\n",
    "    valX, valY = df_validation_set[feature_cols], df_validation_set[target_col]\n",
    "                            \n",
    "    # Test set for submission (not labeled)    \n",
    "    df_test_set = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "#     df_test_set=df_test_set.loc[df_test_valid['data_type'] == 'live'] \n",
    "    df_test_set=df_test_set.copy(deep=True)\n",
    "    df_test_set.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    tid_1_SINGLE = df_test_set['id']\n",
    "    df_test_set.drop('id', axis=1,inplace=True)\n",
    "    df_test_set.drop('era', axis=1,inplace=True)\n",
    "    df_test_set.drop('data_type', axis=1,inplace=True)   \n",
    "    \n",
    "    # Add polynomial features    \n",
    "    df_test_set=genBasicFeatures(df_test_set)\n",
    "#     df_test_set = addPolyFeatures(df_test_set)\n",
    "   \n",
    "    \n",
    "    feature_cols = list(df_test_set.columns) # must be run here, we dont want the ID    \n",
    "#     print (feature_cols)\n",
    "    df_test_set = pd.concat([tid_1_SINGLE, df_test_set], axis=1)            \n",
    "    testX = df_test_set[feature_cols].values\n",
    "        \n",
    "    return trainX, trainY, valX, valY, testX, df_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating basic features ...\n",
      "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0   0.53352   0.64336   0.46577   0.53001   0.55734   0.45773   0.41169   \n",
      "\n",
      "   feature8  feature9  feature10   ...     feature20  feature21    x_mean  \\\n",
      "0    0.5207   0.36351    0.72262   ...       0.46233    0.33341  0.495936   \n",
      "\n",
      "   x_median     x_std   x_skew    x_kurt    x_var    x_max    x_min  \n",
      "0   0.50484  0.088713  0.48164  0.453078  0.00787  0.72262  0.33341  \n",
      "\n",
      "[1 rows x 29 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating basic features ...\n",
      "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0   0.33463    0.5162   0.73225    0.3637   0.35314   0.63717   0.51138   \n",
      "\n",
      "   feature8  feature9  feature10   ...     feature20  feature21    x_mean  \\\n",
      "0   0.62956   0.18643    0.60806   ...       0.59448    0.46003  0.492229   \n",
      "\n",
      "   x_median     x_std    x_skew    x_kurt    x_var    x_max    x_min  \n",
      "0   0.51138  0.166973 -0.148699 -1.259785  0.02788  0.73225  0.18643  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "Generating basic features ...\n",
      "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0   0.33463    0.5162   0.73225    0.3637   0.35314   0.63717   0.51138   \n",
      "\n",
      "   feature8  feature9  feature10   ...     feature20  feature21    x_mean  \\\n",
      "0   0.62956   0.18643    0.60806   ...       0.59448    0.46003  0.492229   \n",
      "\n",
      "   x_median     x_std    x_skew    x_kurt    x_var    x_max    x_min  \n",
      "0   0.51138  0.166973 -0.148699 -1.259785  0.02788  0.73225  0.18643  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "(108405, 29)\n",
      "(108405,)\n",
      "(16686, 29)\n",
      "(16686,)\n",
      "(45647, 29)\n",
      "(45647, 30)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "# X, y = loadDataSplit(999)\n",
    "\n",
    "\n",
    "# # Number of features for the input layer\n",
    "N_FEATURES=trainX.shape[1]\n",
    "# print (trainX.head(3))\n",
    "# print (df_test_set.head(3))\n",
    "print (trainX.shape)\n",
    "print (trainY.shape)\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "print (testX.shape)\n",
    "print (df_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create PyTorch GPU tensors from numpy arrays\n",
    "\n",
    "- Note how we transfrom the np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def XnumpyToTensor(x_data_np):\n",
    "    x_data_np = np.array(x_data_np.values, dtype=np.float32)        \n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")    \n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")\n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "    \n",
    "    print(type(X_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))    \n",
    "    return X_tensor\n",
    "\n",
    "\n",
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def YnumpyToTensor(y_data_np):    \n",
    "    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")            \n",
    "    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")        \n",
    "    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n",
    "\n",
    "    print(type(Y_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))    \n",
    "    return Y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The NN model\n",
    "\n",
    "### MLP model\n",
    "- A multilayer perceptron is a logistic regressor where instead of feeding the input to the logistic regression you insert a intermediate layer, called the hidden layer, that has a nonlinear activation function (usually tanh or sigmoid) . One can use many such hidden layers making the architecture deep.\n",
    "\n",
    "- Here we define a simple MLP structure. We map the input feature vector to a higher space (256), then later gradually decrease the dimension, and in the end into a 16-dimension space. Because we are calculating the probability of each genre independently, after the final affine layer we need to implement a sigmoid layer. \n",
    "\n",
    "###  Initial weights selection\n",
    "\n",
    "- There are many ways to select the initial weights to a neural network architecture. A common initialization scheme is random initialization, which sets the biases and weights of all the nodes in each hidden layer randomly.\n",
    "\n",
    "- Before starting the training process, an initial value is assigned to each variable. This is done by pure randomness, using for example a uniform or Gaussian distribution. But if we start with weights that are too small, the signal could decrease so much that it is too small to be useful. On the other side, when the parameters are initialized with high values, the signal can end up to explode while propagating through the network.\n",
    "\n",
    "- In consequence, a good initialization can have a radical effect on how fast the network will learn useful patterns.For this purpose, some best practices have been developed. One famous example used is **Xavier initialization**. Its formulation is based on the number of input and output neurons and uses sampling from a uniform distribution with zero mean and all biases set to zero.\n",
    "\n",
    "- In effect (according to theory) initializing the weights of the network to values that would be closer to the optimal, and therefore require less epochs to train.\n",
    "\n",
    "### References: \n",
    "* **`nninit.xavier_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a uniform distribution.\n",
    "* **`nninit.xavier_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a normal distribution.\n",
    "* **`nninit.kaiming_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.](https://arxiv.org/abs/1502.01852) using a uniform distribution.\n",
    "* **`nninit.kaiming_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (29 -> 1024)\n",
      "  (1): Dropout (p = 0.05)\n",
      "  (2): Tanh ()\n",
      "  (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (4): Linear (1024 -> 128)\n",
      "  (5): Dropout (p = 0.05)\n",
      "  (6): Tanh ()\n",
      "  (7): Linear (128 -> 64)\n",
      "  (8): Dropout (p = 0.05)\n",
      "  (9): LeakyReLU (0.01)\n",
      "  (10): Linear (64 -> 32)\n",
      "  (11): Dropout (p = 0.05)\n",
      "  (12): Tanh ()\n",
      "  (13): Linear (32 -> 16)\n",
      "  (14): Dropout (p = 0.05)\n",
      "  (15): LeakyReLU (0.01)\n",
      "  (16): Linear (16 -> 1)\n",
      "  (17): Sigmoid ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# p is the probability of being dropped in PyTorch\n",
    "# At each layer, DECREASE dropout\n",
    "dropout = torch.nn.Dropout(p=1 - (DROPOUT_PROB +0.20))\n",
    "\n",
    "\n",
    "\n",
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, n_feature, n_hidden, n_output,initKernel='uniform'):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "#         self.out = torch.nn.Linear(n_hidden, n_output)   # output layer        \n",
    "        \n",
    "#         # xavier initializer\n",
    "#         if initKernel == 'uniform':\n",
    "#             nn.init.xavier_uniform(self.hidden.weight, gain=np.sqrt(2.0))\n",
    "#         else:\n",
    "#             nn.init.kaiming_normal(self.hidden.weight)           \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "#         x = self.out(x)\n",
    "#         return F.sigmoid(x)\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output,initKernel='uniform'):\n",
    "        super(Net2, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(n_feature, n_hidden),\n",
    "            dropout,\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            dropout,\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "            dropout,\n",
    "            nn.Sigmoid()\n",
    "        )        \n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "hiddenLayer1Size=1024\n",
    "hiddenLayer2Size=int(hiddenLayer1Size/8)\n",
    "hiddenLayer3Size=int(hiddenLayer1Size/16)\n",
    "hiddenLayer4Size=int(hiddenLayer1Size/32)\n",
    "hiddenLayer5Size=int(hiddenLayer1Size/64)\n",
    "\n",
    "# # Hypothesis using sigmoid\n",
    "linear1=torch.nn.Linear(N_FEATURES, hiddenLayer1Size, bias=True) \n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "\n",
    "linear2=torch.nn.Linear(hiddenLayer1Size, hiddenLayer2Size)\n",
    "torch.nn.init.xavier_uniform(linear2.weight)\n",
    "\n",
    "linear3=torch.nn.Linear(hiddenLayer2Size, hiddenLayer3Size)\n",
    "torch.nn.init.xavier_uniform(linear3.weight)\n",
    "\n",
    "linear4=torch.nn.Linear(hiddenLayer3Size, hiddenLayer4Size)\n",
    "torch.nn.init.xavier_uniform(linear4.weight)\n",
    "\n",
    "linear5=torch.nn.Linear(hiddenLayer4Size, hiddenLayer5Size)\n",
    "torch.nn.init.xavier_uniform(linear5.weight)\n",
    "\n",
    "linear6=torch.nn.Linear(hiddenLayer5Size, 1)\n",
    "torch.nn.init.xavier_uniform(linear6.weight)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "tanh=torch.nn.Tanh()\n",
    "relu=torch.nn.LeakyReLU()\n",
    "\n",
    "net = torch.nn.Sequential(linear1,dropout,tanh,nn.BatchNorm1d(hiddenLayer1Size),\n",
    "                          linear2,dropout,tanh,\n",
    "                          linear3,dropout,relu,\n",
    "                          linear4,dropout,tanh,\n",
    "                          linear5,dropout,relu,\n",
    "                          linear6,sigmoid\n",
    "                          )\n",
    "\n",
    "# net = Net(n_feature=N_FEATURES, n_hidden=1024, n_output=1)   # define the network\n",
    "# net = Net2(n_feature=N_FEATURES, n_hidden=2048, n_output=1)   # define the network\n",
    "\n",
    "lgr.info(net)  # net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Print the full net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (29 -> 1024), weights=((1024L, 29L), (1024L,)), parameters=30720\n",
      "  (1): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (2): Tanh (), weights=(), parameters=0\n",
      "  (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True), weights=((1024L,), (1024L,)), parameters=2048\n",
      "  (4): Linear (1024 -> 128), weights=((128L, 1024L), (128L,)), parameters=131200\n",
      "  (5): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (6): Tanh (), weights=(), parameters=0\n",
      "  (7): Linear (128 -> 64), weights=((64L, 128L), (64L,)), parameters=8256\n",
      "  (8): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (9): LeakyReLU (0.01), weights=(), parameters=0\n",
      "  (10): Linear (64 -> 32), weights=((32L, 64L), (32L,)), parameters=2080\n",
      "  (11): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (12): Tanh (), weights=(), parameters=0\n",
      "  (13): Linear (32 -> 16), weights=((16L, 32L), (16L,)), parameters=528\n",
      "  (14): Dropout (p = 0.05), weights=(), parameters=0\n",
      "  (15): LeakyReLU (0.01), weights=(), parameters=0\n",
      "  (16): Linear (16 -> 1), weights=((1L, 16L), (1L,)), parameters=17\n",
      "  (17): Sigmoid (), weights=(), parameters=0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# See https://stackoverflow.com/questions/42480111/model-summary-in-pytorch/42616812\n",
    "from torch.nn.modules.module import _addindent\n",
    "import torch\n",
    "import numpy as np\n",
    "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
    "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
    "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
    "    for key, module in model._modules.items():\n",
    "        # if it contains layers let call it recursively to get params and weights\n",
    "        if type(module) in [\n",
    "            torch.nn.modules.container.Container,\n",
    "            torch.nn.modules.container.Sequential\n",
    "        ]:\n",
    "            modstr = torch_summarize(module)\n",
    "        else:\n",
    "            modstr = module.__repr__()\n",
    "        modstr = _addindent(modstr, 2)\n",
    "\n",
    "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
    "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
    "\n",
    "        tmpstr += '  (' + key + '): ' + modstr \n",
    "        if show_weights:\n",
    "            tmpstr += ', weights={}'.format(weights)\n",
    "        if show_parameters:\n",
    "            tmpstr +=  ', parameters={}'.format(params)\n",
    "        tmpstr += '\\n'   \n",
    "\n",
    "    tmpstr = tmpstr + ')'\n",
    "    return tmpstr\n",
    "\n",
    "lgr.info(torch_summarize(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Loss and Optimizer\n",
    "\n",
    "###  BCELoss\n",
    "- In addition, we will calculate the binary cross entropy loss (BCELoss). Luckily we have one loss function already present. For details please checkout http://pytorch.org/docs/master/nn.html. \n",
    "\n",
    "- ** NOTE this BCELoss may not be numerical stable, although it's fine during my training process.**\n",
    "\n",
    "### Optimization\n",
    "\n",
    "- if return F.log_softmax(x) then loss = F.nll_loss(output, target) (MNIST)\n",
    "- print(nn.BCEWithLogitsLoss()(o, t)) is equivalent to print(nn.BCELoss()(sigmoid(o), t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "INFO:__main__:<torch.optim.adam.Adam object at 0x7f7e6c176590>\n",
      "INFO:__main__:BCELoss (\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.02)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=5e-4)\n",
    "\n",
    "#L2 regularization can easily be added to the entire model via the optimizer\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-4) #  L2 regularization\n",
    "optimizer = torch.optim.Adagrad(net.parameters(), lr=1e-6, weight_decay=5e-4)\n",
    "# loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted\n",
    "# loss_func = torch.nn.NLLLoss()\n",
    "loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "# http://andersonjo.github.io/artificial-intelligence/2017/01/07/Cost-Functions/\n",
    "# use_cuda=True\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    net.cuda()\n",
    "    loss_func.cuda()\n",
    "#     cudnn.benchmark = True\n",
    "    #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "lgr.info (optimizer)\n",
    "lgr.info (loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Training in batches  + Measuring the performance of the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108405, 29)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(108405, 29)\n",
      "<type 'numpy.ndarray'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(108405, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "0 [ 0.70687878]\n",
      "ACC=0.0, LOG_LOSS=0.773157932199, ROC_AUC=0.507367520723 \n",
      "150 [ 0.69225222]\n",
      "ACC=0.0, LOG_LOSS=0.692301525945, ROC_AUC=0.521555907106 \n",
      "300 [ 0.69222361]\n",
      "ACC=0.0, LOG_LOSS=0.69222101258, ROC_AUC=0.522790421489 \n",
      "450 [ 0.69223088]\n",
      "ACC=0.0, LOG_LOSS=0.692252201464, ROC_AUC=0.521583596234 \n",
      "600 [ 0.69233209]\n",
      "ACC=0.0, LOG_LOSS=0.692281790831, ROC_AUC=0.520880144643 \n",
      "750 [ 0.69230485]\n",
      "ACC=0.0, LOG_LOSS=0.692286232274, ROC_AUC=0.520974018251 \n",
      "900 [ 0.69226182]\n",
      "ACC=0.0, LOG_LOSS=0.692282773273, ROC_AUC=0.521511256951 \n",
      "1050 [ 0.69233322]\n",
      "ACC=0.0, LOG_LOSS=0.692347041851, ROC_AUC=0.51951264279 \n",
      "1200 [ 0.69239569]\n",
      "ACC=0.0, LOG_LOSS=0.69239998742, ROC_AUC=0.520080823497 \n",
      "1350 [ 0.69228059]\n",
      "ACC=0.0, LOG_LOSS=0.692300217429, ROC_AUC=0.520434252749 \n",
      "GPU: 942.443 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns5QDwczMAAeCmZmlHAhmZgbA/wfa/F9T/xMuCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e6c143950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e31694f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()    \n",
    "epochs=1500\n",
    "all_losses = []\n",
    "\n",
    "X_tensor_train= XnumpyToTensor(trainX)\n",
    "Y_tensor_train= YnumpyToTensor(trainY)\n",
    "\n",
    "print(type(X_tensor_train.data), type(Y_tensor_train.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "# From here onwards, we must only use PyTorch Tensors\n",
    "for step in range(epochs):\n",
    "#     net.train()\n",
    "    \n",
    "#     output = F.sigmoid(net(input))\n",
    "#     loss = crit(output, target)\n",
    "    out = net(X_tensor_train)                 # input x and predict based on x\n",
    "    cost = loss_func(out, Y_tensor_train)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    cost.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "                   \n",
    "        \n",
    "    if step % 150 == 0:        \n",
    "        loss = cost.data[0]\n",
    "        all_losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "        # Use .cpu() to move the tensor to host memory first.        \n",
    "#         prediction = torch.max(F.softmax(out), 1)[1]\n",
    "#         _, prediction = torch.max(out, 1)    \n",
    "        prediction = (net(X_tensor_train).data).float() # probabilities \n",
    "        \n",
    "#         prediction = (net(X_tensor).data > 0.5).float() # zero or one\n",
    "#         print (\"Pred:\" + str (prediction)) # Pred:Variable containing: 0 or 1\n",
    "#         pred_y = prediction.data.numpy().squeeze()\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "    \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = Y_tensor_train.cpu().data.numpy()\n",
    "                        \n",
    "        tu = ((pred_y == target_y).mean(),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "        print ('ACC={}, LOG_LOSS={}, ROC_AUC={} '.format(*tu))        \n",
    "                \n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Performance of the deep learning model on the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16686, 29)\n",
      "(16686,)\n",
      "(16686, 29)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(16686, 29)\n",
      "<type 'numpy.ndarray'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(16686, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "acc=0.0 log_loss=0.692493408893 roc_auc=0.522454035428 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyBKFMcaYgCxRGGOMCej/AX93U7SMTgBrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e6c1bad90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.eval()\n",
    "# Validation data\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "\n",
    "X_tensor_val= XnumpyToTensor(valX)\n",
    "Y_tensor_val= YnumpyToTensor(valY)\n",
    "\n",
    "\n",
    "print(type(X_tensor_val.data), type(Y_tensor_val.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "predicted_val = (net(X_tensor_val).data).float() # probabilities \n",
    "# predicted_val = (net(X_tensor_val).data > 0.5).float() # zero or one\n",
    "pred_y = predicted_val.cpu().numpy()\n",
    "target_y = Y_tensor_val.cpu().data.numpy()                \n",
    "\n",
    "print (type(pred_y))\n",
    "print (type(target_y))\n",
    "\n",
    "tu = (str ((pred_y == target_y).mean()),log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "print ('\\n')\n",
    "print ('acc={} log_loss={} roc_auc={} '.format(*tu))\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# print (pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Submission on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45647, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97040.0</td>\n",
       "      <td>0.501994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65399.0</td>\n",
       "      <td>0.481901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147258.0</td>\n",
       "      <td>0.497755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129573.0</td>\n",
       "      <td>0.504502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134978.0</td>\n",
       "      <td>0.519406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  probability\n",
       "0   97040.0     0.501994\n",
       "1   65399.0     0.481901\n",
       "2  147258.0     0.497755\n",
       "3  129573.0     0.504502\n",
       "4  134978.0     0.519406"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testX, df_test_set\n",
    "# df[df.columns.difference(['b'])]\n",
    "# trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "\n",
    "print (df_test_set.shape)\n",
    "columns = ['id', 'probability']\n",
    "df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n",
    "df_pred.id.astype(int)\n",
    "\n",
    "for index, row in df_test_set.iterrows():\n",
    "    rwo_no_id=row.drop('id')    \n",
    "#     print (rwo_no_id.values)    \n",
    "    x_data_np = np.array(rwo_no_id.values, dtype=np.float32)        \n",
    "    if use_cuda:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "                    \n",
    "    X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n",
    "    predicted_val = (net(X_tensor_test).data).float() # probabilities     \n",
    "    p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n",
    "    \n",
    "    df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n",
    "    \n",
    "# p_test =   pd.DataFrame (p_test, columns=['probability'])\n",
    "\n",
    "# # df_pred = df_test_set.append(p_test, ignore_index=True)\n",
    "# df_pred = pd.concat([p_test, df_test_set], axis=0, ignore_index=True)\n",
    "\n",
    "# # # df_pred = pd.DataFrame({\n",
    "# # #     'id': df_test_set['id'],\n",
    "# # #     'probability': p_test[:,1]\n",
    "# # # })\n",
    "\n",
    "df_pred.head(5)\n",
    "\n",
    "# df_test_set = pd.concat([tid_1_SINGLE, df_test_set], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/pred_0.692493408893_1504543207.31.csv\n"
     ]
    }
   ],
   "source": [
    "df_pred.id=df_pred.id.astype(int)\n",
    "\n",
    "def savePred(df_pred, loss):\n",
    "#     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n",
    "    csv_path = 'pred/pred_{}_{}.csv'.format(loss, (str(time.time())))\n",
    "    df_pred.to_csv(csv_path, columns=('id', 'probability'), index=None)\n",
    "    print (csv_path)\n",
    "    \n",
    "savePred (df_pred, log_loss(target_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
