{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.6 (default, Oct 26 2016, 20:30:19) \n",
      "[GCC 4.8.4]\n",
      "__pyTorch VERSION: 0.2.0_1\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 0\n",
      "__Devices\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "import logging\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT ='/root/sharedfolder/jupyter/PyTorch/data/cifar10/'\n",
    "IMG_PATH = DATA_ROOT + '/train/'\n",
    "IMG_EXT = '.png'\n",
    "IMG_DATA_LABELS = DATA_ROOT + '/trainLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "    \n",
    "class GenericImageDataset(Dataset):    \n",
    "\n",
    "    def __init__(self, csv_path, img_path, img_ext, transform=None):\n",
    "        \n",
    "        t = time.time()        \n",
    "        lgr.info('CSV path {}'.format(csv_path))\n",
    "        lgr.info('IMG path {}'.format(img_path))        \n",
    "        \n",
    "        assert img_ext in ['.png']\n",
    "        \n",
    "        tmp_df = pd.read_csv(csv_path, header=None)\n",
    "                                \n",
    "        self.img_path = img_path\n",
    "        self.img_ext = img_ext        \n",
    "\n",
    "        self.X_train = tmp_df[0]                \n",
    "        self.y_train = tmp_df[1]\n",
    "                \n",
    "        lgr.info(\"DF X_train:\\n\" + str (self.X_train))\n",
    "        lgr.info (\"DF y_train:\\n\" + str(self.y_train))\n",
    "        \n",
    "\n",
    "        lgr.info('[*]Dataset loading time {}'.format(time.time() - t))\n",
    "        lgr.info('[*] Data size is {}'.format(len(self)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        lgr.info (\"__getitem__:\" + str(index))\n",
    "        print (self.img_path)\n",
    "        print (self.X_train[index])\n",
    "        print (self.img_ext)\n",
    "        \n",
    "        path=self.img_path + self.X_train[index] + self.img_ext\n",
    "        lgr.info (\" --- get item path:\" + path)\n",
    "        img = Image.open(path)\n",
    "        if self.transform is not None: # TypeError: batch must contain tensors, numbers, or lists; \n",
    "                                     #found <class 'PIL.Image.Image'>\n",
    "            img = self.transform(img)\n",
    "#             print (str (type(img))) # <class 'torch.FloatTensor'>                \n",
    "        label = torch.from_numpy(self.y_train[index])\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        l=len(self.X_train.index)\n",
    "#         lgr.info (\"Lenght:\" +str(l))\n",
    "        return (l)       \n",
    "\n",
    "    @staticmethod        \n",
    "    def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "    @staticmethod    \n",
    "    def flaotTensorToImage(img, mean=0, std=1):\n",
    "        \"\"\"convert a tensor to an image\"\"\"\n",
    "        img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "        img = (img*std+ mean)*255\n",
    "        img = img.astype(np.uint8)    \n",
    "        return img    \n",
    "    \n",
    "    @staticmethod\n",
    "    def toTensor(img):\n",
    "        \"\"\"convert a numpy array of shape HWC to CHW tensor\"\"\"\n",
    "        img = img.transpose((2, 0, 1)).astype(np.float32)\n",
    "        tensor = torch.from_numpy(img).float()\n",
    "        return tensor/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformations = transforms.Compose([transforms.ToTensor()])\n",
    "transformations = transforms.Compose([transforms.Scale(32),transforms.ToTensor()])\n",
    "\n",
    "# transformations = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:CSV path /root/sharedfolder/jupyter/PyTorch/data/cifar10//trainLabels.csv\n",
      "INFO:__main__:IMG path /root/sharedfolder/jupyter/PyTorch/data/cifar10//train/\n",
      "INFO:__main__:DF X_train:\n",
      "0            1\n",
      "1            2\n",
      "2            3\n",
      "3            4\n",
      "4            5\n",
      "5            6\n",
      "6            7\n",
      "7            8\n",
      "8            9\n",
      "9           10\n",
      "10          11\n",
      "11          12\n",
      "12          13\n",
      "13          14\n",
      "14          15\n",
      "15          16\n",
      "16          17\n",
      "17          18\n",
      "18          19\n",
      "19          20\n",
      "20          21\n",
      "21          22\n",
      "22          23\n",
      "23          24\n",
      "24          25\n",
      "25          26\n",
      "26          27\n",
      "27          28\n",
      "28          29\n",
      "29          30\n",
      "         ...  \n",
      "49970    49971\n",
      "49971    49972\n",
      "49972    49973\n",
      "49973    49974\n",
      "49974    49975\n",
      "49975    49976\n",
      "49976    49977\n",
      "49977    49978\n",
      "49978    49979\n",
      "49979    49980\n",
      "49980    49981\n",
      "49981    49982\n",
      "49982    49983\n",
      "49983    49984\n",
      "49984    49985\n",
      "49985    49986\n",
      "49986    49987\n",
      "49987    49988\n",
      "49988    49989\n",
      "49989    49990\n",
      "49990    49991\n",
      "49991    49992\n",
      "49992    49993\n",
      "49993    49994\n",
      "49994    49995\n",
      "49995    49996\n",
      "49996    49997\n",
      "49997    49998\n",
      "49998    49999\n",
      "49999    50000\n",
      "Name: 0, Length: 50000, dtype: int64\n",
      "INFO:__main__:DF y_train:\n",
      "0              frog\n",
      "1             truck\n",
      "2             truck\n",
      "3              deer\n",
      "4        automobile\n",
      "5        automobile\n",
      "6              bird\n",
      "7             horse\n",
      "8              ship\n",
      "9               cat\n",
      "10             deer\n",
      "11            horse\n",
      "12            horse\n",
      "13             bird\n",
      "14            truck\n",
      "15            truck\n",
      "16            truck\n",
      "17              cat\n",
      "18             bird\n",
      "19             frog\n",
      "20             deer\n",
      "21              cat\n",
      "22             frog\n",
      "23             frog\n",
      "24             bird\n",
      "25             frog\n",
      "26              cat\n",
      "27              dog\n",
      "28             deer\n",
      "29         airplane\n",
      "            ...    \n",
      "49970           cat\n",
      "49971         truck\n",
      "49972          bird\n",
      "49973    automobile\n",
      "49974          deer\n",
      "49975           cat\n",
      "49976          ship\n",
      "49977    automobile\n",
      "49978         horse\n",
      "49979           cat\n",
      "49980           dog\n",
      "49981          deer\n",
      "49982           cat\n",
      "49983           cat\n",
      "49984          deer\n",
      "49985          ship\n",
      "49986         horse\n",
      "49987          bird\n",
      "49988           dog\n",
      "49989    automobile\n",
      "49990          deer\n",
      "49991          bird\n",
      "49992      airplane\n",
      "49993    automobile\n",
      "49994      airplane\n",
      "49995          bird\n",
      "49996          frog\n",
      "49997         truck\n",
      "49998    automobile\n",
      "49999    automobile\n",
      "Name: 1, Length: 50000, dtype: object\n",
      "INFO:__main__:[*]Dataset loading time 0.0541999340057\n",
      "INFO:__main__:[*] Data size is 50000\n"
     ]
    }
   ],
   "source": [
    "dset_train = GenericImageDataset(IMG_DATA_LABELS,\n",
    "                                 IMG_PATH,\n",
    "                                 IMG_EXT,transformations)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dset_train, batch_size=4,\n",
    "                                          shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:__getitem__:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/sharedfolder/jupyter/PyTorch/data/cifar10//train/\n",
      "1\n",
      ".png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:__getitem__:4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/sharedfolder/jupyter/PyTorch/data/cifar10//train/\n",
      "5\n",
      ".png\n",
      ".png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:__getitem__:8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/sharedfolder/jupyter/PyTorch/data/cifar10//train/\n",
      "9\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-79-b6ae2be7d4d8>\", line 13, in __getitem__\n    return self.full_ds[i+self.offset]\n  File \"<ipython-input-76-ae1aa27a8347>\", line 37, in __getitem__\n    path=self.img_path + self.X_train[index] + self.img_ext\nTypeError: ufunc 'add' did not contain a loop with signature matching types dtype('S55') dtype('S55') dtype('S55')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-c711d28e1815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# get some random training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# show images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-79-b6ae2be7d4d8>\", line 13, in __getitem__\n    return self.full_ds[i+self.offset]\n  File \"<ipython-input-76-ae1aa27a8347>\", line 37, in __getitem__\n    path=self.img_path + self.X_train[index] + self.img_ext\nTypeError: ufunc 'add' did not contain a loop with signature matching types dtype('S55') dtype('S55') dtype('S55')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
