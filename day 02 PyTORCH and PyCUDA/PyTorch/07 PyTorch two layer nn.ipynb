{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 07 PyTorch two layer nn\n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "('__Python VERSION:', '2.7.12 (default, Nov 19 2016, 06:48:10) \\n[GCC 5.4.0 20160609]')\n",
      "('__pyTorch VERSION:', '0.1.12+4eb448a')\n",
      "__CUDA VERSION\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2016 NVIDIA Corporation\n",
      "Built on Tue_Jan_10_13:22:03_CST_2017\n",
      "Cuda compilation tools, release 8.0, V8.0.61\n",
      "('__CUDNN VERSION:', 5110)\n",
      "('__Number CUDA Devices:', 1L)\n",
      "__Devices\n",
      "('Active CUDA Device: GPU', 0L)\n",
      "('Available devices ', 1L)\n",
      "('Current cuda device ', 0L)\n",
      "<class 'torch.FloatTensor'>\n",
      "\n",
      "1.00000e-36 *\n",
      "  1.6793  0.0000\n",
      "  1.7689  0.0000\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       "[torch.cuda.DoubleTensor of size 3x4 (GPU 0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "# imports\n",
    "import numpy as np                     # numeric python lib\n",
    "import matplotlib.image as mpimg       # reading images to numpy arrays\n",
    "import matplotlib.pyplot as plt        # to plot any graph\n",
    "import matplotlib.patches as mpatches  # to draw a circle at the mean contour\n",
    "import scipy.ndimage as ndi            # to determine shape centrality\n",
    "# matplotlib setup\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plot   # Library to plot\n",
    "import matplotlib.cm as colormap   # Library to plot\n",
    "import PIL\n",
    "from PIL import Image as PILImage\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "x=torch.Tensor(3,2)\n",
    "print (type(x))\n",
    "print (x)\n",
    "torch.from_numpy (np.zeros((3,4))).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Two Layer NN using PyTorch NN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/mkrphys/ipython-tikzmagic\n",
    "# ! pip install git+git://github.com/mkrphys/ipython-tikzmagic.git\n",
    "# ! apt-get install  -qyy imagemagick  pdf2svg ghostscript\n",
    "# sudo apt-get install texlive-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "\n",
    "# %load_ext tikzmagic\n",
    "# %reload_ext tikzmagic\n",
    "# %tikz \\draw (0,0) rectangle (1,3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, cost = 0.285651, acc = 95.48%\n",
      "Epoch 2, cost = 0.114465, acc = 96.28%\n",
      "Epoch 3, cost = 0.081446, acc = 96.02%\n",
      "Epoch 4, cost = 0.063199, acc = 96.85%\n",
      "Epoch 5, cost = 0.049565, acc = 97.37%\n",
      "Epoch 6, cost = 0.043171, acc = 97.38%\n",
      "Epoch 7, cost = 0.037471, acc = 96.79%\n",
      "Epoch 8, cost = 0.032391, acc = 97.54%\n",
      "Epoch 9, cost = 0.027450, acc = 97.15%\n",
      "Epoch 10, cost = 0.030221, acc = 97.77%\n",
      "Epoch 11, cost = 0.025462, acc = 97.47%\n",
      "Epoch 12, cost = 0.025810, acc = 97.93%\n",
      "Epoch 13, cost = 0.021117, acc = 97.48%\n",
      "Epoch 14, cost = 0.020988, acc = 97.67%\n",
      "Epoch 15, cost = 0.020017, acc = 97.58%\n",
      "Epoch 16, cost = 0.020140, acc = 97.80%\n",
      "Epoch 17, cost = 0.018000, acc = 97.85%\n",
      "Epoch 18, cost = 0.018227, acc = 97.76%\n",
      "Epoch 19, cost = 0.018760, acc = 97.51%\n",
      "Epoch 20, cost = 0.018152, acc = 97.92%\n",
      "Epoch 21, cost = 0.014606, acc = 97.89%\n",
      "Epoch 22, cost = 0.016066, acc = 97.71%\n",
      "Epoch 23, cost = 0.014409, acc = 97.86%\n",
      "Epoch 24, cost = 0.016373, acc = 97.41%\n",
      "Epoch 25, cost = 0.015187, acc = 97.51%\n",
      "Epoch 26, cost = 0.014995, acc = 97.81%\n",
      "Epoch 27, cost = 0.012487, acc = 97.87%\n",
      "Epoch 28, cost = 0.017068, acc = 98.02%\n",
      "Epoch 29, cost = 0.012375, acc = 97.84%\n",
      "Epoch 30, cost = 0.012766, acc = 98.13%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "dtype = torch.cuda.FloatTensor \n",
    "\n",
    "from data_util import load_mnist\n",
    "\n",
    "\n",
    "def build_model(input_dim, output_dim):\n",
    "    model = torch.nn.Sequential().cuda()\n",
    "#     model = torch.nn.DataParallel(model, device_ids=[0]).cuda()\n",
    "    model.add_module(\"linear_1\", torch.nn.Linear(input_dim, 512, bias=False))\n",
    "    model.add_module(\"relu_1\", torch.nn.ReLU())\n",
    "    model.add_module(\"dropout_1\", torch.nn.Dropout(0.2))\n",
    "    model.add_module(\"linear_2\", torch.nn.Linear(512, 512, bias=False))\n",
    "    model.add_module(\"relu_2\", torch.nn.ReLU())\n",
    "    model.add_module(\"dropout_2\", torch.nn.Dropout(0.2))\n",
    "    model.add_module(\"linear_3\", torch.nn.Linear(512, output_dim, bias=False))\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model, loss, optimizer, x_val, y_val):\n",
    "    x = Variable(x_val, requires_grad=False)\n",
    "    y = Variable(y_val, requires_grad=False)\n",
    "\n",
    "    # Reset gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward\n",
    "    fx = model.forward(x)\n",
    "    output = loss.forward(fx, y)\n",
    "\n",
    "    # Backward\n",
    "    output.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return output.data[0]\n",
    "\n",
    "\n",
    "def predict(model, x_val):\n",
    "    x = Variable(x_val, requires_grad=False)\n",
    "    output = model.forward(x)\n",
    "    return output.data.numpy().argmax(axis=1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    torch.manual_seed(42)\n",
    "    trX, teX, trY, teY = load_mnist(onehot=False)\n",
    "    trX = torch.from_numpy(trX).float()\n",
    "    teX = torch.from_numpy(teX).float()\n",
    "    trY = torch.from_numpy(trY).long()\n",
    "\n",
    "    n_examples, n_features = trX.size()\n",
    "    n_classes = 10\n",
    "    model = build_model(n_features, n_classes)\n",
    "    loss = torch.nn.CrossEntropyLoss(size_average=True)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    batch_size = 100\n",
    "\n",
    "    for i in range(30):\n",
    "        cost = 0.\n",
    "        num_batches = n_examples // batch_size\n",
    "        for k in range(num_batches):\n",
    "            start, end = k * batch_size, (k + 1) * batch_size\n",
    "            cost += train(model, loss, optimizer, trX[start:end], trY[start:end])\n",
    "        predY = predict(model, teX)\n",
    "        print(\"Epoch %d, cost = %f, acc = %.2f%%\"\n",
    "              % (i + 1, cost / num_batches, 100. * np.mean(predY == teY)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
