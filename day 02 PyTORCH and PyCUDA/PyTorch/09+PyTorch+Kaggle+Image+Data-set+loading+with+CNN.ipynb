{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 09 PyTorch Kaggle Image Data-set loading with CNN\n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">\n",
    "\n",
    "#### References:\n",
    "\n",
    "- http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "- https://www.bountysource.com/issues/44576966-a-tutorial-on-writing-custom-datasets-samplers-and-using-transforms\n",
    "\n",
    "- https://medium.com/towards-data-science/my-first-kaggle-competition-9d56d4773607\n",
    "\n",
    "- https://github.com/sohyongsheng/kaggle-planet-forest\n",
    "\n",
    "- https://github.com/rwightman/pytorch-planet-amazon/blob/master/dataset.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.6 (default, Oct 26 2016, 20:30:19) \n",
      "[GCC 4.8.4]\n",
      "__pyTorch VERSION: 0.2.0_1\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 0\n",
      "__Devices\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "# print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "# print ('Available devices ', torch.cuda.device_count())\n",
    "# print ('Current cuda device ', torch.cuda.current_device())\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "import logging\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# No GPU ... ? \n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "OSError                                   Traceback (most recent call last)\n",
    "<ipython-input-3-64c0769366fe> in <module>()\n",
    "     36 print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "     37 print('__Devices')\n",
    "---> 38 call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "     39 print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "     40 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==0.2.0.post1 from http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from torch==0.2.0.post1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torch==0.2.0.post1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torchvision)\n",
      "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from torchvision)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python2.7/dist-packages (from torchvision)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python2.7/dist-packages (from torchvision)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from torch->torchvision)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from pillow->torchvision)\n"
     ]
    }
   ],
   "source": [
    "# Torch CPU\n",
    "!pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "!pip install torchvision \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CUDA Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Setting up global variables\n",
    "\n",
    "- Root folder\n",
    "- Image folder\n",
    "- Image Label folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT ='/root/data/amz/'\n",
    "IMG_PATH = DATA_ROOT + '/train-jpg/'\n",
    "IMG_EXT = '.jpg'\n",
    "IMG_DATA_LABELS = DATA_ROOT + '/train_v2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Torch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "    \n",
    "class GenericImageDataset(Dataset):    \n",
    "\n",
    "    def __init__(self, csv_path, img_path, img_ext, transform=None):\n",
    "        \n",
    "        t = time.time()        \n",
    "        lgr.info('CSV path {}'.format(csv_path))\n",
    "        lgr.info('IMG path {}'.format(img_path))        \n",
    "        \n",
    "        assert img_ext in ['.jpg']\n",
    "        \n",
    "        tmp_df = pd.read_csv(csv_path, header=None)\n",
    "                        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.img_path = img_path\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "\n",
    "        self.X_train = tmp_df[0]        \n",
    "#         self.X_train = self.X_train.ix[1:]\n",
    "        \n",
    "        self.y_train = self.mlb.fit_transform(tmp_df[1].str.split()).astype(np.float32)         \n",
    "                \n",
    "#         lgr.info(\"DF:\\n\" + str (self.X_train))\n",
    "#         lgr.info (\"self.y_train:\\n\" + str(self.y_train))\n",
    "\n",
    "        lgr.info('[*]Dataset loading time {}'.format(time.time() - t))\n",
    "        lgr.info('[*] Data size is {}'.format(len(self)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         lgr.info (\"__getitem__:\" + str(index))\n",
    "        path=self.img_path + self.X_train[index] + self.img_ext\n",
    "#         lgr.info (\" --- get item path:\" + path)\n",
    "        img = Image.open(path)\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None: # TypeError: batch must contain tensors, numbers, or lists; \n",
    "                                     #found <class 'PIL.Image.Image'>\n",
    "            img = self.transform(img)\n",
    "#             print (str (type(img))) # <class 'torch.FloatTensor'>                \n",
    "        label = torch.from_numpy(self.y_train[index])\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        l=len(self.X_train.index)\n",
    "#         lgr.info (\"Lenght:\" +str(l))\n",
    "        return (l)       \n",
    "\n",
    "    @staticmethod        \n",
    "    def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "    @staticmethod    \n",
    "    def flaotTensorToImage(img, mean=0, std=1):\n",
    "        \"\"\"convert a tensor to an image\"\"\"\n",
    "        img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "        img = (img*std+ mean)*255\n",
    "        img = img.astype(np.uint8)    \n",
    "        return img    \n",
    "    \n",
    "    @staticmethod\n",
    "    def toTensor(img):\n",
    "        \"\"\"convert a numpy array of shape HWC to CHW tensor\"\"\"\n",
    "        img = img.transpose((2, 0, 1)).astype(np.float32)\n",
    "        tensor = torch.from_numpy(img).float()\n",
    "        return tensor/255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Torch transforms.ToTensor() methood\n",
    "\n",
    "- Converts: a PIL.Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformations = transforms.Compose([transforms.ToTensor()])\n",
    "transformations = transforms.Compose([transforms.Scale(32),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Torch DataLoader Class\n",
    "\n",
    "- Will load our GenericImageDataset\n",
    "- Can be regarded as a list (or iterator, technically). \n",
    "- Each time it is invoked will provide a minibatch of (img, label) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:CSV path /root/data/amz//train_v2.csv\n",
      "INFO:__main__:IMG path /root/data/amz//train-jpg/\n",
      "INFO:__main__:[*]Dataset loading time 0.19496512413\n",
      "INFO:__main__:[*] Data size is 40479\n"
     ]
    }
   ],
   "source": [
    "dset_train = GenericImageDataset(IMG_DATA_LABELS,\n",
    "                                 IMG_PATH,\n",
    "                                 IMG_EXT,transformations)\n",
    "\n",
    "train_loader = DataLoader(dset_train,\n",
    "                          batch_size=64,\n",
    "                          shuffle=False,\n",
    "                          num_workers=1 # 1 for CUDA\n",
    "                         # pin_memory=True # CUDA only\n",
    "                         )\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# for i, data in enumerate(train_loader, 0):\n",
    "#             lgr.info('i=%d: '%(i))            \n",
    "#             images, labels = data\n",
    "            \n",
    "#             num = len(images)\n",
    "#             for n in range(num):\n",
    "#                 image=images[n]\n",
    "#                 label=labels[n]\n",
    "# #                 lgr.info(\"Label:\" + str(label))\n",
    "#                 plt.imshow (GenericImageDataset.flaotTensorToImage(image))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The NN model\n",
    "\n",
    "- We will use a simple CNN with conv(3x3) -> bn -> relu -> pool(4x4) -> fc.\n",
    "\n",
    "- In PyTorch, a model is defined by a subclass of nn.Module. It has two methods:\n",
    "\n",
    "- `__init__: constructor. Create layers here. Note that we don't define the connections between layers in this function.`\n",
    "\n",
    "\n",
    "- `forward(x): forward function. Receives an input variable x. Returns a output variable. Note that we actually connect the layers here dynamically.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model Net (\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d (p=0.5)\n",
      "  (fc1): Linear (2304 -> 256)\n",
      "  (fc2): Linear (256 -> 17)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning/code/notebook\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(2304, 256)\n",
    "        self.fc2 = nn.Linear(256, 17)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "model = Net() # On CPU\n",
    "# model = Net().cuda() # On GPU\n",
    "\n",
    "lgr.info('Model {}'.format(model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Visualize the NN graph\n",
    "\n",
    "- taken from https://github.com/szagoruyko/functional-zoo/blob/master/resnet-18-export.ipynb\n",
    "- https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/04-utils/tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# ! pip install hickle\n",
    "import hickle as hkl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from visualize import make_dot\n",
    "\n",
    "# Save the model\n",
    "# see also https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/3\n",
    "# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/04-utils/tensorboard/main.py#L83-L105\n",
    "torch.save(model.state_dict(), 'mdl.pt')\n",
    "# .. to load your previously training model:\n",
    "model.load_state_dict(torch.load('mdl.pt'))\n",
    "\n",
    "# params = hkl.load('mdl.pt')\n",
    "# # convert numpy arrays to torch Variables\n",
    "# for k,v in sorted(params.items()):\n",
    "#     print (k, v.shape)\n",
    "#     params[k] = Variable(torch.from_numpy(v), requires_grad=True)\n",
    "    \n",
    "# print ('\\nTotal parameters:', sum(v.numel() for v in params.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Loss and Optimizer\n",
    "\n",
    "- Select a loss function and the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Optimizer <torch.optim.sgd.SGD object at 0x7f13d055b490>\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "lgr.info('Optimizer {}'.format(optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Start training in Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # data, target = data.cuda(async=True), target.cuda(async=True) # On GPU\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            lgr.info('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.697851\n",
      "INFO:__main__:Train Epoch: 1 [6400/40479 (16%)]\tLoss: 0.537523\n",
      "INFO:__main__:Train Epoch: 1 [12800/40479 (32%)]\tLoss: 0.265035\n",
      "INFO:__main__:Train Epoch: 1 [19200/40479 (47%)]\tLoss: 0.294723\n",
      "INFO:__main__:Train Epoch: 1 [25600/40479 (63%)]\tLoss: 0.320152\n",
      "INFO:__main__:Train Epoch: 1 [32000/40479 (79%)]\tLoss: 0.272814\n",
      "INFO:__main__:Train Epoch: 1 [38400/40479 (95%)]\tLoss: 0.275925\n",
      "INFO:__main__:Train Epoch: 2 [0/40479 (0%)]\tLoss: 0.286751\n",
      "INFO:__main__:Train Epoch: 2 [6400/40479 (16%)]\tLoss: 0.279433\n",
      "INFO:__main__:Train Epoch: 2 [12800/40479 (32%)]\tLoss: 0.219592\n",
      "INFO:__main__:Train Epoch: 2 [19200/40479 (47%)]\tLoss: 0.258705\n",
      "INFO:__main__:Train Epoch: 2 [25600/40479 (63%)]\tLoss: 0.265714\n",
      "INFO:__main__:Train Epoch: 2 [32000/40479 (79%)]\tLoss: 0.243284\n",
      "INFO:__main__:Train Epoch: 2 [38400/40479 (95%)]\tLoss: 0.256228\n",
      "INFO:__main__:Train Epoch: 3 [0/40479 (0%)]\tLoss: 0.271307\n",
      "INFO:__main__:Train Epoch: 3 [6400/40479 (16%)]\tLoss: 0.247757\n",
      "INFO:__main__:Train Epoch: 3 [12800/40479 (32%)]\tLoss: 0.197557\n",
      "INFO:__main__:Train Epoch: 3 [19200/40479 (47%)]\tLoss: 0.259584\n",
      "INFO:__main__:Train Epoch: 3 [25600/40479 (63%)]\tLoss: 0.256486\n",
      "INFO:__main__:Train Epoch: 3 [32000/40479 (79%)]\tLoss: 0.231359\n",
      "INFO:__main__:Train Epoch: 3 [38400/40479 (95%)]\tLoss: 0.250553\n",
      "INFO:__main__:Train Epoch: 4 [0/40479 (0%)]\tLoss: 0.257810\n",
      "INFO:__main__:Train Epoch: 4 [6400/40479 (16%)]\tLoss: 0.248458\n",
      "INFO:__main__:Train Epoch: 4 [12800/40479 (32%)]\tLoss: 0.197114\n",
      "INFO:__main__:Train Epoch: 4 [19200/40479 (47%)]\tLoss: 0.253158\n",
      "INFO:__main__:Train Epoch: 4 [25600/40479 (63%)]\tLoss: 0.255004\n",
      "INFO:__main__:Train Epoch: 4 [32000/40479 (79%)]\tLoss: 0.233641\n",
      "INFO:__main__:Train Epoch: 4 [38400/40479 (95%)]\tLoss: 0.241374\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model OrderedDict([('conv1.weight', \n",
      "(0 ,0 ,.,.) = \n",
      "  0.1203 -0.1799  0.1263\n",
      " -0.0594 -0.1837  0.0304\n",
      "  0.1167 -0.0552  0.1911\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  0.1834 -0.1647 -0.1456\n",
      "  0.1770 -0.0816 -0.0827\n",
      "  0.0242  0.1543 -0.0943\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "  0.0765  0.0228  0.1851\n",
      "  0.1864  0.0114 -0.1208\n",
      " -0.1879 -0.0851 -0.0214\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -0.1876 -0.1693  0.1804\n",
      "  0.0765  0.0815  0.0106\n",
      " -0.0084  0.1106 -0.1373\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      " -0.1007  0.0662  0.0354\n",
      " -0.1569 -0.0217 -0.1812\n",
      " -0.0156 -0.1245 -0.1256\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      "  0.0283 -0.1882 -0.0793\n",
      " -0.0244 -0.0315  0.1868\n",
      " -0.0452 -0.0585 -0.1608\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -0.1915 -0.0085 -0.0939\n",
      "  0.0535  0.1117 -0.1404\n",
      " -0.1516 -0.0378  0.1492\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      "  0.0414  0.0267  0.1004\n",
      "  0.0865 -0.0468 -0.1029\n",
      "  0.1253 -0.0368 -0.1478\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "  0.0354 -0.0267 -0.0224\n",
      "  0.0537 -0.1790  0.1007\n",
      " -0.1253  0.0084 -0.1820\n",
      "\n",
      "(3 ,0 ,.,.) = \n",
      " -0.0894  0.1288 -0.1575\n",
      " -0.1075 -0.0338 -0.0942\n",
      "  0.1351 -0.0661  0.0607\n",
      "\n",
      "(3 ,1 ,.,.) = \n",
      " -0.0205 -0.1162  0.0202\n",
      " -0.0473  0.1747 -0.0267\n",
      " -0.0188 -0.0361 -0.1253\n",
      "\n",
      "(3 ,2 ,.,.) = \n",
      "  0.0239 -0.0061  0.1379\n",
      "  0.1064 -0.0230 -0.1613\n",
      " -0.1508  0.0022 -0.1740\n",
      "\n",
      "(4 ,0 ,.,.) = \n",
      " -0.1813  0.1448 -0.0026\n",
      " -0.1409  0.0381  0.0700\n",
      "  0.1372 -0.0619 -0.0534\n",
      "\n",
      "(4 ,1 ,.,.) = \n",
      " -0.1045 -0.0607 -0.0171\n",
      "  0.0989 -0.1385 -0.1433\n",
      " -0.1762 -0.1152  0.0849\n",
      "\n",
      "(4 ,2 ,.,.) = \n",
      " -0.1341 -0.1589  0.0406\n",
      "  0.1179  0.0907  0.0217\n",
      "  0.0105  0.1344 -0.1570\n",
      "\n",
      "(5 ,0 ,.,.) = \n",
      "  0.1330  0.0727 -0.0723\n",
      " -0.0207 -0.0329 -0.1814\n",
      "  0.0842  0.0601  0.0758\n",
      "\n",
      "(5 ,1 ,.,.) = \n",
      "  0.1353  0.1707 -0.0677\n",
      " -0.0095  0.1779 -0.1758\n",
      "  0.0060 -0.1838 -0.0662\n",
      "\n",
      "(5 ,2 ,.,.) = \n",
      " -0.0805  0.1609 -0.0605\n",
      " -0.0162  0.0421 -0.0466\n",
      " -0.1903 -0.1220  0.0448\n",
      "\n",
      "(6 ,0 ,.,.) = \n",
      " -0.1459  0.1386  0.0601\n",
      " -0.0363 -0.1734 -0.0478\n",
      " -0.1627  0.0688 -0.1079\n",
      "\n",
      "(6 ,1 ,.,.) = \n",
      " -0.1165  0.0934  0.1456\n",
      " -0.1453  0.0218 -0.0038\n",
      "  0.0414 -0.1445 -0.0885\n",
      "\n",
      "(6 ,2 ,.,.) = \n",
      "  0.1369  0.0967  0.0427\n",
      "  0.0100  0.0668 -0.1324\n",
      " -0.0143  0.0394  0.1081\n",
      "\n",
      "(7 ,0 ,.,.) = \n",
      "  0.1105 -0.1375  0.0910\n",
      "  0.1311 -0.0956 -0.1746\n",
      " -0.1467  0.1383 -0.1460\n",
      "\n",
      "(7 ,1 ,.,.) = \n",
      "  0.1354  0.1818  0.1655\n",
      " -0.1717 -0.0942 -0.0477\n",
      " -0.0593 -0.1683  0.1478\n",
      "\n",
      "(7 ,2 ,.,.) = \n",
      " -0.0330  0.0282 -0.1373\n",
      " -0.0733 -0.0334  0.0393\n",
      "  0.0898  0.1868  0.0501\n",
      "\n",
      "(8 ,0 ,.,.) = \n",
      " -0.0923  0.0235 -0.1641\n",
      " -0.1174 -0.0453  0.0558\n",
      "  0.1067  0.1220 -0.0219\n",
      "\n",
      "(8 ,1 ,.,.) = \n",
      " -0.0701  0.1880  0.1648\n",
      "  0.1136  0.0150  0.1043\n",
      " -0.1038 -0.0554  0.0823\n",
      "\n",
      "(8 ,2 ,.,.) = \n",
      "  0.1134  0.0813  0.1241\n",
      "  0.0582 -0.1698 -0.0375\n",
      "  0.0567  0.1749  0.0495\n",
      "\n",
      "(9 ,0 ,.,.) = \n",
      " -0.2093 -0.1292 -0.0406\n",
      "  0.0381 -0.0244 -0.1946\n",
      "  0.0791  0.0899  0.1344\n",
      "\n",
      "(9 ,1 ,.,.) = \n",
      " -0.1681 -0.1332 -0.0108\n",
      "  0.1455  0.1382  0.0575\n",
      " -0.0091  0.1583 -0.1998\n",
      "\n",
      "(9 ,2 ,.,.) = \n",
      "  0.0773  0.0046 -0.1551\n",
      " -0.0027 -0.1315 -0.0400\n",
      " -0.1257  0.0425 -0.1324\n",
      "\n",
      "(10,0 ,.,.) = \n",
      "  0.1031 -0.1462  0.0760\n",
      "  0.0062  0.1447 -0.1687\n",
      " -0.0458 -0.0107  0.0161\n",
      "\n",
      "(10,1 ,.,.) = \n",
      "  0.0527 -0.1025  0.1336\n",
      "  0.0775 -0.1499  0.1598\n",
      " -0.1699 -0.1273  0.0067\n",
      "\n",
      "(10,2 ,.,.) = \n",
      " -0.1411 -0.1735 -0.0126\n",
      " -0.1316 -0.1354 -0.1106\n",
      " -0.0143  0.0396  0.1764\n",
      "\n",
      "(11,0 ,.,.) = \n",
      "  0.1572 -0.1543 -0.0235\n",
      " -0.1712  0.0679 -0.0951\n",
      "  0.1243 -0.0714 -0.1183\n",
      "\n",
      "(11,1 ,.,.) = \n",
      "  0.1189  0.0771  0.1940\n",
      "  0.1362 -0.1537 -0.1108\n",
      "  0.0108 -0.0602  0.1645\n",
      "\n",
      "(11,2 ,.,.) = \n",
      " -0.0478  0.0666 -0.1182\n",
      " -0.1888  0.1499 -0.0594\n",
      "  0.0933  0.1345  0.0505\n",
      "\n",
      "(12,0 ,.,.) = \n",
      " -0.0662  0.1524  0.1444\n",
      "  0.1687  0.0020  0.0095\n",
      "  0.0627  0.0564  0.0163\n",
      "\n",
      "(12,1 ,.,.) = \n",
      "  0.0969  0.1477 -0.0596\n",
      "  0.1633  0.1955  0.1577\n",
      " -0.1315 -0.0355 -0.0263\n",
      "\n",
      "(12,2 ,.,.) = \n",
      " -0.0167  0.1111 -0.1348\n",
      " -0.0464  0.0802 -0.0148\n",
      "  0.1171 -0.0586  0.1127\n",
      "\n",
      "(13,0 ,.,.) = \n",
      " -0.1836  0.0557 -0.0838\n",
      " -0.1731  0.1044  0.1171\n",
      "  0.1103 -0.1785  0.0323\n",
      "\n",
      "(13,1 ,.,.) = \n",
      "  0.0587 -0.1109  0.0620\n",
      " -0.1107 -0.1195 -0.1712\n",
      " -0.1128  0.1865  0.0005\n",
      "\n",
      "(13,2 ,.,.) = \n",
      " -0.1500 -0.1595 -0.0215\n",
      " -0.0096 -0.1089 -0.1697\n",
      "  0.0315 -0.1635 -0.1047\n",
      "\n",
      "(14,0 ,.,.) = \n",
      "  0.0161 -0.0368 -0.2000\n",
      " -0.1240 -0.0009 -0.0154\n",
      " -0.1261 -0.0387  0.1269\n",
      "\n",
      "(14,1 ,.,.) = \n",
      "  0.0815  0.0403  0.0160\n",
      "  0.1811  0.0210  0.0598\n",
      " -0.0857  0.1272  0.1055\n",
      "\n",
      "(14,2 ,.,.) = \n",
      " -0.0252  0.0108  0.0052\n",
      "  0.0504 -0.0419  0.1165\n",
      "  0.0664  0.0631  0.0804\n",
      "\n",
      "(15,0 ,.,.) = \n",
      "  0.0636 -0.1579  0.0175\n",
      " -0.1799  0.0743  0.0409\n",
      " -0.0738 -0.1747 -0.1489\n",
      "\n",
      "(15,1 ,.,.) = \n",
      " -0.0536 -0.1903  0.1241\n",
      "  0.1549 -0.0225 -0.0582\n",
      "  0.1432 -0.0216 -0.0710\n",
      "\n",
      "(15,2 ,.,.) = \n",
      "  0.1549  0.0986 -0.1972\n",
      "  0.0870  0.0746 -0.0009\n",
      "  0.0886  0.0325  0.0796\n",
      "\n",
      "(16,0 ,.,.) = \n",
      "  0.0199  0.1284 -0.1404\n",
      " -0.1699 -0.1009  0.1387\n",
      "  0.1788  0.0011  0.1191\n",
      "\n",
      "(16,1 ,.,.) = \n",
      " -0.1608 -0.1050 -0.0277\n",
      " -0.0629 -0.0618 -0.1223\n",
      " -0.0725 -0.0775 -0.0416\n",
      "\n",
      "(16,2 ,.,.) = \n",
      "  0.0225  0.0385 -0.1774\n",
      " -0.1488 -0.0843 -0.0952\n",
      " -0.1576  0.1006 -0.1607\n",
      "\n",
      "(17,0 ,.,.) = \n",
      "  0.0704 -0.0140  0.0840\n",
      "  0.1356 -0.1855  0.0520\n",
      " -0.0155 -0.1253  0.0139\n",
      "\n",
      "(17,1 ,.,.) = \n",
      "  0.1721  0.1089  0.0176\n",
      " -0.1472  0.0432 -0.1180\n",
      "  0.0007  0.0751  0.0615\n",
      "\n",
      "(17,2 ,.,.) = \n",
      " -0.1255 -0.1787 -0.0641\n",
      " -0.0259  0.0646  0.0161\n",
      " -0.0477 -0.0370 -0.0048\n",
      "\n",
      "(18,0 ,.,.) = \n",
      " -0.0333 -0.1592 -0.1030\n",
      "  0.2106 -0.1020  0.0095\n",
      "  0.2037 -0.0261  0.0277\n",
      "\n",
      "(18,1 ,.,.) = \n",
      "  0.0586  0.0467  0.0472\n",
      "  0.1309 -0.0463  0.0561\n",
      "  0.1125  0.1571  0.1330\n",
      "\n",
      "(18,2 ,.,.) = \n",
      "  0.0425  0.1935  0.1841\n",
      "  0.0250  0.1616  0.2023\n",
      "  0.2040  0.0599 -0.1779\n",
      "\n",
      "(19,0 ,.,.) = \n",
      "  0.0544  0.1407 -0.1313\n",
      " -0.0692 -0.1288 -0.0776\n",
      "  0.0443 -0.0257  0.1553\n",
      "\n",
      "(19,1 ,.,.) = \n",
      "  0.1101 -0.0175 -0.0396\n",
      " -0.1711  0.1746 -0.1287\n",
      "  0.0819 -0.0542  0.1062\n",
      "\n",
      "(19,2 ,.,.) = \n",
      " -0.0977  0.0162 -0.1414\n",
      " -0.0208  0.0657  0.1112\n",
      " -0.1776 -0.1060 -0.1740\n",
      "\n",
      "(20,0 ,.,.) = \n",
      "  0.0944  0.1428  0.0163\n",
      "  0.0116  0.1274  0.0844\n",
      " -0.0569  0.0923 -0.0680\n",
      "\n",
      "(20,1 ,.,.) = \n",
      "  0.1915 -0.1365  0.1747\n",
      " -0.0172 -0.0852  0.1731\n",
      " -0.0884  0.0370 -0.0648\n",
      "\n",
      "(20,2 ,.,.) = \n",
      " -0.1719 -0.1814 -0.1772\n",
      "  0.0791 -0.0820  0.1792\n",
      " -0.0826 -0.0608 -0.0228\n",
      "\n",
      "(21,0 ,.,.) = \n",
      "  0.1066  0.1187 -0.0161\n",
      " -0.1764 -0.1002 -0.1309\n",
      " -0.1230 -0.0066 -0.0902\n",
      "\n",
      "(21,1 ,.,.) = \n",
      " -0.0441  0.1137 -0.1884\n",
      " -0.0875 -0.0515  0.0646\n",
      " -0.1095 -0.0363  0.1640\n",
      "\n",
      "(21,2 ,.,.) = \n",
      " -0.1524  0.1678 -0.1749\n",
      " -0.0371 -0.0736  0.0526\n",
      " -0.0050 -0.0440  0.1596\n",
      "\n",
      "(22,0 ,.,.) = \n",
      "  0.2106  0.0377 -0.1389\n",
      "  0.1713  0.0859  0.1526\n",
      "  0.1326 -0.0542 -0.0178\n",
      "\n",
      "(22,1 ,.,.) = \n",
      "  0.1846 -0.1674  0.1836\n",
      " -0.1043 -0.1392  0.1509\n",
      "  0.1047 -0.0504  0.1450\n",
      "\n",
      "(22,2 ,.,.) = \n",
      "  0.0890  0.0256  0.1530\n",
      "  0.1970 -0.0967  0.1229\n",
      "  0.0724 -0.1635 -0.0058\n",
      "\n",
      "(23,0 ,.,.) = \n",
      "  0.0306 -0.0030 -0.0023\n",
      "  0.1568 -0.0350  0.0007\n",
      " -0.1082  0.1323  0.0755\n",
      "\n",
      "(23,1 ,.,.) = \n",
      " -0.0182 -0.0726  0.1873\n",
      "  0.1040 -0.0378  0.0296\n",
      "  0.1149  0.0842  0.0625\n",
      "\n",
      "(23,2 ,.,.) = \n",
      "  0.0172 -0.0121  0.1954\n",
      " -0.0551  0.0950 -0.0752\n",
      " -0.0563  0.0083  0.1605\n",
      "\n",
      "(24,0 ,.,.) = \n",
      "  0.1898 -0.0259 -0.0458\n",
      "  0.0233  0.0368 -0.1923\n",
      " -0.0040 -0.0229  0.1256\n",
      "\n",
      "(24,1 ,.,.) = \n",
      " -0.0466  0.0247 -0.1510\n",
      "  0.0470  0.1903  0.1734\n",
      " -0.0428 -0.1310 -0.0100\n",
      "\n",
      "(24,2 ,.,.) = \n",
      " -0.0853 -0.0248  0.0487\n",
      "  0.0796 -0.0281 -0.1775\n",
      " -0.1467 -0.0753  0.1530\n",
      "\n",
      "(25,0 ,.,.) = \n",
      "  0.1049  0.0815 -0.0728\n",
      "  0.0800  0.1001  0.1316\n",
      "  0.0992  0.0185 -0.2198\n",
      "\n",
      "(25,1 ,.,.) = \n",
      " -0.0203  0.0183 -0.1026\n",
      "  0.1322  0.0497 -0.0285\n",
      " -0.1447 -0.1626  0.1263\n",
      "\n",
      "(25,2 ,.,.) = \n",
      "  0.0107 -0.1229  0.0387\n",
      " -0.1063 -0.0768  0.0126\n",
      " -0.1533  0.1156 -0.1854\n",
      "\n",
      "(26,0 ,.,.) = \n",
      "  0.0890  0.1165 -0.0607\n",
      " -0.1985 -0.2250  0.0509\n",
      "  0.0476  0.0712  0.1333\n",
      "\n",
      "(26,1 ,.,.) = \n",
      "  0.1129  0.0905 -0.1847\n",
      " -0.2027 -0.0267  0.1618\n",
      "  0.0018 -0.1578 -0.1803\n",
      "\n",
      "(26,2 ,.,.) = \n",
      "  0.0721  0.0658  0.1701\n",
      " -0.1888  0.0027 -0.0234\n",
      " -0.0788 -0.0261 -0.1247\n",
      "\n",
      "(27,0 ,.,.) = \n",
      "  0.1236 -0.1189 -0.0323\n",
      " -0.0097 -0.0986  0.1458\n",
      "  0.0467 -0.0335 -0.0216\n",
      "\n",
      "(27,1 ,.,.) = \n",
      " -0.1585 -0.0648  0.1460\n",
      "  0.0231 -0.0174  0.1514\n",
      "  0.0642  0.1759 -0.1265\n",
      "\n",
      "(27,2 ,.,.) = \n",
      "  0.1693 -0.1296  0.0824\n",
      "  0.0390 -0.0047  0.1087\n",
      " -0.1134 -0.1937  0.0447\n",
      "\n",
      "(28,0 ,.,.) = \n",
      "  0.1756 -0.0768  0.0284\n",
      " -0.1497 -0.1609  0.1737\n",
      " -0.1147  0.0088 -0.1454\n",
      "\n",
      "(28,1 ,.,.) = \n",
      " -0.1056  0.1847  0.1341\n",
      " -0.0637  0.0078  0.1030\n",
      "  0.1702 -0.0879  0.1604\n",
      "\n",
      "(28,2 ,.,.) = \n",
      " -0.1343  0.1813 -0.0671\n",
      " -0.0235 -0.1729 -0.1336\n",
      " -0.0188 -0.1140  0.0016\n",
      "\n",
      "(29,0 ,.,.) = \n",
      " -0.1928  0.0538 -0.0627\n",
      "  0.0613  0.1046 -0.1646\n",
      "  0.1427 -0.1386  0.0463\n",
      "\n",
      "(29,1 ,.,.) = \n",
      " -0.0774 -0.1913 -0.1032\n",
      " -0.1770  0.0530  0.1523\n",
      " -0.1867 -0.0573  0.1453\n",
      "\n",
      "(29,2 ,.,.) = \n",
      "  0.1558 -0.1539 -0.0193\n",
      "  0.0526 -0.1638  0.0596\n",
      "  0.0984 -0.1904  0.0357\n",
      "\n",
      "(30,0 ,.,.) = \n",
      "  0.2008  0.0918  0.0637\n",
      "  0.1556  0.0168 -0.0382\n",
      "  0.0955 -0.1722 -0.1295\n",
      "\n",
      "(30,1 ,.,.) = \n",
      "  0.1791  0.1225  0.0605\n",
      "  0.1635 -0.1615 -0.1191\n",
      " -0.0362  0.0735  0.0056\n",
      "\n",
      "(30,2 ,.,.) = \n",
      " -0.1266 -0.0675  0.1482\n",
      "  0.1335 -0.0340  0.0068\n",
      "  0.1966 -0.0619 -0.0540\n",
      "\n",
      "(31,0 ,.,.) = \n",
      " -0.0847 -0.1135  0.0717\n",
      " -0.1412 -0.1567  0.1927\n",
      " -0.1485  0.0908  0.0884\n",
      "\n",
      "(31,1 ,.,.) = \n",
      " -0.1185 -0.1820  0.1609\n",
      " -0.1457  0.0416  0.0991\n",
      "  0.1185  0.1351  0.0007\n",
      "\n",
      "(31,2 ,.,.) = \n",
      "  0.1134 -0.1470 -0.0450\n",
      " -0.1591 -0.1585  0.1340\n",
      "  0.1379  0.0041  0.0065\n",
      "[torch.FloatTensor of size 32x3x3x3]\n",
      "), ('conv1.bias', \n",
      "-0.1262\n",
      "-0.1540\n",
      " 0.2571\n",
      " 0.2433\n",
      "-0.0214\n",
      "-0.1061\n",
      "-0.1319\n",
      " 0.0769\n",
      "-0.1016\n",
      " 0.3466\n",
      " 0.1055\n",
      "-0.0312\n",
      " 0.1643\n",
      "-0.1335\n",
      " 0.3805\n",
      " 0.3248\n",
      " 0.0687\n",
      "-0.1635\n",
      "-0.1759\n",
      "-0.1072\n",
      " 0.1115\n",
      " 0.2993\n",
      "-0.0675\n",
      "-0.1463\n",
      "-0.0867\n",
      " 0.4455\n",
      " 0.3923\n",
      " 0.0708\n",
      " 0.0074\n",
      " 0.2819\n",
      "-0.1045\n",
      "-0.0804\n",
      "[torch.FloatTensor of size 32]\n",
      "), ('conv2.weight', \n",
      "(0 ,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -1.5517 -3.8700 -3.6823\n",
      "  3.6034  1.5192  4.4556\n",
      " -2.1931  1.2472  4.1313\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.4627 -1.3925  4.8344\n",
      "  4.6810 -4.5756  5.1242\n",
      "  4.8907  4.6426 -2.7281\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.1134 -0.4502  5.7006\n",
      "  3.0840 -5.7901  0.0990\n",
      " -0.2853  2.4841 -4.2620\n",
      "   ...\n",
      "\n",
      "(0 ,29,.,.) = \n",
      "1.00000e-02 *\n",
      "  4.9110  0.7478  4.9114\n",
      "  3.6230  5.2966 -1.6073\n",
      "  4.3179 -3.5743  0.4774\n",
      "\n",
      "(0 ,30,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.0777 -0.3633 -2.0646\n",
      "  5.7312 -5.5867  2.8427\n",
      " -4.0799  0.3843  4.2830\n",
      "\n",
      "(0 ,31,.,.) = \n",
      "1.00000e-02 *\n",
      " -3.8776 -3.8920 -1.0251\n",
      "  0.2091  0.3844  0.5886\n",
      "  3.4495 -2.3541 -5.8316\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  2.0523  4.7078 -0.4561\n",
      " -5.5873 -3.7378 -3.8743\n",
      " -1.7568  2.9936  4.1635\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -3.0803  0.2461 -2.7056\n",
      " -2.6622 -2.6304  5.3680\n",
      "  3.9635 -3.0253 -4.3292\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.5648 -0.9413  5.8493\n",
      " -5.3413 -5.6534  2.9615\n",
      "  4.7105  5.6071  3.4171\n",
      "   ...\n",
      "\n",
      "(1 ,29,.,.) = \n",
      "1.00000e-02 *\n",
      "  3.3484  4.3874 -5.7740\n",
      "  5.6695 -0.3667 -4.4359\n",
      "  1.7188  2.9289 -1.9173\n",
      "\n",
      "(1 ,30,.,.) = \n",
      "1.00000e-02 *\n",
      "  2.1823  3.0968 -4.3644\n",
      "  1.5961  4.4175 -0.4587\n",
      "  3.3760  2.1233  3.6445\n",
      "\n",
      "(1 ,31,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.9395  4.4443  4.0797\n",
      "  4.5879 -0.2562 -0.5611\n",
      "  0.6099 -0.3146  2.9721\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  2.6305  2.1077 -5.0794\n",
      "  4.5588 -1.0927 -5.2653\n",
      " -2.0464 -1.5638  1.2410\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.0942  4.5608  2.9937\n",
      " -0.4114 -1.7084 -4.2800\n",
      " -5.5575  3.9658  1.3225\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  4.2048  4.9217  6.0062\n",
      "  3.0411  1.7052  2.4640\n",
      "  5.6218  4.6205 -2.8346\n",
      "   ...\n",
      "\n",
      "(2 ,29,.,.) = \n",
      "1.00000e-02 *\n",
      "  1.3969  2.6089 -3.0698\n",
      " -3.5529  0.4483  4.4314\n",
      "  1.8780  7.5237  1.1753\n",
      "\n",
      "(2 ,30,.,.) = \n",
      "1.00000e-02 *\n",
      "  1.9134 -6.0790  0.6386\n",
      "  4.1755 -1.5966 -0.1597\n",
      " -0.1744 -2.2212 -3.9230\n",
      "\n",
      "(2 ,31,.,.) = \n",
      "1.00000e-02 *\n",
      "  2.1221 -4.9367 -2.0260\n",
      "  4.2632 -3.6405 -3.9116\n",
      " -1.3148 -2.1940  1.0021\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(61,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.0147  1.3280  0.0141\n",
      "  0.8341 -4.2769  5.5105\n",
      "  4.7959 -3.7123 -2.7270\n",
      "\n",
      "(61,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  1.7545 -2.2496  2.6106\n",
      " -3.2695 -1.4661  0.3853\n",
      "  4.2791 -4.3384 -4.0538\n",
      "\n",
      "(61,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.7065  4.4324  2.8044\n",
      "  4.5851  2.6567 -0.4762\n",
      "  2.2172 -4.4581  1.6815\n",
      "   ...\n",
      "\n",
      "(61,29,.,.) = \n",
      "1.00000e-02 *\n",
      " -3.9876 -3.3367 -3.2207\n",
      "  2.8332  3.1283 -4.6628\n",
      "  4.3630  2.7980  5.7100\n",
      "\n",
      "(61,30,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.1213  5.7491  4.0629\n",
      "  0.5639  2.2162 -4.2688\n",
      "  5.4315  1.0634 -3.6731\n",
      "\n",
      "(61,31,.,.) = \n",
      "1.00000e-02 *\n",
      "  5.0555  5.3513  1.6730\n",
      "  5.7529 -5.6257  0.1636\n",
      "  1.6174  4.5822  0.6929\n",
      "     ⋮ \n",
      "\n",
      "(62,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -1.2776  1.7166  3.1300\n",
      "  2.6267  2.6332 -0.9440\n",
      "  1.5836 -1.2344  2.8731\n",
      "\n",
      "(62,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  5.4742 -4.3710  0.4521\n",
      " -0.2377 -3.6689 -3.1880\n",
      "  4.3790  3.6613 -1.3368\n",
      "\n",
      "(62,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.5375  0.3499 -4.9323\n",
      " -5.8519  4.2565 -1.4937\n",
      " -4.4626 -2.9096  4.5453\n",
      "   ...\n",
      "\n",
      "(62,29,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.6461  4.6619 -5.0657\n",
      " -3.3725  0.1628  2.9916\n",
      " -2.5839  4.0220 -4.1278\n",
      "\n",
      "(62,30,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.3816  1.1696 -4.3916\n",
      " -0.0856 -2.1486 -3.1181\n",
      " -0.6674  3.0655  2.1068\n",
      "\n",
      "(62,31,.,.) = \n",
      "1.00000e-02 *\n",
      "  1.9596 -3.4880 -0.3547\n",
      " -0.9379  1.5897 -2.7591\n",
      "  0.2425 -1.2205 -3.2370\n",
      "     ⋮ \n",
      "\n",
      "(63,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  4.1828  3.3788  2.4291\n",
      "  1.4649  0.4596  4.2962\n",
      " -5.6697 -3.3467  4.3766\n",
      "\n",
      "(63,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.9982  3.1296  5.3655\n",
      "  4.8629  4.9918 -0.6405\n",
      "  1.5931  3.6189 -5.8303\n",
      "\n",
      "(63,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  5.6962  3.0067 -3.2901\n",
      " -2.6428 -0.5829  1.3957\n",
      "  2.5900  3.5690  5.8409\n",
      "   ...\n",
      "\n",
      "(63,29,.,.) = \n",
      "1.00000e-02 *\n",
      "  3.4943  5.6216  4.1551\n",
      "  2.7051  0.6341  3.4352\n",
      " -5.7169  1.1210  2.5416\n",
      "\n",
      "(63,30,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.9370  5.6089 -2.6894\n",
      "  3.9108 -4.8148  0.7887\n",
      " -0.0590  1.3289  3.9649\n",
      "\n",
      "(63,31,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.9457 -2.7431 -2.8497\n",
      " -3.4519  4.6685 -5.8265\n",
      "  1.8573  0.2658  2.3712\n",
      "[torch.FloatTensor of size 64x32x3x3]\n",
      "), ('conv2.bias', \n",
      " 0.0330\n",
      " 0.0314\n",
      " 0.1311\n",
      "-0.0174\n",
      " 0.0957\n",
      " 0.0454\n",
      " 0.0121\n",
      " 0.0001\n",
      " 0.0888\n",
      " 0.0545\n",
      " 0.0198\n",
      " 0.0285\n",
      " 0.0855\n",
      " 0.0944\n",
      "-0.0531\n",
      " 0.0936\n",
      " 0.0378\n",
      "-0.0470\n",
      " 0.0678\n",
      " 0.0749\n",
      " 0.0459\n",
      " 0.1240\n",
      " 0.0397\n",
      " 0.1076\n",
      " 0.0086\n",
      "-0.0108\n",
      " 0.1142\n",
      " 0.0628\n",
      " 0.0847\n",
      "-0.0265\n",
      "-0.0054\n",
      "-0.0187\n",
      "-0.0484\n",
      " 0.0714\n",
      "-0.0555\n",
      " 0.1187\n",
      " 0.0237\n",
      " 0.0047\n",
      "-0.0554\n",
      " 0.0530\n",
      "-0.0549\n",
      " 0.0931\n",
      " 0.0420\n",
      " 0.0468\n",
      "-0.0204\n",
      " 0.1130\n",
      "-0.0168\n",
      "-0.0045\n",
      " 0.0078\n",
      " 0.0109\n",
      " 0.0081\n",
      "-0.0473\n",
      "-0.0443\n",
      " 0.0409\n",
      "-0.0418\n",
      " 0.0522\n",
      " 0.0425\n",
      " 0.0270\n",
      "-0.0386\n",
      " 0.1196\n",
      "-0.0407\n",
      "-0.0250\n",
      " 0.0110\n",
      "-0.0300\n",
      "[torch.FloatTensor of size 64]\n",
      "), ('fc1.weight', \n",
      "-2.0252e-02  1.7674e-02  2.3423e-03  ...   1.0058e-03  9.2306e-03 -1.8194e-02\n",
      "-4.7159e-03  2.0091e-03  1.8899e-02  ...   5.0062e-03 -1.9302e-02  1.9593e-02\n",
      "-1.1443e-02 -1.7184e-02  1.5639e-02  ...   1.9164e-02 -1.0314e-02 -1.3345e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 6.8596e-03  1.2328e-02  1.8272e-02  ...   1.0504e-03  2.0166e-02  3.9109e-03\n",
      " 1.2552e-02  4.8745e-03 -5.5974e-03  ...  -1.1621e-02  8.6178e-03  1.4749e-02\n",
      " 6.0242e-03  1.8313e-02 -1.4724e-02  ...  -1.3046e-02 -7.9409e-03  2.0551e-02\n",
      "[torch.FloatTensor of size 256x2304]\n",
      "), ('fc1.bias', \n",
      "1.00000e-02 *\n",
      " -0.3491\n",
      " -1.2022\n",
      "  0.7844\n",
      " -0.1601\n",
      "  1.5611\n",
      "  2.9775\n",
      "  0.2781\n",
      "  1.7158\n",
      "  2.0351\n",
      "  0.6385\n",
      " -1.6673\n",
      "  1.9563\n",
      " -1.4957\n",
      "  0.0740\n",
      " -1.3840\n",
      "  1.7367\n",
      "  1.9554\n",
      "  0.1290\n",
      " -1.0868\n",
      "  2.6993\n",
      "  0.5643\n",
      "  0.7091\n",
      " -0.8901\n",
      "  0.7895\n",
      " -0.2287\n",
      " -1.0717\n",
      "  0.2843\n",
      "  3.4276\n",
      "  1.3506\n",
      "  2.2101\n",
      "  0.7883\n",
      "  3.5515\n",
      " -1.8328\n",
      "  0.8344\n",
      " -0.8651\n",
      "  0.3001\n",
      " -0.9379\n",
      " -0.9448\n",
      "  1.6866\n",
      " -2.5253\n",
      "  2.1138\n",
      "  1.9971\n",
      "  1.4235\n",
      "  1.1032\n",
      " -1.0714\n",
      " -0.8644\n",
      "  1.8953\n",
      "  0.9188\n",
      " -1.8206\n",
      " -0.7138\n",
      "  2.0197\n",
      " -0.3494\n",
      "  1.1786\n",
      " -1.4420\n",
      " -0.4958\n",
      "  0.9732\n",
      " -1.0460\n",
      "  0.4852\n",
      " -0.7381\n",
      "  0.5070\n",
      "  2.6069\n",
      "  2.1609\n",
      "  1.6273\n",
      "  1.2139\n",
      "  0.2883\n",
      " -1.6746\n",
      "  4.9732\n",
      "  1.8451\n",
      " -1.7768\n",
      "  0.7903\n",
      "  0.7729\n",
      "  4.3961\n",
      " -0.2173\n",
      "  1.9746\n",
      " -2.2077\n",
      "  1.0948\n",
      " -0.1538\n",
      "  0.6071\n",
      " -1.8068\n",
      " -0.5314\n",
      "  2.0377\n",
      "  1.0162\n",
      " -0.4483\n",
      "  0.2576\n",
      "  1.2259\n",
      "  1.0310\n",
      " -0.1261\n",
      " -0.5650\n",
      " -2.2034\n",
      "  2.1056\n",
      "  0.6412\n",
      "  0.6468\n",
      "  1.7989\n",
      "  0.0396\n",
      "  1.7741\n",
      " -0.1640\n",
      "  0.1622\n",
      "  0.8066\n",
      " -0.5233\n",
      " -0.2864\n",
      "  2.1659\n",
      "  3.1052\n",
      "  1.5418\n",
      " -1.9936\n",
      "  0.2833\n",
      "  2.0523\n",
      " -0.6675\n",
      "  3.3992\n",
      "  4.3911\n",
      "  1.5589\n",
      "  2.5847\n",
      "  1.1119\n",
      "  2.0971\n",
      "  0.9126\n",
      "  1.3113\n",
      "  1.1071\n",
      "  0.8135\n",
      " -0.0532\n",
      " -1.8716\n",
      " -0.4048\n",
      "  0.2056\n",
      "  0.0090\n",
      " -0.1184\n",
      " -1.4083\n",
      "  0.6551\n",
      " -0.4825\n",
      "  1.8026\n",
      "  1.0008\n",
      " -0.5839\n",
      "  0.3363\n",
      " -1.8963\n",
      " -0.6228\n",
      " -1.9610\n",
      "  0.9731\n",
      "  2.0436\n",
      "  0.3501\n",
      "  4.5996\n",
      "  2.1327\n",
      "  2.3046\n",
      " -0.4414\n",
      "  0.9178\n",
      " -0.7970\n",
      "  1.8029\n",
      "  0.9643\n",
      " -0.0916\n",
      " -0.8274\n",
      "  3.7396\n",
      " -0.0855\n",
      "  3.5357\n",
      "  0.2482\n",
      "  0.2331\n",
      "  3.1407\n",
      "  0.0853\n",
      "  2.7210\n",
      "  0.4963\n",
      " -1.0443\n",
      "  1.1211\n",
      " -0.8699\n",
      " -0.1040\n",
      "  1.2052\n",
      "  1.4723\n",
      "  1.0233\n",
      " -1.6913\n",
      "  1.4379\n",
      "  1.9001\n",
      " -0.4063\n",
      "  2.1368\n",
      " -1.2517\n",
      " -1.6963\n",
      "  4.6180\n",
      "  0.7051\n",
      " -1.2430\n",
      "  0.1448\n",
      "  1.5854\n",
      " -0.9512\n",
      "  1.7504\n",
      " -1.7803\n",
      "  1.4830\n",
      "  0.7415\n",
      "  0.5834\n",
      " -2.0322\n",
      "  0.4752\n",
      " -0.1156\n",
      " -0.4093\n",
      "  0.1085\n",
      " -1.2149\n",
      "  0.6309\n",
      "  1.4593\n",
      " -1.4197\n",
      " -1.1421\n",
      " -0.0877\n",
      " -0.4704\n",
      "  2.2016\n",
      " -0.9846\n",
      "  2.2283\n",
      "  3.6401\n",
      "  1.8885\n",
      " -0.1257\n",
      "  0.3514\n",
      "  0.4739\n",
      "  0.8602\n",
      "  1.1818\n",
      "  2.6649\n",
      "  1.7112\n",
      "  1.8130\n",
      "  0.3568\n",
      " -1.5263\n",
      "  0.7329\n",
      "  0.3638\n",
      "  2.3645\n",
      "  2.2233\n",
      "  1.3196\n",
      "  0.8793\n",
      "  0.0862\n",
      " -1.2783\n",
      " -0.1656\n",
      "  2.0727\n",
      "  0.7829\n",
      "  1.4444\n",
      " -2.2203\n",
      "  1.6809\n",
      "  0.9533\n",
      "  0.6392\n",
      " -1.0727\n",
      "  0.1720\n",
      "  0.9768\n",
      "  1.6907\n",
      "  3.9727\n",
      "  2.4211\n",
      "  0.8350\n",
      " -1.9768\n",
      "  0.0975\n",
      " -1.7212\n",
      "  0.3298\n",
      "  1.3016\n",
      "  1.7456\n",
      " -0.7439\n",
      "  0.6668\n",
      "  1.3580\n",
      "  2.3751\n",
      " -1.1615\n",
      "  3.5974\n",
      " -1.3244\n",
      "  2.6406\n",
      " -2.4210\n",
      "  0.0569\n",
      "  1.9211\n",
      " -0.3607\n",
      "  3.0028\n",
      " -1.3496\n",
      "  0.7786\n",
      "  0.1322\n",
      "  3.2342\n",
      " -1.0067\n",
      " -1.4972\n",
      " -0.4523\n",
      "[torch.FloatTensor of size 256]\n",
      "), ('fc2.weight', \n",
      "-0.0003  0.0419  0.0173  ...   0.0444  0.0195 -0.0361\n",
      " 0.0083 -0.0643 -0.0662  ...   0.0241  0.0523 -0.0556\n",
      "-0.0072  0.0340  0.0412  ...  -0.0411 -0.0235 -0.0477\n",
      "          ...             ⋱             ...          \n",
      "-0.0460 -0.0651  0.0422  ...   0.0359  0.0422  0.0139\n",
      " 0.0356  0.0257  0.0020  ...   0.0492 -0.0612  0.0050\n",
      "-0.0452 -0.0580  0.0137  ...   0.0378  0.0252 -0.0304\n",
      "[torch.FloatTensor of size 17x256]\n",
      "), ('fc2.bias', \n",
      "-0.0439\n",
      "-0.0918\n",
      "-0.0853\n",
      "-0.1044\n",
      "-0.0792\n",
      "-0.0049\n",
      "-0.0517\n",
      "-0.1394\n",
      "-0.1449\n",
      "-0.1322\n",
      "-0.1097\n",
      "-0.0662\n",
      " 0.0517\n",
      "-0.0366\n",
      "-0.1433\n",
      "-0.1251\n",
      "-0.0754\n",
      "[torch.FloatTensor of size 17]\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "lgr.info('Model {}'.format(model.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ./09 PyTorch Kaggle Image Data-set loading with CNN.ipynb to slides\n",
      "[NbConvertApp] Writing 303374 bytes to ./py09.html.slides.html\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "jupyter nbconvert \\\n",
    "    --to=slides \\\n",
    "    --reveal-prefix=https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.2.0/ \\\n",
    "    --output=py09.html \\\n",
    "    './09 PyTorch Kaggle Image Data-set loading with CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
