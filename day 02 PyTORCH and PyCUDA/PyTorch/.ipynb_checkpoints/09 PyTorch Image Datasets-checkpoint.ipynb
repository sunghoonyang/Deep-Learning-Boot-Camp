{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 09 PyTorch Image Datasets\n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('__Python VERSION:', '2.7.12 (default, Nov 19 2016, 06:48:10) \\n[GCC 5.4.0 20160609]')\n",
      "('__pyTorch VERSION:', '0.1.12+4eb448a')\n",
      "__CUDA VERSION\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2016 NVIDIA Corporation\n",
      "Built on Tue_Jan_10_13:22:03_CST_2017\n",
      "Cuda compilation tools, release 8.0, V8.0.61\n",
      "('__CUDNN VERSION:', 5110)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:<class 'torch.FloatTensor'>\n",
      "INFO:__main__:\n",
      "1.00000e-36 *\n",
      " -7.0698  0.0000\n",
      " -7.0698  0.0000\n",
      "  0.8719  0.0000\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('__Number CUDA Devices:', 1L)\n",
      "__Devices\n",
      "('Active CUDA Device: GPU', 0L)\n",
      "('Available devices ', 1L)\n",
      "('Current cuda device ', 0L)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       "[torch.cuda.DoubleTensor of size 3x4 (GPU 0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import numpy\n",
    "import os.path\n",
    "import shutil\n",
    "import pandas\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "import PIL.Image\n",
    "import random\n",
    "import matplotlib.pyplot\n",
    "import pylab\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms\n",
    "import torch.nn\n",
    "import torch.nn.functional\n",
    "import torch.optim\n",
    "import torch.autograd\n",
    "%matplotlib inline\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "\n",
    "gpu_index = 0\n",
    "torch.cuda.set_device(gpu_index)\n",
    "    \n",
    "from __future__ import print_function\n",
    "import torch\n",
    "x=torch.Tensor(3,2)\n",
    "import logging\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "\n",
    "lgr.info (type(x))\n",
    "lgr.info(x)\n",
    "torch.from_numpy (np.zeros((3,4))).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch image Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT ='/root/data/amazon/'\n",
    "IMG_PATH = DATA_ROOT + '/train-jpg/'\n",
    "IMG_EXT = '.jpg'\n",
    "IMG_LEBELS_PATH = DATA_ROOT + '/train_v2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class GenericImageDataset(torch.utils.data.dataset.Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 csv_training_labels_path, \n",
    "                 image_directory, \n",
    "                 image_extension,                  \n",
    "                 transform = None):\n",
    "        lgr.info(\"GenericImageDataset CTOR ...\")\n",
    "        self.csv_training_labels_path = csv_training_labels_path\n",
    "        self.image_directory = image_directory\n",
    "        self.image_extension = image_extension\n",
    "        self.transform = transform\n",
    "        \n",
    "        lgr.info (\"CSV path:\" + csv_training_labels_path)\n",
    "        lgr.info (\"IMG path:\" + image_directory)\n",
    "        \n",
    "        training_examples = pandas.read_csv(self.csv_training_labels_path)\n",
    "#         tmp_df = pd.read_csv(csv_path, header=None)\n",
    "        self.training_image_names = training_examples['image_name']\n",
    "        self.training_labels = training_examples['tags']\n",
    "        \n",
    "        self.training_image_names = self.training_image_names.head()\n",
    "        self.training_labels = self.training_labels.head()\n",
    "\n",
    "        is_file = lambda training_image_name: os.path.isfile(\n",
    "            self.image_directory + training_image_name + self.image_extension)\n",
    "        assert self.training_image_names.apply(\n",
    "            is_file).all(), \"Some training images in \" + self.csv_training_labels_path + \" are not found.\"\n",
    "\n",
    "        self.multi_label_binarizer = sklearn.preprocessing.MultiLabelBinarizer()\n",
    "        self.training_labels = self.multi_label_binarizer.fit_transform(self.training_labels.str.split())\n",
    "        self.training_labels = self.training_labels.astype(numpy.float32)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        lgr.info (\"Get item:\" + str(index))\n",
    "        training_image_path = self.image_directory + self.training_image_names[index] + self.image_extension\n",
    "        training_image = PIL.Image.open(training_image_path)\n",
    "        training_image = training_image.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            training_image = self.transform(training_image)\n",
    "        training_label = torch.from_numpy(self.training_labels[index])\n",
    "\n",
    "        return (training_image, training_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        L=len(self.training_image_names.index)\n",
    "        lgr.info (\"Lenght:\" +str(L))\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:GenericImageDataset CTOR ...\n",
      "INFO:__main__:CSV path:/root/data/amazon//train_v2.csv\n",
      "INFO:__main__:IMG path:/root/data/amazon//train-jpg/\n"
     ]
    }
   ],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_set = GenericImageDataset(IMG_LEBELS_PATH, \n",
    "                                IMG_PATH, \n",
    "                                IMG_EXT,                                 \n",
    "                                transform = transformations)\n",
    "\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=5,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Lenght:5\n",
      "INFO:__main__:Lenght:5\n",
      "INFO:__main__:Get item:0\n",
      "INFO:__main__:Get item:1\n",
      "INFO:__main__:Get item:4\n",
      "INFO:__main__:Get item:2\n",
      "INFO:__main__:Get item:3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print (type(data)) # <class 'torch.FloatTensor'>   \n",
    "#     trans = transforms.ToPILImage()\n",
    "#     plt.imshow(trans(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
