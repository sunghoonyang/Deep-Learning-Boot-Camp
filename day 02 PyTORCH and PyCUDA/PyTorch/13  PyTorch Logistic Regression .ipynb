{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 13  PyTorch Logistic Regression \n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.6 (default, Oct 26 2016, 20:30:19) \n",
      "[GCC 4.8.4]\n",
      "__pyTorch VERSION: 0.2.0_1\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 0\n",
      "__Devices\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Load a CSV file for Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.531170</td>\n",
       "      <td>-0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.145729</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.766866</td>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.492741</td>\n",
       "      <td>-0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.162444</td>\n",
       "      <td>-0.923997</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.602837</td>\n",
       "      <td>0.284650</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.294118  0.487437  0.180328 -0.292929  0.000000  0.001490 -0.531170   \n",
       "1 -0.882353 -0.145729  0.081967 -0.414141  0.000000 -0.207153 -0.766866   \n",
       "2 -0.058824  0.839196  0.049180  0.000000  0.000000 -0.305514 -0.492741   \n",
       "3 -0.882353 -0.105528  0.081967 -0.535354 -0.777778 -0.162444 -0.923997   \n",
       "4  0.000000  0.376884 -0.344262 -0.292929 -0.602837  0.284650  0.887276   \n",
       "\n",
       "          7  \n",
       "0 -0.033333  \n",
       "1 -0.666667  \n",
       "2 -0.633333  \n",
       "3  0.000000  \n",
       "4 -0.600000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% reset -f\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import logging\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "F_NAME_TRAIN= 'data-03-diabetes.csv'\n",
    "\n",
    "X_df_train= pd.read_csv(F_NAME_TRAIN,header=None)\n",
    "X_df_train_SINGLE=X_df_train.copy(deep=True)\n",
    "answers_1_SINGLE = list (X_df_train_SINGLE[X_df_train_SINGLE.columns[-1]].values)\n",
    "answers_1_SINGLE= map(int, answers_1_SINGLE)\n",
    "X_df_train_SINGLE = X_df_train_SINGLE.drop(X_df_train_SINGLE.columns[-1], axis=1)\n",
    "X_df_train_SINGLE=X_df_train_SINGLE.apply(lambda x: pandas.to_numeric(x, errors='ignore'))  \n",
    "\n",
    "print(X_df_train_SINGLE.shape)\n",
    "\n",
    "X_df_train_SINGLE.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create PyTorch GPU tensors\n",
    "\n",
    "- Note how we transfrom the np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592, 8) (592, 1)\n",
      "<type 'numpy.ndarray'> <type 'numpy.ndarray'>\n",
      "<class 'torch.FloatTensor'> <class 'torch.FloatTensor'>\n",
      "<class 'torch.FloatTensor'> <class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "\n",
    "# fix seed\n",
    "seed=17*19\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "        \n",
    "\n",
    "# sk learn\n",
    "trainX, testX, trainY, testY = train_test_split(X_df_train_SINGLE, answers_1_SINGLE, test_size=.22, random_state=999)  \n",
    "\n",
    "# Train data\n",
    "x_data_np = np.array(trainX.values, dtype=np.float32)\n",
    "y_data_np = np.array(trainY, dtype=np.float32)\n",
    "y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "\n",
    "\n",
    "print(x_data_np.shape, y_data_np.shape)\n",
    "print(type(x_data_np), type(y_data_np))\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    X = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch\n",
    "    Y = Variable(torch.from_numpy(y_data_np).cuda())\n",
    "else:\n",
    "    lgr.info (\"Using the CPU\")\n",
    "    X = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "    Y = Variable(torch.from_numpy(y_data_np))    \n",
    "print(type(X.data), type(Y.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    \n",
    "print(type(X.data), type(Y.data)) # should be 'torch.cuda.FloatTensor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Define the NN model\n",
    "\n",
    "- First a simple two leyer network and then a more involved version\n",
    "\n",
    "- There are many ways to select the initial weights to a neural network architecture. A common initialization scheme is random initialization, which sets the biases and weights of all the nodes in each hidden layer randomly, so they are in a random point of the space, and objective function, and then find a nearby local minima using an algorithm like SGD or Adam.\n",
    "- We use a *xavier initializer*, in effect (according to theory) initializing the weights of the network to values that would be closer to the optimal, and therefore require less epochs to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n",
      "INFO:__main__:Model Sequential (\n",
      "  (0): Linear (8 -> 32)\n",
      "  (1): Dropout (p = 0.15)\n",
      "  (2): Tanh ()\n",
      "  (3): Linear (32 -> 16)\n",
      "  (4): Dropout (p = 0.15)\n",
      "  (5): Tanh ()\n",
      "  (6): Linear (16 -> 1)\n",
      "  (7): Dropout (p = 0.15)\n",
      "  (8): Sigmoid ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "keep_prob=0.85\n",
    "# p is the probability of being dropped in PyTorch\n",
    "dropout = torch.nn.Dropout(p=1 - keep_prob)\n",
    "\n",
    "\n",
    "hiddenLayer1Size=32\n",
    "hiddenLayer2Size=16\n",
    "# # Hypothesis using sigmoid\n",
    "linear1=torch.nn.Linear(x_data_np.shape[1], hiddenLayer1Size, bias=True) # size mismatch, m1: [5373 x 344], m2: [8 x 1] at /pytorch/torch/lib/TH/generic/THTensorMath.c:1293\n",
    "# xavier initializer\n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "linear2=torch.nn.Linear(hiddenLayer1Size, hiddenLayer2Size)\n",
    "# xavier initializer\n",
    "torch.nn.init.xavier_uniform(linear2.weight)\n",
    "linear3=torch.nn.Linear(hiddenLayer2Size, 1)\n",
    "# xavier initializer\n",
    "torch.nn.init.xavier_uniform(linear3.weight)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "tanh=torch.nn.Tanh()\n",
    "model = torch.nn.Sequential(linear1,dropout, tanh, linear2,dropout, tanh, linear3,dropout, sigmoid)\n",
    "\n",
    "\n",
    "# #Hypothesis using sigmoid\n",
    "# linear1=torch.nn.Linear(x_data_np.shape[1], 1, bias=True) \n",
    "# # xavier initializer\n",
    "# torch.nn.init.xavier_uniform(linear1.weight)\n",
    "# sigmoid = torch.nn.Sigmoid()\n",
    "# model = torch.nn.Sequential(linear1,dropout, sigmoid)\n",
    "# # model = torch.nn.Sequential(linear1, sigmoid)\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")\n",
    "    model = model.cuda() # On GPU\n",
    "else:\n",
    "    lgr.info (\"Using the CPU\")   \n",
    "\n",
    "lgr.info('Model {}'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Optimizer <torch.optim.sgd.SGD object at 0x7fb244692290>\n"
     ]
    }
   ],
   "source": [
    "# see https://github.com/facebookresearch/SentEval/blob/master/senteval/tools/classifier.py\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "lgr.info('Optimizer {}'.format(optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The cross-entropy loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "sp.interactive.printing.init_printing(use_latex=True)\n",
    "from IPython.display import display, Math, Latex\n",
    "maths = lambda s: display(Math(s))\n",
    "latex = lambda s: display(Latex(s))\n",
    "\n",
    "#the loss function is as follows:\n",
    "maths(\"\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Start training in Batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.83436877]\n",
      "TRAINING LOG_LOSS=0.773275594982\n",
      "TRAINING ROC AUC:0.486734965239\n",
      "4000 [ 0.48640257]\n",
      "TRAINING LOG_LOSS=0.483760661987\n",
      "TRAINING ROC AUC:0.815334253549\n",
      "8000 [ 0.47054452]\n",
      "TRAINING LOG_LOSS=0.486227451048\n",
      "TRAINING ROC AUC:0.820646599212\n",
      "12000 [ 0.47109121]\n",
      "TRAINING LOG_LOSS=0.442642504024\n",
      "TRAINING ROC AUC:0.853014550382\n",
      "16000 [ 0.46237826]\n",
      "TRAINING LOG_LOSS=0.452384518758\n",
      "TRAINING ROC AUC:0.839515240544\n",
      "GPU: 120.561 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()    \n",
    "epochs=20000\n",
    "\n",
    "for step in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)    \n",
    "    # cost/loss function\n",
    "    cost = -(Y * torch.log(hypothesis) + (1 - Y)\n",
    "             * torch.log(1 - hypothesis)).mean()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 4000 == 0:\n",
    "        print(step, cost.data.cpu().numpy())\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "        # Use .cpu() to move the tensor to host memory first.\n",
    "#         predicted = (model(X).data > 0.5).float()\n",
    "        predicted = (model(X).data ).float() # This is like predict proba\n",
    "        predictions=predicted.cpu().numpy()\n",
    "#         accuracy = (predicted == Y.data).float().mean()\n",
    "#         print('TRAINNING Accuracy:' + str(accuracy))\n",
    "        print ('TRAINING LOG_LOSS=' + str(log_loss(trainY, predictions)))\n",
    "        R_SCORE=roc_auc_score(Y.data.cpu().numpy(),predictions )        \n",
    "        print ('TRAINING ROC AUC:' + str(R_SCORE))\n",
    "\n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cross validation, metrics, ROC_AUC etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 8) (167, 1)\n",
      "<type 'numpy.ndarray'> <type 'numpy.ndarray'>\n",
      "VALIDATION ROC AUC:0.848753894081\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQSUqIQEZGElChERCSh/w92NrENGTz6wwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb2448169d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Validation data\n",
    "x_data_np_val = np.array(testX.values, dtype=np.float32)\n",
    "y_data_np_val = np.array(testY, dtype=np.float32)\n",
    "y_data_np_val=y_data_np_val.reshape((y_data_np_val.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "\n",
    "\n",
    "print(x_data_np_val.shape, y_data_np_val.shape)\n",
    "print(type(x_data_np_val), type(y_data_np_val))\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    X_val = Variable(torch.from_numpy(x_data_np_val).cuda()) # Note the conversion for pytorch\n",
    "    Y_val = Variable(torch.from_numpy(y_data_np_val).cuda())\n",
    "else:\n",
    "    lgr.info (\"Using the CPU\")\n",
    "    X_val = Variable(torch.from_numpy(x_data_np_val)) # Note the conversion for pytorch\n",
    "    Y_val = Variable(torch.from_numpy(y_data_np_val))\n",
    "\n",
    "# VALIDATION\n",
    "predicted_val = (model(X_val).data).float()\n",
    "predictions_val=predicted_val.cpu().numpy()\n",
    "accuracy_val = (predicted_val == Y_val.data).float().mean()\n",
    "R_SCORE_VAL=roc_auc_score(Y_val.data.cpu().numpy(),predictions_val)        \n",
    "print ('VALIDATION ROC AUC:' + str(R_SCORE_VAL))\n",
    "\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(testY, predictions_val)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt.title('LOG_LOSS=' + str(log_loss(testY, predictions_val)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
