{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 13  PyTorch Logistic Regression \n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:1.2.1\n",
      "__Python VERSION: 2.7.6 (default, Oct 26 2016, 20:30:19) \n",
      "[GCC 4.8.4]\n",
      "__pyTorch VERSION: 0.2.0_1\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 0\n",
      "__Devices\n"
     ]
    }
   ],
   "source": [
    "# !pip install pycuda\n",
    "%reset -f\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Load a CSV file for Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.531170</td>\n",
       "      <td>-0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.145729</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.766866</td>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.492741</td>\n",
       "      <td>-0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.162444</td>\n",
       "      <td>-0.923997</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.602837</td>\n",
       "      <td>0.284650</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.294118  0.487437  0.180328 -0.292929  0.000000  0.001490 -0.531170   \n",
       "1 -0.882353 -0.145729  0.081967 -0.414141  0.000000 -0.207153 -0.766866   \n",
       "2 -0.058824  0.839196  0.049180  0.000000  0.000000 -0.305514 -0.492741   \n",
       "3 -0.882353 -0.105528  0.081967 -0.535354 -0.777778 -0.162444 -0.923997   \n",
       "4  0.000000  0.376884 -0.344262 -0.292929 -0.602837  0.284650  0.887276   \n",
       "\n",
       "          7  \n",
       "0 -0.033333  \n",
       "1 -0.666667  \n",
       "2 -0.633333  \n",
       "3  0.000000  \n",
       "4 -0.600000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% reset -f\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import logging\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "F_NAME_TRAIN= 'data-03-diabetes.csv'\n",
    "\n",
    "X_df_train= pd.read_csv(F_NAME_TRAIN,header=None)\n",
    "X_df_train_SINGLE=X_df_train.copy(deep=True)\n",
    "answers_1_SINGLE = list (X_df_train_SINGLE[X_df_train_SINGLE.columns[-1]].values)\n",
    "answers_1_SINGLE= map(int, answers_1_SINGLE)\n",
    "X_df_train_SINGLE = X_df_train_SINGLE.drop(X_df_train_SINGLE.columns[-1], axis=1)\n",
    "X_df_train_SINGLE=X_df_train_SINGLE.apply(lambda x: pandas.to_numeric(x, errors='ignore'))  \n",
    "\n",
    "print(X_df_train_SINGLE.shape)\n",
    "\n",
    "X_df_train_SINGLE.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create PyTorch GPU tensors\n",
    "\n",
    "- Note how we transfrom the np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592, 8) (592, 1)\n",
      "<type 'numpy.ndarray'> <type 'numpy.ndarray'>\n",
      "<class 'torch.FloatTensor'> <class 'torch.FloatTensor'>\n",
      "<class 'torch.FloatTensor'> <class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "\n",
    "# fix seed\n",
    "seed=17*19\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "        \n",
    "\n",
    "# sk learn\n",
    "trainX, testX, trainY, testY = train_test_split(X_df_train_SINGLE, answers_1_SINGLE, test_size=.22, random_state=999)  \n",
    "\n",
    "# Train data\n",
    "x_data_np = np.array(trainX.values, dtype=np.float32)\n",
    "y_data_np = np.array(trainY, dtype=np.float32)\n",
    "y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "\n",
    "\n",
    "print(x_data_np.shape, y_data_np.shape)\n",
    "print(type(x_data_np), type(y_data_np))\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    X = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch\n",
    "    Y = Variable(torch.from_numpy(y_data_np).cuda())\n",
    "else:\n",
    "    lgr.info (\"Using the CPU\")\n",
    "    X = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "    Y = Variable(torch.from_numpy(y_data_np))    \n",
    "print(type(X.data), type(Y.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    \n",
    "print(type(X.data), type(Y.data)) # should be 'torch.cuda.FloatTensor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Define the NN model\n",
    "\n",
    "- First a simple two leyer network and then a more involved version\n",
    "\n",
    "- There are many ways to select the initial weights to a neural network architecture. A common initialization scheme is random initialization, which sets the biases and weights of all the nodes in each hidden layer randomly, so they are in a random point of the space, and objective function, and then find a nearby local minima using an algorithm like SGD or Adam.\n",
    "- We use a *xavier initializer*, in effect (according to theory) initializing the weights of the network to values that would be closer to the optimal, and therefore require less epochs to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n",
      "INFO:__main__:Model Sequential (\n",
      "  (0): Linear (8 -> 1)\n",
      "  (1): Sigmoid ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "keep_prob=0.85\n",
    "# p is the probability of being dropped in PyTorch\n",
    "dropout = torch.nn.Dropout(p=1 - keep_prob)\n",
    "\n",
    "\n",
    "hiddenLayer1Size=32\n",
    "hiddenLayer2Size=16\n",
    "# # Hypothesis using sigmoid\n",
    "linear1=torch.nn.Linear(x_data_np.shape[1], hiddenLayer1Size, bias=True) # size mismatch, m1: [5373 x 344], m2: [8 x 1] at /pytorch/torch/lib/TH/generic/THTensorMath.c:1293\n",
    "# xavier initializer\n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "linear2=torch.nn.Linear(hiddenLayer1Size, hiddenLayer2Size)\n",
    "# xavier initializer\n",
    "torch.nn.init.xavier_uniform(linear2.weight)\n",
    "linear3=torch.nn.Linear(hiddenLayer2Size, 1)\n",
    "# xavier initializer\n",
    "torch.nn.init.xavier_uniform(linear3.weight)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "tanh=torch.nn.Tanh()\n",
    "model = torch.nn.Sequential(linear1,dropout, tanh, linear2, tanh, linear3,sigmoid)\n",
    "\n",
    "\n",
    "#Hypothesis using sigmoid\n",
    "linear1=torch.nn.Linear(x_data_np.shape[1], 1, bias=True) \n",
    "# xavier initializer\n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "# model = torch.nn.Sequential(linear1,dropout, sigmoid)\n",
    "model = torch.nn.Sequential(linear1, sigmoid)\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")\n",
    "    model = model.cuda() # On GPU\n",
    "else:\n",
    "    lgr.info (\"Using the CPU\")   \n",
    "\n",
    "lgr.info('Model {}'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Optimizer <torch.optim.sgd.SGD object at 0x7fb24476bf90>\n"
     ]
    }
   ],
   "source": [
    "# see https://github.com/facebookresearch/SentEval/blob/master/senteval/tools/classifier.py\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "lgr.info('Optimizer {}'.format(optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The cross-entropy loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "sp.interactive.printing.init_printing(use_latex=True)\n",
    "from IPython.display import display, Math, Latex\n",
    "maths = lambda s: display(Math(s))\n",
    "latex = lambda s: display(Latex(s))\n",
    "\n",
    "#the loss function is as follows:\n",
    "maths(\"\\mathbf{Loss Function:} J(x, z) = -\\sum_k^d[x_k \\log z_k + (1-x_k)log(1-z_k)]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Start training in Batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.70002741]\n",
      "TRAINING LOG_LOSS=0.69553798276\n",
      "TRAINING ROC AUC:0.411437689161\n",
      "4000 [ 0.47060481]\n",
      "TRAINING LOG_LOSS=0.47060448441\n",
      "TRAINING ROC AUC:0.840085098839\n",
      "8000 [ 0.47019634]\n",
      "TRAINING LOG_LOSS=0.470196323878\n",
      "TRAINING ROC AUC:0.840173743462\n",
      "12000 [ 0.47017387]\n",
      "TRAINING LOG_LOSS=0.470173862851\n",
      "TRAINING ROC AUC:0.840300378639\n",
      "16000 [ 0.47017249]\n",
      "TRAINING LOG_LOSS=0.470172506471\n",
      "TRAINING ROC AUC:0.84035103271\n",
      "GPU: 18.128 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()    \n",
    "epochs=20000\n",
    "\n",
    "for step in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)    \n",
    "    # cost/loss function\n",
    "    cost = -(Y * torch.log(hypothesis) + (1 - Y)\n",
    "             * torch.log(1 - hypothesis)).mean()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 4000 == 0:\n",
    "        print(step, cost.data.cpu().numpy())\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "        # Use .cpu() to move the tensor to host memory first.\n",
    "#         predicted = (model(X).data > 0.5).float()\n",
    "        predicted = (model(X).data ).float() # This is like predict proba\n",
    "        predictions=predicted.cpu().numpy()\n",
    "#         accuracy = (predicted == Y.data).float().mean()\n",
    "#         print('TRAINNING Accuracy:' + str(accuracy))\n",
    "        print ('TRAINING LOG_LOSS=' + str(log_loss(trainY, predictions)))\n",
    "        R_SCORE=roc_auc_score(Y.data.cpu().numpy(),predictions )        \n",
    "        print ('TRAINING ROC AUC:' + str(R_SCORE))\n",
    "\n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cross validation, metrics, ROC_AUC etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 8) (167, 1)\n",
      "<type 'numpy.ndarray'> <type 'numpy.ndarray'>\n",
      "VALIDATION Accuracy:0.0\n",
      "VALIDATION ROC AUC:0.827414330218\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJQoREUno/wGO1ewZB7vVWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb24476b2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Validation data\n",
    "x_data_np_val = np.array(testX.values, dtype=np.float32)\n",
    "y_data_np_val = np.array(testY, dtype=np.float32)\n",
    "y_data_np_val=y_data_np_val.reshape((y_data_np_val.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "\n",
    "\n",
    "print(x_data_np_val.shape, y_data_np_val.shape)\n",
    "print(type(x_data_np_val), type(y_data_np_val))\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    X_val = Variable(torch.from_numpy(x_data_np_val).cuda()) # Note the conversion for pytorch\n",
    "    Y_val = Variable(torch.from_numpy(y_data_np_val).cuda())\n",
    "else:\n",
    "    lgr.info (\"Using the CPU\")\n",
    "    X_val = Variable(torch.from_numpy(x_data_np_val)) # Note the conversion for pytorch\n",
    "    Y_val = Variable(torch.from_numpy(y_data_np_val))\n",
    "\n",
    "# VALIDATION\n",
    "predicted_val = (model(X_val).data).float()\n",
    "predictions_val=predicted_val.cpu().numpy()\n",
    "accuracy_val = (predicted_val == Y_val.data).float().mean()\n",
    "print('VALIDATION Accuracy:' + str(accuracy_val))\n",
    "R_SCORE_VAL=roc_auc_score(Y_val.data.cpu().numpy(),predictions_val)        \n",
    "print ('VALIDATION ROC AUC:' + str(R_SCORE_VAL))\n",
    "\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(testY, predictions_val)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt.title('LOG_LOSS=' + str(log_loss(testY, predictions_val)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
