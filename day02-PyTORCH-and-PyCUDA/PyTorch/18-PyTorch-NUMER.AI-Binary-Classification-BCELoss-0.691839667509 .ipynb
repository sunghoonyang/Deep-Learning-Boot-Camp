{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n",
    "\n",
    "<img src=\"../images/bcamp.png\" align=\"center\">\n",
    "\n",
    "## 18  PyTorch NUMER.AI  Deep Learning Binary Classification using BCELoss \n",
    "\n",
    "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n",
    "\n",
    "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n",
    "\n",
    "*Shlomo Kashani*\n",
    "\n",
    "<img src=\"../images/pt.jpg\" width=\"35%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# What consists a Numerai competition?\n",
    "- Numerai provides payments based on the number of correctly predictted labels (LOGG_LOSS) in a data-set which changes every week.\n",
    "\n",
    "- Two data-sets are provided: numerai_training_data.csv and numerai_tournament_data.csv\n",
    "\n",
    "# Criteria \n",
    "- On top of LOG_LOSS, they also measure:\n",
    "* Consistency\n",
    "* Originality\t\n",
    "* Concordance \n",
    "\n",
    "\n",
    "# PyTorch and Numerai\n",
    "\n",
    "- This tutorial was written in order to demonstrate a **fully working** example of a PyTorch NN on a real world use case, namely a Binary Classification problem on the NumerAI data set. If you are interested in the sk-learn version of this problem please refer to: https://github.com/QuantScientist/deep-ml-meetups/tree/master/hacking-kaggle/python/numer-ai \n",
    "\n",
    "- For the scientific foundation behind Binary Classification and Logistic Regression, refer to: https://github.com/QuantScientist/Deep-Learning-Boot-Camp/tree/master/Data-Science-Interviews-Book\n",
    "\n",
    "- Every step, from reading the CSV into numpy arrays, converting to GPU based tensors, training and validation, are meant to aid newcomers in their first steps in PyTorch. \n",
    "\n",
    "- Additionally, commonly used Kaggle metrics such as ROC_AUC and LOG_LOSS are logged and plotted both for the training set as well as for the validation set. \n",
    "\n",
    "- Thus, the NN architecture is naive and by no means **optimized**. Hopefully, I will improve it over time and I am working on a second CNN based version of the same problem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Data\n",
    "- Download from https://numer.ai/leaderboard\n",
    "\n",
    "\n",
    "<img src=\"../images/numerai-logo.png\" width=\"35%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:0.12.1\n",
      "__Python VERSION: 3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]\n",
      "__pyTorch VERSION: 0.2.1+a4fc05a\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "OS:  win32\n",
      "Python:  3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]\n",
      "PyTorch:  0.2.1+a4fc05a\n",
      "Numpy:  1.13.3\n",
      "3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]\n",
      "0.0\n",
      "svmem(total=68627443712, available=42866917376, percent=37.5, used=25760526336, free=42866917376)\n",
      "memory GB: 0.17676544189453125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu75/torch-0.2.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "# !pip install --upgrade torch\n",
    "# !pip install torchvision \n",
    "# ! pip install cv2\n",
    "# import cv2\n",
    "\n",
    "# !pip install pycuda\n",
    "%reset -f\n",
    "# %%timeit\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import logging\n",
    "import numpy\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "import tensorflow as tf \n",
    "print(\"tensorflow:\" + tf.__version__)\n",
    "!set \"KERAS_BACKEND=tensorflow\"\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "\n",
    "\n",
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install psutil\n",
    "import psutil\n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "\n",
    "cpuStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:USE CUDA=True\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "lgr.info(\"USE CUDA=\" + str (use_cuda))\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ! watch -n 0.1 'ps f -o user,pgrp,pid,pcpu,pmem,start,time,command -p `lsof -n -w -t /dev/nvidia*`'\n",
    "# sudo apt-get install dstat #install dstat\n",
    "# sudo pip install nvidia-ml-py #install Python NVIDIA Management Library\n",
    "# wget https://raw.githubusercontent.com/datumbox/dstat/master/plugins/dstat_nvidia_gpu.py\n",
    "# sudo mv dstat_nvidia_gpu.py /usr/share/dstat/ #move file to the plugins directory of dstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "TARGET_VAR= 'target'\n",
    "TOURNAMENT_DATA_CSV = 'numerai_tournament_data.csv'\n",
    "TRAINING_DATA_CSV = 'numerai_training_data.csv'\n",
    "BASE_FOLDER = 'numerai/'\n",
    "\n",
    "# fix seed\n",
    "seed=17*19\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Load a CSV file for Binary classification (numpy)\n",
    "\n",
    "As mentioned, NumerAI provided **numerai_training_data.csv** and **numerai_tournament_data.csv.**\n",
    "\n",
    "- Training_data.csv is labeled\n",
    "- Numerai_tournament_data.csv has lebles for the **validation set** and no labels for the **test set**. See belo how I seperate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>805942eb33874b8a</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.30008</td>\n",
       "      <td>0.37324</td>\n",
       "      <td>0.57645</td>\n",
       "      <td>0.37148</td>\n",
       "      <td>0.52052</td>\n",
       "      <td>0.60583</td>\n",
       "      <td>0.33377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47933</td>\n",
       "      <td>0.58084</td>\n",
       "      <td>0.42970</td>\n",
       "      <td>0.45649</td>\n",
       "      <td>0.60583</td>\n",
       "      <td>0.72200</td>\n",
       "      <td>0.50618</td>\n",
       "      <td>0.48407</td>\n",
       "      <td>0.50080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b7677d6dd4a4628</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.56470</td>\n",
       "      <td>0.70196</td>\n",
       "      <td>0.48211</td>\n",
       "      <td>0.62086</td>\n",
       "      <td>0.62108</td>\n",
       "      <td>0.45080</td>\n",
       "      <td>0.53855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46720</td>\n",
       "      <td>0.49887</td>\n",
       "      <td>0.75146</td>\n",
       "      <td>0.29838</td>\n",
       "      <td>0.60046</td>\n",
       "      <td>0.39081</td>\n",
       "      <td>0.56075</td>\n",
       "      <td>0.66980</td>\n",
       "      <td>0.54756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d07e9a5554ce4260</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.43007</td>\n",
       "      <td>0.66582</td>\n",
       "      <td>0.49114</td>\n",
       "      <td>0.47834</td>\n",
       "      <td>0.58221</td>\n",
       "      <td>0.56852</td>\n",
       "      <td>0.31707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47799</td>\n",
       "      <td>0.53493</td>\n",
       "      <td>0.62822</td>\n",
       "      <td>0.33925</td>\n",
       "      <td>0.50770</td>\n",
       "      <td>0.37361</td>\n",
       "      <td>0.64351</td>\n",
       "      <td>0.44245</td>\n",
       "      <td>0.46482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edb288460914446b</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.45063</td>\n",
       "      <td>0.41458</td>\n",
       "      <td>0.45002</td>\n",
       "      <td>0.45682</td>\n",
       "      <td>0.51356</td>\n",
       "      <td>0.30201</td>\n",
       "      <td>0.58351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50967</td>\n",
       "      <td>0.52020</td>\n",
       "      <td>0.53748</td>\n",
       "      <td>0.65659</td>\n",
       "      <td>0.42574</td>\n",
       "      <td>0.55174</td>\n",
       "      <td>0.45375</td>\n",
       "      <td>0.53443</td>\n",
       "      <td>0.41326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71c393405b0f4835</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.32543</td>\n",
       "      <td>0.29692</td>\n",
       "      <td>0.62043</td>\n",
       "      <td>0.50293</td>\n",
       "      <td>0.53586</td>\n",
       "      <td>0.63649</td>\n",
       "      <td>0.23866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48918</td>\n",
       "      <td>0.60177</td>\n",
       "      <td>0.48885</td>\n",
       "      <td>0.47384</td>\n",
       "      <td>0.45593</td>\n",
       "      <td>0.59715</td>\n",
       "      <td>0.60360</td>\n",
       "      <td>0.41422</td>\n",
       "      <td>0.41210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   era data_type  feature1  feature2  feature3  feature4  \\\n",
       "0  805942eb33874b8a  era1     train   0.30008   0.37324   0.57645   0.37148   \n",
       "1  5b7677d6dd4a4628  era1     train   0.56470   0.70196   0.48211   0.62086   \n",
       "2  d07e9a5554ce4260  era1     train   0.43007   0.66582   0.49114   0.47834   \n",
       "3  edb288460914446b  era1     train   0.45063   0.41458   0.45002   0.45682   \n",
       "4  71c393405b0f4835  era1     train   0.32543   0.29692   0.62043   0.50293   \n",
       "\n",
       "   feature5  feature6  feature7   ...    feature42  feature43  feature44  \\\n",
       "0   0.52052   0.60583   0.33377   ...      0.47933    0.58084    0.42970   \n",
       "1   0.62108   0.45080   0.53855   ...      0.46720    0.49887    0.75146   \n",
       "2   0.58221   0.56852   0.31707   ...      0.47799    0.53493    0.62822   \n",
       "3   0.51356   0.30201   0.58351   ...      0.50967    0.52020    0.53748   \n",
       "4   0.53586   0.63649   0.23866   ...      0.48918    0.60177    0.48885   \n",
       "\n",
       "   feature45  feature46  feature47  feature48  feature49  feature50  target  \n",
       "0    0.45649    0.60583    0.72200    0.50618    0.48407    0.50080       0  \n",
       "1    0.29838    0.60046    0.39081    0.56075    0.66980    0.54756       0  \n",
       "2    0.33925    0.50770    0.37361    0.64351    0.44245    0.46482       0  \n",
       "3    0.65659    0.42574    0.55174    0.45375    0.53443    0.41326       0  \n",
       "4    0.47384    0.45593    0.59715    0.60360    0.41422    0.41210       1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Feature enrichement\n",
    "- This would be usually not required when using NN's; it is here for demonstration purposes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import defaultdict\n",
    "\n",
    "# def genBasicFeatures(inDF):\n",
    "#     print('Generating basic features ...')\n",
    "#     df_copy=inDF.copy(deep=True)\n",
    "#     magicNumber=21\n",
    "#     feature_cols = list(inDF.columns)\n",
    "\n",
    "#     inDF['x_mean'] = np.mean(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_median'] = np.median(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_std'] = np.std(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_skew'] = scipy.stats.skew(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_kurt'] = scipy.stats.kurtosis(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_var'] = np.var(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_max'] = np.max(df_copy.ix[:, 0:magicNumber], axis=1)\n",
    "#     inDF['x_min'] = np.min(df_copy.ix[:, 0:magicNumber], axis=1)    \n",
    "\n",
    "#     return inDF\n",
    "\n",
    "def addPolyFeatures(inDF, deg=2):\n",
    "    print('Generating poly features ...')\n",
    "    df_copy=inDF.copy(deep=True)\n",
    "    poly=PolynomialFeatures(degree=deg)\n",
    "    p_testX = poly.fit(df_copy)\n",
    "    # AttributeError: 'PolynomialFeatures' object has no attribute 'get_feature_names'\n",
    "    target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(df_copy.columns,p) for p in poly.powers_]]\n",
    "    df_copy = pd.DataFrame(p_testX.transform(df_copy),columns=target_feature_names)\n",
    "        \n",
    "    return df_copy\n",
    "\n",
    "def oneHOT(inDF):\n",
    "    d = defaultdict(LabelEncoder)\n",
    "    X_df=inDF.copy(deep=True)\n",
    "    # Encoding the variable\n",
    "    X_df = X_df.apply(lambda x: d['era'].fit_transform(x))\n",
    "            \n",
    "    return X_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Train / Validation / Test Split\n",
    "- Numerai provides a data set that is allready split into train, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Train, Validation, Test Split\n",
    "def loadDataSplit():\n",
    "    df_train = pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV)\n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    df_test_valid = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "\n",
    "    answers_1_SINGLE = df_train[TARGET_VAR]\n",
    "    df_train.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    df_train.drop('id', axis=1,inplace=True)\n",
    "    df_train.drop('era', axis=1,inplace=True)\n",
    "    df_train.drop('data_type', axis=1,inplace=True)    \n",
    "    \n",
    "#     df_train=oneHOT(df_train)\n",
    "\n",
    "    df_train.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=False,  index = False)    \n",
    "    df_train= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + 'clean.csv', header=None, dtype=np.float32)    \n",
    "    df_train = pd.concat([df_train, answers_1_SINGLE], axis=1)\n",
    "    feature_cols = list(df_train.columns[:-1])\n",
    "#     print (feature_cols)\n",
    "    target_col = df_train.columns[-1]\n",
    "    trainX, trainY = df_train[feature_cols], df_train[target_col]\n",
    "    \n",
    "    \n",
    "    # TOURNAMENT_DATA_CSV has both validation and test data provided by NumerAI\n",
    "    # Validation set\n",
    "    df_validation_set=df_test_valid.loc[df_test_valid['data_type'] == 'validation'] \n",
    "    df_validation_set=df_validation_set.copy(deep=True)\n",
    "    answers_1_SINGLE_validation = df_validation_set[TARGET_VAR]\n",
    "    df_validation_set.drop(TARGET_VAR, axis=1,inplace=True)    \n",
    "    df_validation_set.drop('id', axis=1,inplace=True)\n",
    "    df_validation_set.drop('era', axis=1,inplace=True)\n",
    "    df_validation_set.drop('data_type', axis=1,inplace=True)\n",
    "    \n",
    "#     df_validation_set=oneHOT(df_validation_set)\n",
    "    \n",
    "    df_validation_set.to_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=False,  index = False)    \n",
    "    df_validation_set= pd.read_csv(BASE_FOLDER + TRAINING_DATA_CSV + '-validation-clean.csv', header=None, dtype=np.float32)    \n",
    "    df_validation_set = pd.concat([df_validation_set, answers_1_SINGLE_validation], axis=1)\n",
    "    feature_cols = list(df_validation_set.columns[:-1])\n",
    "\n",
    "    target_col = df_validation_set.columns[-1]\n",
    "    valX, valY = df_validation_set[feature_cols], df_validation_set[target_col]\n",
    "                            \n",
    "    # Test set for submission (not labeled)    \n",
    "    df_test_set = pd.read_csv(BASE_FOLDER + TOURNAMENT_DATA_CSV)\n",
    "#     df_test_set=df_test_set.loc[df_test_valid['data_type'] == 'live'] \n",
    "    df_test_set=df_test_set.copy(deep=True)\n",
    "    df_test_set.drop(TARGET_VAR, axis=1,inplace=True)\n",
    "    tid_1_SINGLE = df_test_set['id']\n",
    "    df_test_set.drop('id', axis=1,inplace=True)\n",
    "    df_test_set.drop('era', axis=1,inplace=True)\n",
    "    df_test_set.drop('data_type', axis=1,inplace=True)   \n",
    "    \n",
    "#     df_test_set=oneHOT(df_validation_set)\n",
    "    \n",
    "    feature_cols = list(df_test_set.columns) # must be run here, we dont want the ID    \n",
    "#     print (feature_cols)\n",
    "    df_test_set = pd.concat([tid_1_SINGLE, df_test_set], axis=1)            \n",
    "    testX = df_test_set[feature_cols].values\n",
    "        \n",
    "    return trainX, trainY, valX, valY, testX, df_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(535713, 50)\n",
      "(535713,)\n",
      "(73865, 50)\n",
      "(73865,)\n",
      "(349053, 50)\n",
      "(349053, 51)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "# # Number of features for the input layer\n",
    "N_FEATURES=trainX.shape[1]\n",
    "print (trainX.shape)\n",
    "print (trainY.shape)\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "print (testX.shape)\n",
    "print (df_test_set.shape)\n",
    "\n",
    "# print (trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Correlated columns\n",
    "- Correlation plot\n",
    "- Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 numeric and 0 categorical columns in train data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f744c471e90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAD/CAYAAADCOHwpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBfW5mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f744c471910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seperate out the Categorical and Numerical features\n",
    "import seaborn as sns\n",
    "\n",
    "numerical_feature=trainX.dtypes[trainX.dtypes!= 'object'].index\n",
    "categorical_feature=trainX.dtypes[trainX.dtypes== 'object'].index\n",
    "\n",
    "print (\"There are {} numeric and {} categorical columns in train data\".format(numerical_feature.shape[0],categorical_feature.shape[0]))\n",
    "\n",
    "corr=trainX[numerical_feature].corr()\n",
    "sns.heatmap(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Absolute Correlations\n",
      "8   46    0.740922\n",
      "1   37    0.718052\n",
      "3   11    0.712265\n",
      "    48    0.650631\n",
      "19  44    0.641989\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from pandas import *\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "\n",
    "# from https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas\n",
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(trainX, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create PyTorch GPU tensors from numpy arrays\n",
    "\n",
    "- Note how we transfrom the np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def XnumpyToTensor(x_data_np):\n",
    "    x_data_np = np.array(x_data_np, dtype=np.float32)        \n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")    \n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")\n",
    "        X_tensor = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "    \n",
    "    print(type(X_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(x_data_np.shape)\n",
    "    print(type(x_data_np))    \n",
    "    return X_tensor\n",
    "\n",
    "\n",
    "# Convert the np arrays into the correct dimention and type\n",
    "# Note that BCEloss requires Float in X as well as in y\n",
    "def YnumpyToTensor(y_data_np):    \n",
    "    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))\n",
    "\n",
    "    if use_cuda:\n",
    "        lgr.info (\"Using the GPU\")            \n",
    "    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n",
    "    else:\n",
    "        lgr.info (\"Using the CPU\")        \n",
    "    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n",
    "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n",
    "\n",
    "    print(type(Y_tensor.data)) # should be 'torch.cuda.FloatTensor'\n",
    "    print(y_data_np.shape)\n",
    "    print(type(y_data_np))    \n",
    "    return Y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The NN model\n",
    "\n",
    "### MLP model\n",
    "- A multilayer perceptron is a logistic regressor where instead of feeding the input to the logistic regression you insert a intermediate layer, called the hidden layer, that has a nonlinear activation function (usually tanh or sigmoid) . One can use many such hidden layers making the architecture deep.\n",
    "\n",
    "- Here we define a simple MLP structure. We map the input feature vector to a higher space, then later gradually decrease the dimension, and in the end into a 1-dimension space. Because we are calculating the probability of each genre independently, after the final layer we need to use a sigmoid layer. \n",
    "\n",
    "###  Initial weights selection\n",
    "\n",
    "- There are many ways to select the initial weights to a neural network architecture. A common initialization scheme is random initialization, which sets the biases and weights of all the nodes in each hidden layer randomly.\n",
    "\n",
    "- Before starting the training process, an initial value is assigned to each variable. This is done by pure randomness, using for example a uniform or Gaussian distribution. But if we start with weights that are too small, the signal could decrease so much that it is too small to be useful. On the other side, when the parameters are initialized with high values, the signal can end up to explode while propagating through the network.\n",
    "\n",
    "- In consequence, a good initialization can have a radical effect on how fast the network will learn useful patterns.For this purpose, some best practices have been developed. One famous example used is **Xavier initialization**. Its formulation is based on the number of input and output neurons and uses sampling from a uniform distribution with zero mean and all biases set to zero.\n",
    "\n",
    "- In effect (according to theory) initializing the weights of the network to values that would be closer to the optimal, and therefore require less epochs to train.\n",
    "\n",
    "### References: \n",
    "* **`nninit.xavier_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a uniform distribution.\n",
    "* **`nninit.xavier_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Understanding the difficulty of training deep feedforward neural networks\" - Glorot, X. and Bengio, Y.](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), using a normal distribution.\n",
    "* **`nninit.kaiming_uniform(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.](https://arxiv.org/abs/1502.01852) using a uniform distribution.\n",
    "* **`nninit.kaiming_normal(tensor, gain=1)`** - Fills `tensor` with values according to the method described in [\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dropout (p = 0.35)\n",
      "INFO:__main__:Sequential (\n",
      "  (0): Linear (50 -> 256)\n",
      "  (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (2): Dropout (p = 0.35)\n",
      "  (3): LeakyReLU (0.01)\n",
      "  (4): Linear (256 -> 128)\n",
      "  (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (6): Dropout (p = 0.35)\n",
      "  (7): LeakyReLU (0.01)\n",
      "  (8): Linear (128 -> 128)\n",
      "  (9): Dropout (p = 0.35)\n",
      "  (10): Sigmoid ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# p is the probability of being dropped in PyTorch\n",
    "# NN params\n",
    "DROPOUT_PROB = 0.65\n",
    "\n",
    "LR = 0.005\n",
    "MOMENTUM= 0.9\n",
    "dropout = torch.nn.Dropout(p=1 - (DROPOUT_PROB))\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "tanh=torch.nn.Tanh()\n",
    "relu=torch.nn.LeakyReLU()\n",
    "\n",
    "lgr.info(dropout)\n",
    "\n",
    "hiddenLayer1Size=256\n",
    "hiddenLayer2Size=int(hiddenLayer1Size/2)\n",
    "hiddenLayer3Size=int(hiddenLayer1Size/2)\n",
    "hiddenLayer4Size=int(hiddenLayer1Size/2)\n",
    "\n",
    "linear1=torch.nn.Linear(N_FEATURES, hiddenLayer1Size, bias=True) \n",
    "torch.nn.init.xavier_uniform(linear1.weight)\n",
    "\n",
    "linear2=torch.nn.Linear(hiddenLayer1Size, hiddenLayer2Size)\n",
    "torch.nn.init.xavier_uniform(linear2.weight)\n",
    "\n",
    "linear3=torch.nn.Linear(hiddenLayer2Size,hiddenLayer3Size)\n",
    "torch.nn.init.xavier_uniform(linear3.weight)\n",
    "\n",
    "linear4=torch.nn.Linear(hiddenLayer3Size,1)\n",
    "torch.nn.init.xavier_uniform(linear4.weight)\n",
    "\n",
    "\n",
    "net = torch.nn.Sequential(linear1,nn.BatchNorm1d(hiddenLayer1Size),dropout,relu,\n",
    "                          linear2,nn.BatchNorm1d(hiddenLayer2Size),dropout,relu,\n",
    "                          linear3,dropout,sigmoid,                                                \n",
    "                          )\n",
    "lgr.info(net)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "INFO:__main__:<torch.optim.adam.Adam object at 0x7f745c434d10>\n",
      "INFO:__main__:BCELoss (\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.02)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=5e-3)\n",
    "#L2 regularization can easily be added to the entire model via the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-2) #  L2 regularization\n",
    "\n",
    "loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "# http://andersonjo.github.io/artificial-intelligence/2017/01/07/Cost-Functions/\n",
    "\n",
    "if use_cuda:\n",
    "    lgr.info (\"Using the GPU\")    \n",
    "    net.cuda()\n",
    "    loss_func.cuda()\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "lgr.info (optimizer)\n",
    "lgr.info (loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Training in batches  + Measuring the performance of the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(535713, 50)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(535713, 50)\n",
      "<type 'numpy.ndarray'>\n",
      "(535713, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(535713, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /home/gpu/dev/pytorch/torch/lib/THC/THCTensorCopy.cu:204",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d4ad7660cdb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# From here onwards, we must only use PyTorch Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor_train\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# input x and predict based on x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_tensor_train\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# must be (1. nn output, 2. target), the target label is NOT one-hotted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/_functions/blas.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 36\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /home/gpu/dev/pytorch/torch/lib/THC/THCTensorCopy.cu:204"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()    \n",
    "epochs=160 # change to 400 for better results\n",
    "div_factor=20\n",
    "all_losses = []\n",
    "loss_arr =[]\n",
    "\n",
    "X_tensor_train= XnumpyToTensor(trainX)\n",
    "Y_tensor_train= YnumpyToTensor(trainY)\n",
    "print(type(X_tensor_train.data), type(Y_tensor_train.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "# CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.\n",
    "# X_tensor_train=X_tensor_train.contiguous()\n",
    "# Y_tensor_train=Y_tensor_train.contiguous()\n",
    "\n",
    "\n",
    "# dataset = TensorDataset(data_tensor = X_tensor_train,target_tensor = Y_tensor_train)\n",
    "# loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "       \n",
    "                \n",
    "# From here onwards, we must only use PyTorch Tensors\n",
    "for step in range(epochs):    \n",
    "    out = net(X_tensor_train)                 # input x and predict based on x\n",
    "    cost = loss_func(out, Y_tensor_train)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    cost.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "                   \n",
    "        \n",
    "    if step % div_factor == 0:        \n",
    "        loss = cost.data[0]\n",
    "        all_losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())\n",
    "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n",
    "        # Use .cpu() to move the tensor to host memory first.        \n",
    "        prediction = (net(X_tensor_train).data).float() # probabilities         \n",
    "#         prediction = (net(X_tensor).data > 0.5).float() # zero or one\n",
    "#         print (\"Pred:\" + str (prediction)) # Pred:Variable containing: 0 or 1\n",
    "#         pred_y = prediction.data.numpy().squeeze()            \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = Y_tensor_train.cpu().data.numpy()\n",
    "                        \n",
    "        tu = (log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "        print ('LOG_LOSS={}, ROC_AUC={} '.format(*tu))  \n",
    "        \n",
    "        loss_arr.append(cost.cpu().data.numpy()[0])\n",
    "                \n",
    "end_time = time.time()\n",
    "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Visualize Loss Graph using Visdom\n",
    "- Make sure you have Visdom installed and running\n",
    "- pip install visdom\n",
    "- python -m visdom.server &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from visdom import Visdom\n",
    "viz = Visdom()\n",
    "\n",
    "num_epoch=int(epochs/div_factor)\n",
    "\n",
    "x = np.reshape([i for i in range(num_epoch)],newshape=[num_epoch,1])\n",
    "loss_data = np.reshape(loss_arr,newshape=[num_epoch,1])\n",
    "\n",
    "win3=viz.line(\n",
    "    X = x,\n",
    "    Y = loss_data,\n",
    "    opts=dict(\n",
    "        xtickmin=0,\n",
    "        xtickmax=num_epoch,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=20,\n",
    "        ytickstep=1,\n",
    "        markercolor=np.random.randint(0, 255, num_epoch),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Performance of the deep learning model on the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using the GPU\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "INFO:__main__:Using the GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73865, 50)\n",
      "(73865,)\n",
      "(73865, 50)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(73865, 50)\n",
      "<type 'numpy.ndarray'>\n",
      "(73865, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "(73865, 1)\n",
      "<type 'numpy.ndarray'>\n",
      "<class 'torch.cuda.FloatTensor'> <class 'torch.cuda.FloatTensor'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "log_loss=0.692511641564 roc_auc=0.523741705841 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f745cca7510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.eval()\n",
    "# Validation data\n",
    "print (valX.shape)\n",
    "print (valY.shape)\n",
    "\n",
    "X_tensor_val= XnumpyToTensor(valX)\n",
    "Y_tensor_val= YnumpyToTensor(valY)\n",
    "\n",
    "\n",
    "print(type(X_tensor_val.data), type(Y_tensor_val.data)) # should be 'torch.cuda.FloatTensor'\n",
    "\n",
    "predicted_val = (net(X_tensor_val).data).float() # probabilities \n",
    "# predicted_val = (net(X_tensor_val).data > 0.5).float() # zero or one\n",
    "pred_y = predicted_val.cpu().numpy()\n",
    "target_y = Y_tensor_val.cpu().data.numpy()                \n",
    "\n",
    "print (type(pred_y))\n",
    "print (type(target_y))\n",
    "\n",
    "tu = (log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ))\n",
    "print ('\\n')\n",
    "print ('log_loss={} roc_auc={} '.format(*tu))\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('LOG_LOSS=' + str(log_loss(target_y, pred_y)))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# print (pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Submission on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349053, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9403af5f3de44039</td>\n",
       "      <td>0.498911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67d84c8e966047d9</td>\n",
       "      <td>0.500971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12f1aa03af504e19</td>\n",
       "      <td>0.482130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e003f1be931040fa</td>\n",
       "      <td>0.527270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550cac2470fe4644</td>\n",
       "      <td>0.501118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  probability\n",
       "0  9403af5f3de44039     0.498911\n",
       "1  67d84c8e966047d9     0.500971\n",
       "2  12f1aa03af504e19     0.482130\n",
       "3  e003f1be931040fa     0.527270\n",
       "4  550cac2470fe4644     0.501118"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testX, df_test_set\n",
    "# df[df.columns.difference(['b'])]\n",
    "# trainX, trainY, valX, valY, testX, df_test_set = loadDataSplit()\n",
    "    \n",
    "print (df_test_set.shape)\n",
    "columns = ['id', 'probability']\n",
    "df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n",
    "# df_pred.id.astype(int)\n",
    "\n",
    "for index, row in df_test_set.iterrows():\n",
    "    rwo_no_id=row.drop('id')    \n",
    "#     print (rwo_no_id.values)    \n",
    "    x_data_np = np.array(rwo_no_id.values, dtype=np.float32)        \n",
    "    if use_cuda:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n",
    "    else:\n",
    "        X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n",
    "                    \n",
    "    X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n",
    "    predicted_val = (net(X_tensor_test).data).float() # probabilities     \n",
    "    p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n",
    "    \n",
    "    df_pred = df_pred.append({'id':row['id'], 'probability':p_test},ignore_index=True)\n",
    "#     df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n",
    "\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Create a CSV with the ID's and the coresponding probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/pred_0.691767700923_1505839265.61.csv\n"
     ]
    }
   ],
   "source": [
    "# df_pred.id=df_pred.id.astype(int)\n",
    "\n",
    "def savePred(df_pred, loss):\n",
    "#     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n",
    "    csv_path = 'pred/pred_{}_{}.csv'.format(loss, (str(time.time())))\n",
    "    df_pred.to_csv(csv_path, columns=('id', 'probability'), index=None)\n",
    "    print (csv_path)\n",
    "    \n",
    "savePred (df_pred, log_loss(target_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Actual score on Numer.ai - screenshot of the leader board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"../images/numerai-score.jpg\" width=\"35%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "livereveal": {
   "controls": "true",
   "history": "true",
   "mouseWheel": "true",
   "overview": "true",
   "progress": "true",
   "scroll": "true",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
