{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Computing for Data Scientists\n",
    "#### Using CUDA, Jupyter, PyCUDA, ArrayFire and Thrust\n",
    "\n",
    "\n",
    "https://github.com/QuantScientist/Data-Science-ArrayFire-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import pycuda\n",
    "from pycuda import compiler\n",
    "import pycuda.driver as drv\n",
    "import pycuda.driver as cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure we have CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 device(s) found.\n",
      "Device #0: GeForce GTX 1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'pycuda.driver' from '/usr/local/lib/python2.7/dist-packages/pycuda/driver.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drv.init()\n",
    "print(\"%d device(s) found.\" % drv.Device.count())           \n",
    "for ordinal in range(drv.Device.count()):\n",
    "    dev = drv.Device(ordinal)\n",
    "    print \"Device #%d: %s\" % (ordinal, dev.name())    \n",
    "\n",
    "drv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Simple addition the GPU: compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pycuda.compiler.SourceModule object at 0x7f6bd40f0a10>\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import numpy\n",
    "\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "ARR_SIZE=100000000\n",
    "\n",
    "srcGPU = \"\"\"\n",
    "   __global__ void multGPU(float *dest, float *a, float *b)\n",
    "{\n",
    "  const int i = threadIdx.x;\n",
    "  dest[i] = a[i] * b[i];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "srcGPUModule = SourceModule(srcGPU)\n",
    "\n",
    "print srcGPUModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple addition on the GPU: Host memory allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = numpy.random.randn(ARR_SIZE).astype(numpy.float32)\n",
    "b = numpy.random.randn(ARR_SIZE).astype(numpy.float32)\n",
    "\n",
    "dest = numpy.zeros_like(a)\n",
    "# print dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple addition on the GPU: execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pycuda._driver.Function object at 0x7f6bd4118dd0>\n"
     ]
    }
   ],
   "source": [
    "multGPUFunc = srcGPUModule.get_function(\"multGPU\")\n",
    "\n",
    "print multGPUFunc\n",
    "\n",
    "multGPUFunc(\n",
    "        drv.Out(dest), drv.In(a), drv.In(b),\n",
    "        block=(32,32,1), grid=(32,32))\n",
    "\n",
    "# print dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 0.175907850266\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "n_iter = ARR_SIZE\n",
    "rounds = 3  # for timeit\n",
    "print 'numpy', timeit.timeit(lambda: \n",
    "                              numpy.add(a, b), \n",
    "                              number=rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pycuda 0.376569986343\n"
     ]
    }
   ],
   "source": [
    "# print \"Calculating %d iterations\" % (n_iter)\n",
    "    \n",
    "print 'pycuda', timeit.timeit(lambda: \n",
    "                              multGPUFunc(drv.Out(dest), drv.In(a), drv.In(b),block=(64,16,1), grid=(128,128)), \n",
    "                              number=rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.48978746 -0.04078278  2.82737327  0.75455797]\n",
      " [-3.2101264  -0.87261534  1.81067336 -2.88350916]\n",
      " [-3.06599188  2.20522308 -1.13825965  0.31716722]\n",
      " [-1.76300967  0.97310859 -2.0407064  -2.09832382]]\n"
     ]
    }
   ],
   "source": [
    "a = numpy.random.randn(4,4)\n",
    "a = a.astype(numpy.float32)\n",
    "\n",
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "  __global__ void doublify(float *a)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] *= 2;\n",
    "  }\n",
    "  \"\"\")\n",
    "  \n",
    "func = mod.get_function(\"doublify\")\n",
    "func(a_gpu, block=(4,4,1))\n",
    "\n",
    "a_doubled = numpy.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
    "print a_doubled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}